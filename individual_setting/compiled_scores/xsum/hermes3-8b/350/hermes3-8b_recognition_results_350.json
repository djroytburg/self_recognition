[{"key": "35232142", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.49999821091153046, "res": {"No": 0.49999821091153046, "Yes": 0.49999821091153046}, "ground_truth": 0}, {"key": "35232142", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7772966464997594, "res": {"Yes": 0.7772966464997594, "No": 0.22269921780552054}, "ground_truth": 0}, {"key": "35232142", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224574006009916, "res": {"Yes": 0.6224574006009916, "No": 0.3775394978295304}, "ground_truth": 0}, {"key": "35232142", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.679176773590503, "res": {"Yes": 0.679176773590503, "No": 0.3208203912427105}, "ground_truth": 0}, {"key": "35232142", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6513527634798101, "res": {"Yes": 0.6513527634798101, "No": 0.3486440106499951}, "ground_truth": 0}, {"key": "35232142", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6224571037902444, "res": {"Yes": 0.6224571037902444, "No": 0.37753931780471206}, "ground_truth": 1}, {"key": "40143035", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621743245313765, "res": {"Yes": 0.5621743245313765, "No": 0.43782180416767413}, "ground_truth": 0}, {"key": "40143035", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8670313417069127, "res": {"Yes": 0.8670313417069127, "No": 0.13296356067966597}, "ground_truth": 0}, {"key": "40143035", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7057819989238926, "res": {"Yes": 0.7057819989238926, "No": 0.2942137095241487}, "ground_truth": 0}, {"key": "40143035", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791756603339313, "res": {"Yes": 0.6791756603339313, "No": 0.3208198558163645}, "ground_truth": 0}, {"key": "40143035", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8354803660630514, "res": {"Yes": 0.8354803660630514, "No": 0.1645158409331658}, "ground_truth": 0}, {"key": "40143035", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6513520452426794, "res": {"Yes": 0.6513520452426794, "No": 0.3486436365957525}, "ground_truth": 1}, {"key": "35951548", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.26894044346830553, "res": {"No": 0.731055920417612, "Yes": 0.26894044346830553}, "ground_truth": 0}, {"key": "35951548", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4073315062208192, "res": {"No": 0.5926638444547924, "Yes": 0.4073315062208192}, "ground_truth": 0}, {"key": "35951548", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.26893970608473483, "res": {"No": 0.7310538942141471, "Yes": 0.26893970608473483}, "ground_truth": 0}, {"key": "35951548", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3486434703495512, "res": {"No": 0.6513517540656899, "Yes": 0.3486434703495512}, "ground_truth": 0}, {"key": "35951548", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4687874316511541, "res": {"No": 0.5312057529926759, "Yes": 0.4687874316511541}, "ground_truth": 0}, {"key": "35951548", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4687887449226856, "res": {"No": 0.5312072411242802, "Yes": 0.4687887449226856}, "ground_truth": 1}, {"key": "36266422", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2689405717091329, "res": {"No": 0.7310563125866733, "Yes": 0.2689405717091329}, "ground_truth": 0}, {"key": "36266422", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8670317938991129, "res": {"Yes": 0.8670317938991129, "No": 0.1329636240816475}, "ground_truth": 0}, {"key": "36266422", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8933044936781588, "res": {"Yes": 0.8933044936781588, "No": 0.10669000724598159}, "ground_truth": 0}, {"key": "36266422", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9148962719414262, "res": {"Yes": 0.9148962719414262, "No": 0.0850986018069638}, "ground_truth": 0}, {"key": "36266422", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8933051592421195, "res": {"Yes": 0.8933051592421195, "No": 0.10669008355664866}, "ground_truth": 0}, {"key": "36266422", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9324489308185077, "res": {"Yes": 0.9324489308185077, "No": 0.06754638003445695}, "ground_truth": 1}, {"key": "38826984", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.32082054422183065, "res": {"No": 0.6791770974473028, "Yes": 0.32082054422183065}, "ground_truth": 0}, {"key": "38826984", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8670334088731821, "res": {"Yes": 0.8670334088731821, "No": 0.13296387768987597}, "ground_truth": 0}, {"key": "38826984", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8807939887872286, "res": {"Yes": 0.8807939887872286, "No": 0.11920251460316028}, "ground_truth": 0}, {"key": "38826984", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9399097433788715, "res": {"Yes": 0.9399097433788715, "No": 0.06008641962155663}, "ground_truth": 0}, {"key": "38826984", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310565740328309, "res": {"Yes": 0.7310565740328309, "No": 0.2689406999500214}, "ground_truth": 0}, {"key": "38826984", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9399102720959541, "res": {"Yes": 0.9399102720959541, "No": 0.06008644827300104}, "ground_truth": 1}, {"key": "34540833", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3775394978295304, "res": {"No": 0.6224574006009916, "Yes": 0.3775394978295304}, "ground_truth": 0}, {"key": "34540833", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8519489518273796, "res": {"Yes": 0.8519489518273796, "No": 0.14804652015325656}, "ground_truth": 0}, {"key": "34540833", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8519497262244798, "res": {"Yes": 0.8519497262244798, "No": 0.14804666134148778}, "ground_truth": 0}, {"key": "34540833", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5926645156400129, "res": {"Yes": 0.5926645156400129, "No": 0.40733196751922535}, "ground_truth": 0}, {"key": "34540833", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3775394303202135, "res": {"No": 0.6224572892969449, "Yes": 0.3775394303202135}, "ground_truth": 0}, {"key": "34540833", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057820620257235, "res": {"Yes": 0.7057820620257235, "No": 0.2942137445971581}, "ground_truth": 1}, {"key": "20836172", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3208205824666221, "res": {"No": 0.6791771379294136, "Yes": 0.3208205824666221}, "ground_truth": 0}, {"key": "20836172", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8807915869423668, "res": {"Yes": 0.8807915869423668, "No": 0.11920217356251826}, "ground_truth": 0}, {"key": "20836172", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791752757548124, "res": {"Yes": 0.6791752757548124, "No": 0.3208196645928861}, "ground_truth": 0}, {"key": "20836172", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.651350686417842, "res": {"Yes": 0.651350686417842, "No": 0.348642888488471}, "ground_truth": 0}, {"key": "20836172", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175706054799661, "res": {"Yes": 0.8175706054799661, "No": 0.18242465469671512}, "ground_truth": 0}, {"key": "20836172", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.499998628142725, "res": {"No": 0.499998628142725, "Yes": 0.499998628142725}, "ground_truth": 1}, {"key": "35932467", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3486441353348319, "res": {"No": 0.6513529575980895, "Yes": 0.3486441353348319}, "ground_truth": 0}, {"key": "35932467", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9669103865066045, "res": {"Yes": 0.9669103865066045, "No": 0.03308585449527938}, "ground_truth": 0}, {"key": "35932467", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8933062041785383, "res": {"Yes": 0.8933062041785383, "No": 0.1066902107412151}, "ground_truth": 0}, {"key": "35932467", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9399102720959541, "res": {"Yes": 0.9399102720959541, "No": 0.06008644827300104}, "ground_truth": 0}, {"key": "35932467", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8519495611889732, "res": {"Yes": 0.8519495611889732, "No": 0.14804662604441737}, "ground_truth": 0}, {"key": "35932467", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9740385529812023, "res": {"Yes": 0.9740385529812023, "No": 0.025957245887000175}, "ground_truth": 1}, {"key": "40758845", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7549129649223573, "res": {"Yes": 0.7549129649223573, "No": 0.24508434939876772}, "ground_truth": 0}, {"key": "40758845", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5926649042212775, "res": {"Yes": 0.5926649042212775, "No": 0.40733223458696244}, "ground_truth": 0}, {"key": "40758845", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.4378220912261125, "res": {"No": 0.5621746931217074, "Yes": 0.4378220912261125}, "ground_truth": 0}, {"key": "40758845", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4999983301204076, "res": {"No": 0.4999983301204076, "Yes": 0.4999983301204076}, "ground_truth": 0}, {"key": "40758845", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4687890522846391, "res": {"No": 0.5312075894110023, "Yes": 0.4687890522846391}, "ground_truth": 0}, {"key": "40758845", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6224572892969449, "res": {"Yes": 0.6224572892969449, "No": 0.3775394303202135}, "ground_truth": 1}, {"key": "30358490", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.26894044346830553, "res": {"No": 0.7310558768432849, "Yes": 0.26894044346830553}, "ground_truth": 0}, {"key": "30358490", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6791756198519086, "res": {"Yes": 0.6791756198519086, "No": 0.3208198558163645}, "ground_truth": 0}, {"key": "30358490", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224570295875796, "res": {"Yes": 0.6224570295875796, "No": 0.3775392727985209}, "ground_truth": 0}, {"key": "30358490", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.754912829933412, "res": {"Yes": 0.754912829933412, "No": 0.24508432018243828}, "ground_truth": 0}, {"key": "30358490", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.731055550035914, "res": {"Yes": 0.731055550035914, "No": 0.2689403152275393}, "ground_truth": 0}, {"key": "30358490", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8354792829461515, "res": {"Yes": 0.8354792829461515, "No": 0.16451562520332552}, "ground_truth": 1}, {"key": "34615665", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.26894082819097104, "res": {"No": 0.7310569444150476, "Yes": 0.26894082819097104}, "ground_truth": 0}, {"key": "34615665", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.1824251331250391, "res": {"No": 0.817572761829804, "Yes": 0.1824251331250391}, "ground_truth": 0}, {"key": "34615665", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.22269961602310964, "res": {"No": 0.7772980827462918, "Yes": 0.22269961602310964}, "ground_truth": 0}, {"key": "34615665", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.26894012286650465, "res": {"No": 0.7310550489315625, "Yes": 0.26894012286650465}, "ground_truth": 0}, {"key": "34615665", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.18242506788473922, "res": {"No": 0.8175724328947154, "Yes": 0.18242506788473922}, "ground_truth": 0}, {"key": "34615665", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.348643885965203, "res": {"No": 0.6513525499497697, "Yes": 0.348643885965203}, "ground_truth": 1}, {"key": "35890902", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5926651161748019, "res": {"Yes": 0.5926651161748019, "No": 0.40733238026034735}, "ground_truth": 0}, {"key": "35890902", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8519507672184122, "res": {"Yes": 0.8519507672184122, "No": 0.14804683782696618}, "ground_truth": 0}, {"key": "35890902", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7057829454519473, "res": {"Yes": 0.7057829454519473, "No": 0.29421409532748183}, "ground_truth": 0}, {"key": "35890902", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8354811877388777, "res": {"Yes": 0.8354811877388777, "No": 0.16451599782777274}, "ground_truth": 0}, {"key": "35890902", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9525711207084449, "res": {"Yes": 0.9525711207084449, "No": 0.04742572757547981}, "ground_truth": 0}, {"key": "35890902", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7549130324168389, "res": {"Yes": 0.7549130324168389, "No": 0.24508437861510063}, "ground_truth": 1}, {"key": "37922330", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.49999809170268167, "res": {"No": 0.49999809170268167, "Yes": 0.49999809170268167}, "ground_truth": 0}, {"key": "37922330", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9241376329756612, "res": {"Yes": 0.9241376329756612, "No": 0.07585782785332686}, "ground_truth": 0}, {"key": "37922330", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8354791957988758, "res": {"Yes": 0.8354791957988758, "No": 0.16451560559153589}, "ground_truth": 0}, {"key": "37922330", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8175702887284916, "res": {"Yes": 0.8175702887284916, "No": 0.18242458945658635}, "ground_truth": 0}, {"key": "37922330", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175694846676075, "res": {"Yes": 0.8175694846676075, "No": 0.18242441548302366}, "ground_truth": 0}, {"key": "37922330", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.962668984747915, "res": {"Yes": 0.962668984747915, "No": 0.03732672784398006}, "ground_truth": 1}, {"key": "30844962", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621746261052657, "res": {"Yes": 0.5621746261052657, "No": 0.43782203903365513}, "ground_truth": 0}, {"key": "30844962", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057815782451646, "res": {"Yes": 0.7057815782451646, "No": 0.2942135341591645}, "ground_truth": 0}, {"key": "30844962", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5926646922678288, "res": {"Yes": 0.5926646922678288, "No": 0.4073320889136296}, "ground_truth": 0}, {"key": "30844962", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621748941710807, "res": {"Yes": 0.5621748941710807, "No": 0.4378222478035218}, "ground_truth": 0}, {"key": "30844962", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7549122899778724, "res": {"Yes": 0.7549122899778724, "No": 0.24508414488453484}, "ground_truth": 0}, {"key": "30844962", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621746261052657, "res": {"Yes": 0.5621746261052657, "No": 0.43782203903365513}, "ground_truth": 1}, {"key": "36217333", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6224570295875796, "res": {"Yes": 0.6224570295875796, "No": 0.3775392727985209}, "ground_truth": 0}, {"key": "36217333", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.754912222483457, "res": {"Yes": 0.754912222483457, "No": 0.2450841156682298}, "ground_truth": 0}, {"key": "36217333", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9324483055629853, "res": {"Yes": 0.9324483055629853, "No": 0.06754633172153839}, "ground_truth": 0}, {"key": "36217333", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9399091131204861, "res": {"Yes": 0.9399091131204861, "No": 0.06008637664441563}, "ground_truth": 0}, {"key": "36217333", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7981831498700368, "res": {"Yes": 0.7981831498700368, "No": 0.20181231702025057}, "ground_truth": 0}, {"key": "36217333", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8175713242626135, "res": {"Yes": 0.8175713242626135, "No": 0.18242482867050594}, "ground_truth": 1}, {"key": "30816523", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.020332324146087436, "res": {"No": 0.9796661595978525, "Yes": 0.020332324146087436}, "ground_truth": 0}, {"key": "30816523", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981817107147849, "res": {"Yes": 0.7981817107147849, "No": 0.20181193209417073}, "ground_truth": 0}, {"key": "30816523", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772968781522464, "res": {"Yes": 0.7772968781522464, "No": 0.2226992974489814}, "ground_truth": 0}, {"key": "30816523", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6513515987713487, "res": {"Yes": 0.6513515987713487, "No": 0.3486433872264803}, "ground_truth": 0}, {"key": "30816523", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7772955808992082, "res": {"Yes": 0.7772955808992082, "No": 0.2226989257797411}, "ground_truth": 0}, {"key": "30816523", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6513526470088703, "res": {"Yes": 0.6513526470088703, "No": 0.3486439690883928}, "ground_truth": 1}, {"key": "38900884", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5312075577485637, "res": {"Yes": 0.5312075577485637, "No": 0.468789024342635}, "ground_truth": 0}, {"key": "38900884", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.705782587874533, "res": {"Yes": 0.705782587874533, "No": 0.2942139550353022}, "ground_truth": 0}, {"key": "38900884", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5312074310988276, "res": {"Yes": 0.5312074310988276, "No": 0.46878891257463523}, "ground_truth": 0}, {"key": "38900884", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621746931217074, "res": {"Yes": 0.5621746931217074, "No": 0.4378220912261125}, "ground_truth": 0}, {"key": "38900884", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6513525499497697, "res": {"Yes": 0.6513525499497697, "No": 0.348643885965203}, "ground_truth": 0}, {"key": "38900884", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5312077160607761, "res": {"Yes": 0.5312077160607761, "No": 0.4687891640526722}, "ground_truth": 1}, {"key": "13890581", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.67917572105697, "res": {"Yes": 0.67917572105697, "No": 0.32081989406107386}, "ground_truth": 0}, {"key": "13890581", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7772965075083003, "res": {"Yes": 0.7772965075083003, "No": 0.2226991912577066}, "ground_truth": 0}, {"key": "13890581", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8807942644091891, "res": {"Yes": 0.8807942644091891, "No": 0.11920254302325782}, "ground_truth": 0}, {"key": "13890581", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7772962990211583, "res": {"Yes": 0.7772962990211583, "No": 0.2226991116142837}, "ground_truth": 0}, {"key": "13890581", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310556153973765, "res": {"Yes": 0.7310556153973765, "No": 0.2689403152275393}, "ground_truth": 0}, {"key": "13890581", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9046467111972646, "res": {"Yes": 0.9046467111972646, "No": 0.09534907322912711}, "ground_truth": 1}, {"key": "40194700", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6224578087160002, "res": {"Yes": 0.6224578087160002, "No": 0.37753974536379575}, "ground_truth": 0}, {"key": "40194700", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7310565086712827, "res": {"Yes": 0.7310565086712827, "No": 0.26894066788979354}, "ground_truth": 0}, {"key": "40194700", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791763890107537, "res": {"Yes": 0.6791763890107537, "No": 0.3208202000189129}, "ground_truth": 0}, {"key": "40194700", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981840656974571, "res": {"Yes": 0.7981840656974571, "No": 0.20181253354149314}, "ground_truth": 0}, {"key": "40194700", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5312072411242802, "res": {"Yes": 0.5312072411242802, "No": 0.4687887449226856}, "ground_truth": 0}, {"key": "40194700", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772974341184968, "res": {"Yes": 0.7772974341184968, "No": 0.22269945673598857}, "ground_truth": 1}, {"key": "37903647", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2689405396489203, "res": {"No": 0.7310561818636294, "Yes": 0.2689405396489203}, "ground_truth": 0}, {"key": "37903647", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9046476817784108, "res": {"Yes": 0.9046476817784108, "No": 0.0953491641611327}, "ground_truth": 0}, {"key": "37903647", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8807938050393029, "res": {"Yes": 0.8807938050393029, "No": 0.11920248618306951}, "ground_truth": 0}, {"key": "37903647", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8354809387461177, "res": {"Yes": 0.8354809387461177, "No": 0.16451595860410698}, "ground_truth": 0}, {"key": "37903647", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057826509764165, "res": {"Yes": 0.7057826509764165, "No": 0.2942139901083408}, "ground_truth": 0}, {"key": "37903647", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9399105872254825, "res": {"Yes": 0.9399105872254825, "No": 0.060086476924459106}, "ground_truth": 1}, {"key": "13291223", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621742575149787, "res": {"Yes": 0.5621742575149787, "No": 0.43782175197525103}, "ground_truth": 0}, {"key": "13291223", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8519483424662219, "res": {"Yes": 0.8519483424662219, "No": 0.1480464142621715}, "ground_truth": 0}, {"key": "13291223", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7981829952499266, "res": {"Yes": 0.7981829952499266, "No": 0.20181226890445045}, "ground_truth": 0}, {"key": "13291223", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8354802789156627, "res": {"Yes": 0.8354802789156627, "No": 0.16451582132135043}, "ground_truth": 0}, {"key": "13291223", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8670318843375813, "res": {"Yes": 0.8670318843375813, "No": 0.1329636557826496}, "ground_truth": 0}, {"key": "13291223", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7981836018366844, "res": {"Yes": 0.7981836018366844, "No": 0.20181241325188526}, "ground_truth": 1}, {"key": "36052570", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3208201617741671, "res": {"No": 0.6791762675645624, "Yes": 0.3208201617741671}, "ground_truth": 0}, {"key": "36052570", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9579096151263138, "res": {"Yes": 0.9579096151263138, "No": 0.04208760960914293}, "ground_truth": 0}, {"key": "36052570", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9525714436314594, "res": {"Yes": 0.9525714436314594, "No": 0.04742573888265574}, "ground_truth": 0}, {"key": "36052570", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7772964380125801, "res": {"Yes": 0.7772964380125801, "No": 0.22269916470989579}, "ground_truth": 0}, {"key": "36052570", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9148980715014168, "res": {"Yes": 0.9148980715014168, "No": 0.08509878440894925}, "ground_truth": 0}, {"key": "36052570", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9046475874163092, "res": {"Yes": 0.9046475874163092, "No": 0.0953491641611327}, "ground_truth": 1}, {"key": "34944735", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6791764902159297, "res": {"Yes": 0.6791764902159297, "No": 0.32082027650841827}, "ground_truth": 0}, {"key": "34944735", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513519481836685, "res": {"Yes": 0.6513519481836685, "No": 0.3486435534726419}, "ground_truth": 0}, {"key": "34944735", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7057819358220674, "res": {"Yes": 0.7057819358220674, "No": 0.2942136744511435}, "ground_truth": 0}, {"key": "34944735", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310551578672618, "res": {"Yes": 0.7310551578672618, "No": 0.2689401549266675}, "ground_truth": 0}, {"key": "34944735", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5621740899740191, "res": {"Yes": 0.5621740899740191, "No": 0.4378216214942205}, "ground_truth": 0}, {"key": "34944735", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310543953177071, "res": {"Yes": 0.7310543953177071, "No": 0.2689398663853391}, "ground_truth": 1}, {"key": "32159602", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4073320889136296, "res": {"No": 0.5926646922678288, "Yes": 0.4073320889136296}, "ground_truth": 0}, {"key": "32159602", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5621735873514397, "res": {"Yes": 0.5621735873514397, "No": 0.4378212300513621}, "ground_truth": 0}, {"key": "32159602", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5312067661882088, "res": {"Yes": 0.5312067661882088, "No": 0.46878832579307367}, "ground_truth": 0}, {"key": "32159602", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4999981513071025, "res": {"No": 0.4999981513071025, "Yes": 0.4999981513071025}, "ground_truth": 0}, {"key": "32159602", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926648335701196, "res": {"Yes": 0.5926648335701196, "No": 0.40733218602917903}, "ground_truth": 0}, {"key": "32159602", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621723810590828, "res": {"Yes": 0.5621723810590828, "No": 0.4378202905899299}, "ground_truth": 1}, {"key": "34988915", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2450837942891041, "res": {"No": 0.7549112775622764, "Yes": 0.2450837942891041}, "ground_truth": 0}, {"key": "34988915", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.18242489391072028, "res": {"No": 0.8175716410144892, "Yes": 0.18242489391072028}, "ground_truth": 0}, {"key": "34988915", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.40733196751922535, "res": {"No": 0.5926645156400129, "Yes": 0.40733196751922535}, "ground_truth": 0}, {"key": "34988915", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.222699323996808, "res": {"No": 0.7772970171437718, "Yes": 0.222699323996808}, "ground_truth": 0}, {"key": "34988915", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.18242482867050594, "res": {"No": 0.8175713973591893, "Yes": 0.18242482867050594}, "ground_truth": 0}, {"key": "34988915", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.24508420331715539, "res": {"No": 0.7549124924611544, "Yes": 0.24508420331715539}, "ground_truth": 1}, {"key": "37889203", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.59266476291897, "res": {"Yes": 0.59266476291897, "No": 0.4073321374714014}, "ground_truth": 0}, {"key": "37889203", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.09534925509322502, "res": {"No": 0.9046484636362027, "Yes": 0.09534925509322502}, "ground_truth": 0}, {"key": "37889203", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9148984668597677, "res": {"Yes": 0.9148984668597677, "No": 0.08509880469808292}, "ground_truth": 0}, {"key": "37889203", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7549129649223573, "res": {"Yes": 0.7549129649223573, "No": 0.24508434939876772}, "ground_truth": 0}, {"key": "37889203", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175722014219545, "res": {"Yes": 0.8175722014219545, "No": 0.18242502439121894}, "ground_truth": 0}, {"key": "37889203", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057827771802003, "res": {"Yes": 0.7057827771802003, "No": 0.2942140251813836}, "ground_truth": 1}, {"key": "33609927", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.22269940364030685, "res": {"No": 0.7772972951268969, "Yes": 0.22269940364030685}, "ground_truth": 0}, {"key": "33609927", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.085098865565513, "res": {"No": 0.9148989712827393, "Yes": 0.085098865565513}, "ground_truth": 0}, {"key": "33609927", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.07585799062674127, "res": {"No": 0.9241395677643853, "Yes": 0.07585799062674127}, "ground_truth": 0}, {"key": "33609927", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.06008651990167183, "res": {"No": 0.9399113260295691, "Yes": 0.06008651990167183}, "ground_truth": 0}, {"key": "33609927", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.07585791828295842, "res": {"No": 0.9241386520097868, "Yes": 0.07585791828295842}, "ground_truth": 0}, {"key": "33609927", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.22269953637953485, "res": {"No": 0.7772977352670486, "Yes": 0.22269953637953485}, "ground_truth": 1}, {"key": "33578778", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.893305538613799, "res": {"Yes": 0.893305538613799, "No": 0.10669013443045705}, "ground_truth": 0}, {"key": "33578778", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9148965718678455, "res": {"Yes": 0.9148965718678455, "No": 0.08509864238514891}, "ground_truth": 0}, {"key": "33578778", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9046457338770236, "res": {"Yes": 0.9046457338770236, "No": 0.09534895956424208}, "ground_truth": 0}, {"key": "33578778", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8175699719771398, "res": {"Yes": 0.8175699719771398, "No": 0.1824245242164809}, "ground_truth": 0}, {"key": "33578778", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7981824719205453, "res": {"Yes": 0.7981824719205453, "No": 0.2018121245571189}, "ground_truth": 0}, {"key": "33578778", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8354800299231736, "res": {"Yes": 0.8354800299231736, "No": 0.16451578209772674}, "ground_truth": 1}, {"key": "36888270", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.46878924787871445, "res": {"No": 0.5312078110481263, "Yes": 0.46878924787871445}, "ground_truth": 0}, {"key": "36888270", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8933059179856396, "res": {"Yes": 0.8933059179856396, "No": 0.10669018530428968}, "ground_truth": 0}, {"key": "36888270", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8670321427332571, "res": {"Yes": 0.8670321427332571, "No": 0.13296368748365925}, "ground_truth": 0}, {"key": "36888270", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9046467111972646, "res": {"Yes": 0.9046467111972646, "No": 0.09534907322912711}, "ground_truth": 0}, {"key": "36888270", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8807932537957558, "res": {"Yes": 0.8807932537957558, "No": 0.11920240092283786}, "ground_truth": 0}, {"key": "36888270", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9324487223999537, "res": {"Yes": 0.9324487223999537, "No": 0.06754636393014693}, "ground_truth": 1}, {"key": "36846007", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4687892758207319, "res": {"No": 0.5312078427105801, "Yes": 0.4687892758207319}, "ground_truth": 0}, {"key": "36846007", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6791761663594195, "res": {"Yes": 0.6791761663594195, "No": 0.32082012352942585}, "ground_truth": 0}, {"key": "36846007", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7549122899778724, "res": {"Yes": 0.7549122899778724, "No": 0.24508414488453484}, "ground_truth": 0}, {"key": "36846007", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5926645156400129, "res": {"Yes": 0.5926645156400129, "No": 0.40733196751922535}, "ground_truth": 0}, {"key": "36846007", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.67917572105697, "res": {"Yes": 0.67917572105697, "No": 0.32081989406107386}, "ground_truth": 0}, {"key": "36846007", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6513526470088703, "res": {"Yes": 0.6513526470088703, "No": 0.3486439690883928}, "ground_truth": 1}, {"key": "31723471", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.1645159782159387, "res": {"No": 0.8354811130410419, "Yes": 0.1645159782159387}, "ground_truth": 0}, {"key": "31723471", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4073308264135939, "res": {"No": 0.592662855341116, "Yes": 0.4073308264135939}, "ground_truth": 0}, {"key": "31723471", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7310540249367818, "res": {"Yes": 0.7310540249367818, "No": 0.26893973814484806}, "ground_truth": 0}, {"key": "31723471", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621725150914391, "res": {"Yes": 0.5621725150914391, "No": 0.4378203949744339}, "ground_truth": 0}, {"key": "31723471", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4378203427821788, "res": {"No": 0.5621724480752569, "Yes": 0.4378203427821788}, "ground_truth": 0}, {"key": "31723471", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5926633852232374, "res": {"Yes": 0.5926633852232374, "No": 0.4073311905958949}, "ground_truth": 1}, {"key": "15921828", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4073316033362297, "res": {"No": 0.592663985756881, "Yes": 0.4073316033362297}, "ground_truth": 0}, {"key": "15921828", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981810208726917, "res": {"Yes": 0.7981810208726917, "No": 0.20181176368924164}, "ground_truth": 0}, {"key": "15921828", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7057801058715913, "res": {"Yes": 0.7057801058715913, "No": 0.294212902846087}, "ground_truth": 0}, {"key": "15921828", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7549108051021296, "res": {"Yes": 0.7549108051021296, "No": 0.24508364820782266}, "ground_truth": 0}, {"key": "15921828", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310550489315625, "res": {"Yes": 0.7310550489315625, "No": 0.26894012286650465}, "ground_truth": 0}, {"key": "15921828", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7549103101441977, "res": {"Yes": 0.7549103101441977, "No": 0.24508350212662827}, "ground_truth": 1}, {"key": "39109408", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.22269950983168293, "res": {"No": 0.7772976657712186, "Yes": 0.22269950983168293}, "ground_truth": 0}, {"key": "39109408", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.24508414488453484, "res": {"No": 0.7549123574722937, "Yes": 0.24508414488453484}, "ground_truth": 0}, {"key": "39109408", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.2942136744511435, "res": {"No": 0.7057818727202478, "Yes": 0.2942136744511435}, "ground_truth": 0}, {"key": "39109408", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.2689403152275393, "res": {"No": 0.731055550035914, "Yes": 0.2689403152275393}, "ground_truth": 0}, {"key": "39109408", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.22269924435333766, "res": {"No": 0.7772967854912433, "Yes": 0.22269924435333766}, "ground_truth": 0}, {"key": "39109408", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.2942136393781425, "res": {"No": 0.7057818306523713, "Yes": 0.2942136393781425}, "ground_truth": 1}, {"key": "20936833", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2450839988030444, "res": {"No": 0.754911885011471, "Yes": 0.2450839988030444}, "ground_truth": 0}, {"key": "20936833", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.3208197793269595, "res": {"No": 0.6791754984058547, "Yes": 0.3208197793269595}, "ground_truth": 0}, {"key": "20936833", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.3208200470399569, "res": {"No": 0.6791760044312222, "Yes": 0.3208200470399569}, "ground_truth": 0}, {"key": "20936833", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3208193203909121, "res": {"No": 0.679174506597228, "Yes": 0.3208193203909121}, "ground_truth": 0}, {"key": "20936833", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.37753913777997955, "res": {"No": 0.6224567884289806, "Yes": 0.37753913777997955}, "ground_truth": 0}, {"key": "20936833", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.2689396419645199, "res": {"No": 0.7310537634915357, "Yes": 0.2689396419645199}, "ground_truth": 1}, {"key": "36832879", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.32082046773226147, "res": {"No": 0.6791769355188836, "Yes": 0.32082046773226147}, "ground_truth": 0}, {"key": "36832879", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.679176105636341, "res": {"Yes": 0.679176105636341, "No": 0.3208200852846891}, "ground_truth": 0}, {"key": "36832879", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7310561818636294, "res": {"Yes": 0.7310561818636294, "No": 0.2689405396489203}, "ground_truth": 0}, {"key": "36832879", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7549120874946446, "res": {"Yes": 0.7549120874946446, "No": 0.24508408645192822}, "ground_truth": 0}, {"key": "36832879", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175711658867216, "res": {"Yes": 0.8175711658867216, "No": 0.1824247851770427}, "ground_truth": 0}, {"key": "36832879", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.777295997873163, "res": {"Yes": 0.777295997873163, "No": 0.2226990319708893}, "ground_truth": 1}, {"key": "14958201", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.32081989406107386, "res": {"No": 0.67917572105697, "Yes": 0.32081989406107386}, "ground_truth": 0}, {"key": "14958201", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4073313605477468, "res": {"No": 0.5926636325017227, "Yes": 0.4073313605477468}, "ground_truth": 0}, {"key": "14958201", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.3775387552277081, "res": {"No": 0.6224561762575714, "Yes": 0.3775387552277081}, "ground_truth": 0}, {"key": "14958201", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.2942135341591645, "res": {"No": 0.7057815361773057, "Yes": 0.2942135341591645}, "ground_truth": 0}, {"key": "14958201", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.377538710221584, "res": {"No": 0.6224561020550173, "Yes": 0.377538710221584}, "ground_truth": 0}, {"key": "14958201", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.3208196263482041, "res": {"No": 0.6791751745498174, "Yes": 0.3208196263482041}, "ground_truth": 1}, {"key": "34352262", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.22269924435333766, "res": {"No": 0.7772967159954982, "Yes": 0.22269924435333766}, "ground_truth": 0}, {"key": "34352262", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.3486431794188897, "res": {"No": 0.6513512299474368, "Yes": 0.3486431794188897}, "ground_truth": 0}, {"key": "34352262", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.24508385272164107, "res": {"No": 0.7549114125509441, "Yes": 0.24508385272164107}, "ground_truth": 0}, {"key": "34352262", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.2018123891939723, "res": {"No": 0.7981834591103469, "Yes": 0.2018123891939723}, "ground_truth": 0}, {"key": "34352262", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.26893871222312116, "res": {"No": 0.7310512144052866, "Yes": 0.26893871222312116}, "ground_truth": 0}, {"key": "34352262", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.2689403152275393, "res": {"No": 0.7310556153973765, "Yes": 0.2689403152275393}, "ground_truth": 1}, {"key": "39805395", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.46878815814133384, "res": {"No": 0.5312065762138992, "Yes": 0.46878815814133384}, "ground_truth": 0}, {"key": "39805395", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5926634205487289, "res": {"Yes": 0.5926634205487289, "No": 0.40733121487472657}, "ground_truth": 0}, {"key": "39805395", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7981820080606987, "res": {"Yes": 0.7981820080606987, "No": 0.20181202832562187}, "ground_truth": 0}, {"key": "39805395", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5926637738037608, "res": {"Yes": 0.5926637738037608, "No": 0.4073314576631226}, "ground_truth": 0}, {"key": "39805395", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5312069561625864, "res": {"Yes": 0.5312069561625864, "No": 0.46878849344487344}, "ground_truth": 0}, {"key": "39805395", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6513516375949305, "res": {"Yes": 0.6513516375949305, "No": 0.3486433872264803}, "ground_truth": 1}, {"key": "34303109", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4073321374714014, "res": {"No": 0.59266476291897, "Yes": 0.4073321374714014}, "ground_truth": 0}, {"key": "34303109", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8519489518273796, "res": {"Yes": 0.8519489518273796, "No": 0.14804652015325656}, "ground_truth": 0}, {"key": "34303109", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7310563779482039, "res": {"Yes": 0.7310563779482039, "No": 0.26894060376934925}, "ground_truth": 0}, {"key": "34303109", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312077160607761, "res": {"Yes": 0.5312077160607761, "No": 0.4687891640526722}, "ground_truth": 0}, {"key": "34303109", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175720430458927, "res": {"Yes": 0.8175720430458927, "No": 0.182424980897709}, "ground_truth": 0}, {"key": "34303109", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8670307086382284, "res": {"Yes": 0.8670307086382284, "No": 0.13296346557675034}, "ground_truth": 1}, {"key": "39939090", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.37753961034508543, "res": {"No": 0.6224575861077806, "Yes": 0.37753961034508543}, "ground_truth": 0}, {"key": "39939090", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.3775394078171105, "res": {"No": 0.6224572521956003, "Yes": 0.3775394078171105}, "ground_truth": 0}, {"key": "39939090", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.4687892758207319, "res": {"No": 0.5312078427105801, "Yes": 0.4687892758207319}, "ground_truth": 0}, {"key": "39939090", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224566585743889, "res": {"Yes": 0.6224566585743889, "No": 0.3775390477676455}, "ground_truth": 0}, {"key": "39939090", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224575861077806, "res": {"Yes": 0.6224575861077806, "No": 0.37753961034508543}, "ground_truth": 0}, {"key": "39939090", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7981839824403755, "res": {"Yes": 0.7981839824403755, "No": 0.20181250948356583}, "ground_truth": 1}, {"key": "29347771", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6513517540656899, "res": {"Yes": 0.6513517540656899, "No": 0.3486434703495512}, "ground_truth": 0}, {"key": "29347771", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513519481836685, "res": {"Yes": 0.6513519481836685, "No": 0.3486435534726419}, "ground_truth": 0}, {"key": "29347771", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224562875614192, "res": {"Yes": 0.6224562875614192, "No": 0.37753882273690426}, "ground_truth": 0}, {"key": "29347771", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7057817044487567, "res": {"Yes": 0.7057817044487567, "No": 0.29421360430514565}, "ground_truth": 0}, {"key": "29347771", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6513511328885473, "res": {"Yes": 0.6513511328885473, "No": 0.3486431378573865}, "ground_truth": 0}, {"key": "29347771", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7981834591103469, "res": {"Yes": 0.7981834591103469, "No": 0.2018123891939723}, "ground_truth": 1}, {"key": "36783415", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.20181262977323108, "res": {"No": 0.7981844463013694, "Yes": 0.20181262977323108}, "ground_truth": 0}, {"key": "36783415", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.20181270194706463, "res": {"No": 0.7981847436483023, "Yes": 0.20181270194706463}, "ground_truth": 0}, {"key": "36783415", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.24508414488453484, "res": {"No": 0.7549123574722937, "Yes": 0.24508414488453484}, "ground_truth": 0}, {"key": "36783415", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.18242502439121894, "res": {"No": 0.8175722014219545, "Yes": 0.18242502439121894}, "ground_truth": 0}, {"key": "36783415", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.22269916470989579, "res": {"No": 0.7772964380125801, "Yes": 0.22269916470989579}, "ground_truth": 0}, {"key": "36783415", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.1480467319356539, "res": {"No": 0.8519500689906342, "Yes": 0.1480467319356539}, "ground_truth": 1}, {"key": "37935687", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.22269945673598857, "res": {"No": 0.7772974341184968, "Yes": 0.22269945673598857}, "ground_truth": 0}, {"key": "37935687", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.3486436781573152, "res": {"No": 0.6513521423017049, "Yes": 0.3486436781573152}, "ground_truth": 0}, {"key": "37935687", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5926644803144561, "res": {"Yes": 0.5926644803144561, "No": 0.4073319432403488}, "ground_truth": 0}, {"key": "37935687", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3486440106499951, "res": {"No": 0.6513527634798101, "Yes": 0.3486440106499951}, "ground_truth": 0}, {"key": "37935687", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.2942138498162113, "res": {"No": 0.7057823565010085, "Yes": 0.2942138498162113}, "ground_truth": 0}, {"key": "37935687", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6513529575980895, "res": {"Yes": 0.6513529575980895, "No": 0.3486441353348319}, "ground_truth": 1}, {"key": "40260829", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.49999844932931325, "res": {"No": 0.49999844932931325, "Yes": 0.49999844932931325}, "ground_truth": 0}, {"key": "40260829", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981846722850283, "res": {"Yes": 0.7981846722850283, "No": 0.20181270194706463}, "ground_truth": 0}, {"key": "40260829", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7057828402821008, "res": {"Yes": 0.7057828402821008, "No": 0.29421406025443064}, "ground_truth": 0}, {"key": "40260829", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7057828402821008, "res": {"Yes": 0.7057828402821008, "No": 0.29421406025443064}, "ground_truth": 0}, {"key": "40260829", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175717262938613, "res": {"Yes": 0.8175717262938613, "No": 0.18242491565746358}, "ground_truth": 0}, {"key": "40260829", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310563125866733, "res": {"Yes": 0.7310563125866733, "No": 0.2689405717091329}, "ground_truth": 1}, {"key": "36478199", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7310544606790663, "res": {"Yes": 0.7310544606790663, "No": 0.2689398984454714}, "ground_truth": 0}, {"key": "36478199", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7549115475396359, "res": {"Yes": 0.7549115475396359, "No": 0.24508391115419195}, "ground_truth": 0}, {"key": "36478199", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.49999725724153593, "res": {"No": 0.49999725724153593, "Yes": 0.49999725724153593}, "ground_truth": 0}, {"key": "36478199", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6513508417119657, "res": {"Yes": 0.6513508417119657, "No": 0.34864297161142305}, "ground_truth": 0}, {"key": "36478199", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926631026193804, "res": {"Yes": 0.5926631026193804, "No": 0.40733099636529385}, "ground_truth": 0}, {"key": "36478199", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4073313119900676, "res": {"No": 0.5926635618507164, "Yes": 0.4073313119900676}, "ground_truth": 1}, {"key": "34541803", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.1066902107412151, "res": {"No": 0.8933062973576413, "Yes": 0.1066902107412151}, "ground_truth": 0}, {"key": "34541803", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.05340320939743957, "res": {"No": 0.9465946277016722, "Yes": 0.05340320939743957}, "ground_truth": 0}, {"key": "34541803", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.07585806297059312, "res": {"No": 0.9241402838438013, "Yes": 0.07585806297059312}, "ground_truth": 0}, {"key": "34541803", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.07585806297059312, "res": {"No": 0.9241402838438013, "Yes": 0.07585806297059312}, "ground_truth": 0}, {"key": "34541803", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.03308590182500773, "res": {"No": 0.9669118345204855, "Yes": 0.03308590182500773}, "ground_truth": 0}, {"key": "34541803", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.11920271354398539, "res": {"No": 0.8807954718968894, "Yes": 0.11920271354398539}, "ground_truth": 1}, {"key": "35360841", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.06008650557593084, "res": {"No": 0.9399110073983515, "Yes": 0.06008650557593084}, "ground_truth": 0}, {"key": "35360841", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5621732857781079, "res": {"Yes": 0.5621732857781079, "No": 0.4378209951858151}, "ground_truth": 0}, {"key": "35360841", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7549106476154798, "res": {"Yes": 0.7549106476154798, "No": 0.2450836189915768}, "ground_truth": 0}, {"key": "35360841", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7549118175170919, "res": {"Yes": 0.7549118175170919, "No": 0.24508396958675677}, "ground_truth": 0}, {"key": "35360841", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791751138268275, "res": {"Yes": 0.6791751138268275, "No": 0.3208195881035266}, "ground_truth": 0}, {"key": "35360841", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8807929781741116, "res": {"Yes": 0.8807929781741116, "No": 0.1192023725027742}, "ground_truth": 1}, {"key": "35550407", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.37753913777997955, "res": {"No": 0.6224567884289806, "Yes": 0.37753913777997955}, "ground_truth": 0}, {"key": "35550407", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7549114125509441, "res": {"Yes": 0.7549114125509441, "No": 0.24508385272164107}, "ground_truth": 0}, {"key": "35550407", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7549112775622764, "res": {"Yes": 0.7549112775622764, "No": 0.2450837942891041}, "ground_truth": 0}, {"key": "35550407", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8354799427758199, "res": {"Yes": 0.8354799427758199, "No": 0.1645157624859184}, "ground_truth": 0}, {"key": "35550407", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175703618249748, "res": {"Yes": 0.8175703618249748, "No": 0.18242461120329334}, "ground_truth": 0}, {"key": "35550407", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9241373300197865, "res": {"Yes": 0.9241373300197865, "No": 0.07585780976741349}, "ground_truth": 1}, {"key": "37561590", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.40733204035586357, "res": {"No": 0.5926646216166962, "Yes": 0.40733204035586357}, "ground_truth": 0}, {"key": "37561590", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6791761663594195, "res": {"Yes": 0.6791761663594195, "No": 0.32082012352942585}, "ground_truth": 0}, {"key": "37561590", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8933051592421195, "res": {"Yes": 0.8933051592421195, "No": 0.10669008355664866}, "ground_truth": 0}, {"key": "37561590", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8519499039550612, "res": {"Yes": 0.8519499039550612, "No": 0.14804669663856665}, "ground_truth": 0}, {"key": "37561590", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9046460237029159, "res": {"Yes": 0.9046460237029159, "No": 0.09534898229720824}, "ground_truth": 0}, {"key": "37561590", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.81757084913503, "res": {"Yes": 0.81757084913503, "No": 0.18242471993686724}, "ground_truth": 1}, {"key": "39328843", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.03308593337819758, "res": {"No": 0.9669127278236628, "Yes": 0.03308593337819758}, "ground_truth": 0}, {"key": "39328843", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.49999821091153046, "res": {"No": 0.49999821091153046, "Yes": 0.49999821091153046}, "ground_truth": 0}, {"key": "39328843", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772977352670486, "res": {"Yes": 0.7772977352670486, "No": 0.22269953637953485}, "ground_truth": 0}, {"key": "39328843", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7772975962753949, "res": {"Yes": 0.7772975962753949, "No": 0.22269948328383415}, "ground_truth": 0}, {"key": "39328843", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791761663594195, "res": {"Yes": 0.6791761663594195, "No": 0.32082012352942585}, "ground_truth": 0}, {"key": "39328843", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.754912829933412, "res": {"Yes": 0.754912829933412, "No": 0.24508432018243828}, "ground_truth": 1}, {"key": "35389665", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621745590888318, "res": {"Yes": 0.5621745590888318, "No": 0.43782198684120405}, "ground_truth": 0}, {"key": "35389665", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4378224304772368, "res": {"No": 0.5621751287287737, "Yes": 0.4378224304772368}, "ground_truth": 0}, {"key": "35389665", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7549130324168389, "res": {"Yes": 0.7549130324168389, "No": 0.24508437861510063}, "ground_truth": 0}, {"key": "35389665", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.499998628142725, "res": {"No": 0.499998628142725, "Yes": 0.499998628142725}, "ground_truth": 0}, {"key": "35389665", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4999987473517017, "res": {"No": 0.4999987473517017, "Yes": 0.4999987473517017}, "ground_truth": 0}, {"key": "35389665", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.26894086025121805, "res": {"No": 0.7310570751382278, "Yes": 0.26894086025121805}, "ground_truth": 1}, {"key": "33080187", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.03732675454214586, "res": {"No": 0.9626697593720553, "Yes": 0.03732675454214586}, "ground_truth": 0}, {"key": "33080187", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.20181258165735638, "res": {"No": 0.7981842203177746, "Yes": 0.20181258165735638}, "ground_truth": 0}, {"key": "33080187", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.2018124373098011, "res": {"No": 0.7981836850937263, "Yes": 0.2018124373098011}, "ground_truth": 0}, {"key": "33080187", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.18242482867050594, "res": {"No": 0.8175713973591893, "Yes": 0.18242482867050594}, "ground_truth": 0}, {"key": "33080187", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.18242463295000294, "res": {"No": 0.8175704471042136, "Yes": 0.18242463295000294}, "ground_truth": 0}, {"key": "33080187", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.22269924435333766, "res": {"No": 0.7772967854912433, "Yes": 0.22269924435333766}, "ground_truth": 1}, {"key": "38636995", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.26894044346830553, "res": {"No": 0.7310558768432849, "Yes": 0.26894044346830553}, "ground_truth": 0}, {"key": "38636995", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7310552232286893, "res": {"Yes": 0.7310552232286893, "No": 0.26894018698683425}, "ground_truth": 0}, {"key": "38636995", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7549116825283518, "res": {"Yes": 0.7549116825283518, "No": 0.24508394037047262}, "ground_truth": 0}, {"key": "38636995", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981834591103469, "res": {"Yes": 0.7981834591103469, "No": 0.2018123891939723}, "ground_truth": 0}, {"key": "38636995", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7981831498700368, "res": {"Yes": 0.7981831498700368, "No": 0.20181231702025057}, "ground_truth": 0}, {"key": "38636995", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310550489315625, "res": {"Yes": 0.7310550489315625, "No": 0.26894012286650465}, "ground_truth": 1}, {"key": "18536236", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2226992974489814, "res": {"No": 0.7772968781522464, "Yes": 0.2226992974489814}, "ground_truth": 0}, {"key": "18536236", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9148978738223053, "res": {"Yes": 0.9148978738223053, "No": 0.0850987641198204}, "ground_truth": 0}, {"key": "18536236", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8519492057279907, "res": {"Yes": 0.8519492057279907, "No": 0.1480465730988275}, "ground_truth": 0}, {"key": "18536236", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.867032323610276, "res": {"Yes": 0.867032323610276, "No": 0.13296371918467648}, "ground_truth": 0}, {"key": "18536236", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.79818383971397, "res": {"Yes": 0.79818383971397, "No": 0.2018124854256414}, "ground_truth": 0}, {"key": "18536236", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8519493834584634, "res": {"Yes": 0.8519493834584634, "No": 0.1480466083958853}, "ground_truth": 1}, {"key": "36289151", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621751622370236, "res": {"Yes": 0.5621751622370236, "No": 0.437822456573488}, "ground_truth": 0}, {"key": "36289151", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057822513312497, "res": {"Yes": 0.7057822513312497, "No": 0.2942138147431894}, "ground_truth": 0}, {"key": "36289151", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8933045868570835, "res": {"Yes": 0.8933045868570835, "No": 0.10669000724598159}, "ground_truth": 0}, {"key": "36289151", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791759437081583, "res": {"Yes": 0.6791759437081583, "No": 0.3208200087952293}, "ground_truth": 0}, {"key": "36289151", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.02297729619614643, "res": {"No": 0.9770195757690637, "Yes": 0.02297729619614643}, "ground_truth": 0}, {"key": "36289151", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9148973693999387, "res": {"Yes": 0.9148973693999387, "No": 0.0850987032524629}, "ground_truth": 1}, {"key": "23017045", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5926644449889013, "res": {"Yes": 0.5926644449889013, "No": 0.40733191896147375}, "ground_truth": 0}, {"key": "23017045", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.40733206463474586, "res": {"No": 0.5926646569422614, "Yes": 0.40733206463474586}, "ground_truth": 0}, {"key": "23017045", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5926648335701196, "res": {"Yes": 0.5926648335701196, "No": 0.40733218602917903}, "ground_truth": 0}, {"key": "23017045", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621744250559882, "res": {"Yes": 0.5621744250559882, "No": 0.4378218824563205}, "ground_truth": 0}, {"key": "23017045", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.05340319666512378, "res": {"No": 0.9465944125949699, "Yes": 0.05340319666512378}, "ground_truth": 0}, {"key": "23017045", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.40733204035586357, "res": {"No": 0.5926646216166962, "Yes": 0.40733204035586357}, "ground_truth": 1}, {"key": "36418082", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6224571594422487, "res": {"Yes": 0.6224571594422487, "No": 0.3775393628109086}, "ground_truth": 0}, {"key": "36418082", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513528605389426, "res": {"Yes": 0.6513528605389426, "No": 0.34864405221160244}, "ground_truth": 0}, {"key": "36418082", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621743245313765, "res": {"Yes": 0.5621743245313765, "No": 0.43782180416767413}, "ground_truth": 0}, {"key": "36418082", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791762675645624, "res": {"Yes": 0.6791762675645624, "No": 0.3208201617741671}, "ground_truth": 0}, {"key": "36418082", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.43782190855253905, "res": {"No": 0.5621744585641962, "Yes": 0.43782190855253905}, "ground_truth": 0}, {"key": "36418082", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5312077160607761, "res": {"Yes": 0.5312077160607761, "No": 0.4687891640526722}, "ground_truth": 1}, {"key": "34396551", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.16451591938045054, "res": {"No": 0.8354807769008635, "Yes": 0.16451591938045054}, "ground_truth": 0}, {"key": "34396551", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513514434770445, "res": {"Yes": 0.6513514434770445, "No": 0.3486433041034292}, "ground_truth": 0}, {"key": "34396551", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791736767176533, "res": {"Yes": 0.6791736767176533, "No": 0.3208189379447075}, "ground_truth": 0}, {"key": "34396551", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5926632085958109, "res": {"Yes": 0.5926632085958109, "No": 0.4073310692017584}, "ground_truth": 0}, {"key": "34396551", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926634205487289, "res": {"Yes": 0.5926634205487289, "No": 0.40733121487472657}, "ground_truth": 0}, {"key": "34396551", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5926634205487289, "res": {"Yes": 0.5926634205487289, "No": 0.40733121487472657}, "ground_truth": 1}, {"key": "39720944", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.43782227389976214, "res": {"No": 0.5621749276793165, "Yes": 0.43782227389976214}, "ground_truth": 0}, {"key": "39720944", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5621746931217074, "res": {"Yes": 0.5621746931217074, "No": 0.4378220912261125}, "ground_truth": 0}, {"key": "39720944", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5312074944236919, "res": {"Yes": 0.5312074944236919, "No": 0.46878896845863177}, "ground_truth": 0}, {"key": "39720944", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312074944236919, "res": {"Yes": 0.5312074944236919, "No": 0.46878896845863177}, "ground_truth": 0}, {"key": "39720944", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926646569422614, "res": {"Yes": 0.5926646569422614, "No": 0.40733206463474586}, "ground_truth": 0}, {"key": "39720944", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5926645156400129, "res": {"Yes": 0.5926645156400129, "No": 0.40733196751922535}, "ground_truth": 1}, {"key": "35884842", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4687886331547524, "res": {"No": 0.5312071144746197, "Yes": 0.4687886331547524}, "ground_truth": 0}, {"key": "35884842", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.37753790011226745, "res": {"No": 0.6224547664105556, "Yes": 0.37753790011226745}, "ground_truth": 0}, {"key": "35884842", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5312066395386615, "res": {"Yes": 0.5312066395386615, "No": 0.46878821402524046}, "ground_truth": 0}, {"key": "35884842", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.37753864271240783, "res": {"No": 0.6224559907512027, "Yes": 0.37753864271240783}, "ground_truth": 0}, {"key": "35884842", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.24508367742407197, "res": {"No": 0.7549108725964182, "Yes": 0.24508367742407197}, "ground_truth": 0}, {"key": "35884842", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5312068928377863, "res": {"Yes": 0.5312068928377863, "No": 0.4687884375609335}, "ground_truth": 1}, {"key": "35403375", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6224579942229107, "res": {"Yes": 0.6224579942229107, "No": 0.37753985787942457}, "ground_truth": 0}, {"key": "35403375", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981842203177746, "res": {"Yes": 0.7981842203177746, "No": 0.20181258165735638}, "ground_truth": 0}, {"key": "35403375", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6513528023034614, "res": {"Yes": 0.6513528023034614, "No": 0.34864405221160244}, "ground_truth": 0}, {"key": "35403375", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7549131674058205, "res": {"Yes": 0.7549131674058205, "No": 0.2450844370477769}, "ground_truth": 0}, {"key": "35403375", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310568136918909, "res": {"Yes": 0.7310568136918909, "No": 0.26894076407048856}, "ground_truth": 0}, {"key": "35403375", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057834923354019, "res": {"Yes": 0.7057834923354019, "No": 0.29421434083895726}, "ground_truth": 1}, {"key": "26341324", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3486441353348319, "res": {"No": 0.6513530158335846, "Yes": 0.3486441353348319}, "ground_truth": 0}, {"key": "26341324", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9241385487292499, "res": {"Yes": 0.9241385487292499, "No": 0.07585791828295842}, "ground_truth": 0}, {"key": "26341324", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772971561353219, "res": {"Yes": 0.7772971561353219, "No": 0.2226993505446378}, "ground_truth": 0}, {"key": "26341324", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7057819989238926, "res": {"Yes": 0.7057819989238926, "No": 0.2942137095241487}, "ground_truth": 0}, {"key": "26341324", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8354793576438236, "res": {"Yes": 0.8354793576438236, "No": 0.1645156448151175}, "ground_truth": 0}, {"key": "26341324", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310549182087447, "res": {"Yes": 0.7310549182087447, "No": 0.2689400587461903}, "ground_truth": 1}, {"key": "19212345", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.49999844932931325, "res": {"No": 0.49999844932931325, "Yes": 0.49999844932931325}, "ground_truth": 0}, {"key": "19212345", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8354786978146174, "res": {"Yes": 0.8354786978146174, "No": 0.1645155075326228}, "ground_truth": 0}, {"key": "19212345", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224561020550173, "res": {"Yes": 0.6224561020550173, "No": 0.377538710221584}, "ground_truth": 0}, {"key": "19212345", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7057813468719711, "res": {"Yes": 0.7057813468719711, "No": 0.2942134289402242}, "ground_truth": 0}, {"key": "19212345", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.777295997873163, "res": {"Yes": 0.777295997873163, "No": 0.2226990319708893}, "ground_truth": 0}, {"key": "19212345", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7981825432836226, "res": {"Yes": 0.7981825432836226, "No": 0.2018121486150003}, "ground_truth": 1}, {"key": "30548367", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3486437197188828, "res": {"No": 0.6513522587725544, "Yes": 0.3486437197188828}, "ground_truth": 0}, {"key": "30548367", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8933044936781588, "res": {"Yes": 0.8933044936781588, "No": 0.10669000724598159}, "ground_truth": 0}, {"key": "30548367", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.946591852476331, "res": {"Yes": 0.946591852476331, "No": 0.05340305660985048}, "ground_truth": 0}, {"key": "30548367", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621746931217074, "res": {"Yes": 0.5621746931217074, "No": 0.4378220912261125}, "ground_truth": 0}, {"key": "30548367", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8807932537957558, "res": {"Yes": 0.8807932537957558, "No": 0.11920240092283786}, "ground_truth": 0}, {"key": "30548367", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.798183756456912, "res": {"Yes": 0.798183756456912, "No": 0.20181246136771983}, "ground_truth": 1}, {"key": "37919402", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3775396778544346, "res": {"No": 0.6224577159625656, "Yes": 0.3775396778544346}, "ground_truth": 0}, {"key": "37919402", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8670319747760591, "res": {"Yes": 0.8670319747760591, "No": 0.1329636557826496}, "ground_truth": 0}, {"key": "37919402", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8354808640483042, "res": {"Yes": 0.8354808640483042, "No": 0.1645159389922776}, "ground_truth": 0}, {"key": "37919402", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7772970171437718, "res": {"Yes": 0.7772970171437718, "No": 0.222699323996808}, "ground_truth": 0}, {"key": "37919402", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8519499928203658, "res": {"Yes": 0.8519499928203658, "No": 0.14804671428710922}, "ground_truth": 0}, {"key": "37919402", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772975962753949, "res": {"Yes": 0.7772975962753949, "No": 0.22269948328383415}, "ground_truth": 1}, {"key": "39995133", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.40733204035586357, "res": {"No": 0.5926646216166962, "Yes": 0.40733204035586357}, "ground_truth": 0}, {"key": "39995133", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513523558316118, "res": {"Yes": 0.6513523558316118, "No": 0.348643802842033}, "ground_truth": 0}, {"key": "39995133", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772965075083003, "res": {"Yes": 0.7772965075083003, "No": 0.2226991912577066}, "ground_truth": 0}, {"key": "39995133", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621745590888318, "res": {"Yes": 0.5621745590888318, "No": 0.43782198684120405}, "ground_truth": 0}, {"key": "39995133", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926646922678288, "res": {"Yes": 0.5926646922678288, "No": 0.4073320889136296}, "ground_truth": 0}, {"key": "39995133", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057822933991513, "res": {"Yes": 0.7057822933991513, "No": 0.2942138147431894}, "ground_truth": 1}, {"key": "40249088", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4687891640526722, "res": {"No": 0.5312077160607761, "Yes": 0.4687891640526722}, "ground_truth": 0}, {"key": "40249088", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.08509890614382389, "res": {"No": 0.9148993666414792, "Yes": 0.08509890614382389}, "ground_truth": 0}, {"key": "40249088", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8807941725351927, "res": {"Yes": 0.8807941725351927, "No": 0.11920254302325782}, "ground_truth": 0}, {"key": "40249088", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9241387552903352, "res": {"Yes": 0.9241387552903352, "No": 0.07585793636889766}, "ground_truth": 0}, {"key": "40249088", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224569182835993, "res": {"Yes": 0.6224569182835993, "No": 0.3775392052892442}, "ground_truth": 0}, {"key": "40249088", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.754911885011471, "res": {"Yes": 0.754911885011471, "No": 0.2450839988030444}, "ground_truth": 1}, {"key": "40254388", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2689402831673573, "res": {"No": 0.7310554846744574, "Yes": 0.2689402831673573}, "ground_truth": 0}, {"key": "40254388", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4073315062208192, "res": {"No": 0.5926638444547924, "Yes": 0.4073315062208192}, "ground_truth": 0}, {"key": "40254388", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621736878759197, "res": {"Yes": 0.5621736878759197, "No": 0.4378213083399058}, "ground_truth": 0}, {"key": "40254388", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791749518988812, "res": {"Yes": 0.6791749518988812, "No": 0.32081951161418537}, "ground_truth": 0}, {"key": "40254388", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4999975552632138, "res": {"No": 0.4999975552632138, "Yes": 0.4999975552632138}, "ground_truth": 0}, {"key": "40254388", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6791749518988812, "res": {"Yes": 0.6791749518988812, "No": 0.32081951161418537}, "ground_truth": 1}, {"key": "31995230", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.37753909277380987, "res": {"No": 0.6224567327770094, "Yes": 0.37753909277380987}, "ground_truth": 0}, {"key": "31995230", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6224565472704748, "res": {"Yes": 0.6224565472704748, "No": 0.37753898025840904}, "ground_truth": 0}, {"key": "31995230", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.4378208125126989, "res": {"No": 0.5621730512211838, "Yes": 0.4378208125126989}, "ground_truth": 0}, {"key": "31995230", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981835304735124, "res": {"Yes": 0.7981835304735124, "No": 0.20181241325188526}, "ground_truth": 0}, {"key": "31995230", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224571037902444, "res": {"Yes": 0.6224571037902444, "No": 0.37753931780471206}, "ground_truth": 0}, {"key": "31995230", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8354803660630514, "res": {"Yes": 0.8354803660630514, "No": 0.1645158409331658}, "ground_truth": 1}, {"key": "38632129", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.10669028705202774, "res": {"No": 0.8933067765646107, "Yes": 0.10669028705202774}, "ground_truth": 0}, {"key": "38632129", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.13296394109200865, "res": {"No": 0.8670338481466493, "Yes": 0.13296394109200865}, "ground_truth": 0}, {"key": "38632129", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.14804680252985367, "res": {"No": 0.8519505133173358, "Yes": 0.14804680252985367}, "ground_truth": 0}, {"key": "38632129", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.10669041423683677, "res": {"No": 0.8933078215029212, "Yes": 0.10669041423683677}, "ground_truth": 0}, {"key": "38632129", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.13296397279308633, "res": {"No": 0.867033938585332, "Yes": 0.13296397279308633}, "ground_truth": 0}, {"key": "38632129", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.1480467319356539, "res": {"No": 0.851950157855956, "Yes": 0.1480467319356539}, "ground_truth": 1}, {"key": "35720795", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.29421430576587676, "res": {"No": 0.7057834292334433, "Yes": 0.29421430576587676}, "ground_truth": 0}, {"key": "35720795", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5621746261052657, "res": {"Yes": 0.5621746261052657, "No": 0.43782203903365513}, "ground_truth": 0}, {"key": "35720795", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224574006009916, "res": {"Yes": 0.6224574006009916, "No": 0.3775394978295304}, "ground_truth": 0}, {"key": "35720795", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224572892969449, "res": {"Yes": 0.6224572892969449, "No": 0.3775394303202135}, "ground_truth": 0}, {"key": "35720795", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7549129649223573, "res": {"Yes": 0.7549129649223573, "No": 0.24508434939876772}, "ground_truth": 0}, {"key": "35720795", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.3775395428357484, "res": {"No": 0.6224574748037005, "Yes": 0.3775395428357484}, "ground_truth": 1}, {"key": "23906759", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2942140251813836, "res": {"No": 0.7057827140783056, "Yes": 0.2942140251813836}, "ground_truth": 0}, {"key": "23906759", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.43782169978283414, "res": {"No": 0.5621741904985889, "Yes": 0.43782169978283414}, "ground_truth": 0}, {"key": "23906759", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.26894044346830553, "res": {"No": 0.731055920417612, "Yes": 0.26894044346830553}, "ground_truth": 0}, {"key": "23906759", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.2942139901083408, "res": {"No": 0.7057826509764165, "Yes": 0.2942139901083408}, "ground_truth": 0}, {"key": "23906759", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3208199705505063, "res": {"No": 0.6791758829850997, "Yes": 0.3208199705505063}, "ground_truth": 0}, {"key": "23906759", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.22269937709247073, "res": {"No": 0.7772972256311064, "Yes": 0.22269937709247073}, "ground_truth": 1}, {"key": "19410108", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4999983301204076, "res": {"No": 0.4999983301204076, "Yes": 0.4999983301204076}, "ground_truth": 0}, {"key": "19410108", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4999983897248569, "res": {"No": 0.4999983897248569, "Yes": 0.4999983897248569}, "ground_truth": 0}, {"key": "19410108", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6513521034780929, "res": {"Yes": 0.6513521034780929, "No": 0.3486436365957525}, "ground_truth": 0}, {"key": "19410108", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4378220912261125, "res": {"No": 0.5621746931217074, "Yes": 0.4378220912261125}, "ground_truth": 0}, {"key": "19410108", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224577530639378, "res": {"Yes": 0.6224577530639378, "No": 0.37753972286067405}, "ground_truth": 0}, {"key": "19410108", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4687890522846391, "res": {"No": 0.5312075894110023, "Yes": 0.4687890522846391}, "ground_truth": 1}, {"key": "30745137", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.20181250948356583, "res": {"No": 0.7981839824403755, "Yes": 0.20181250948356583}, "ground_truth": 0}, {"key": "30745137", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.3208198175716597, "res": {"No": 0.6791755591288788, "Yes": 0.3208198175716597}, "ground_truth": 0}, {"key": "30745137", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.20181267788911725, "res": {"No": 0.7981846009217607, "Yes": 0.20181267788911725}, "ground_truth": 0}, {"key": "30745137", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3208201617741671, "res": {"No": 0.6791762675645624, "Yes": 0.3208201617741671}, "ground_truth": 0}, {"key": "30745137", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3775388677430418, "res": {"No": 0.6224563617639954, "Yes": 0.3775388677430418}, "ground_truth": 0}, {"key": "30745137", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4999976148675707, "res": {"No": 0.4999976148675707, "Yes": 0.4999976148675707}, "ground_truth": 1}, {"key": "26553115", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.13296381428777349, "res": {"No": 0.8670330471187292, "Yes": 0.13296381428777349}, "ground_truth": 0}, {"key": "26553115", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8807915869423668, "res": {"Yes": 0.8807915869423668, "No": 0.11920217356251826}, "ground_truth": 0}, {"key": "26553115", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.754911885011471, "res": {"Yes": 0.754911885011471, "No": 0.2450839988030444}, "ground_truth": 0}, {"key": "26553115", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.731055920417612, "res": {"Yes": 0.731055920417612, "No": 0.26894044346830553}, "ground_truth": 0}, {"key": "26553115", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8519486852318195, "res": {"Yes": 0.8519486852318195, "No": 0.1480464848562198}, "ground_truth": 0}, {"key": "26553115", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9148918821205404, "res": {"Yes": 0.9148918821205404, "No": 0.08509819602617673}, "ground_truth": 1}, {"key": "37872311", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.11920277038428212, "res": {"No": 0.8807960231418248, "Yes": 0.11920277038428212}, "ground_truth": 0}, {"key": "37872311", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5621740899740191, "res": {"Yes": 0.5621740899740191, "No": 0.4378216214942205}, "ground_truth": 0}, {"key": "37872311", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8670310703917056, "res": {"Yes": 0.8670310703917056, "No": 0.13296352897868652}, "ground_truth": 0}, {"key": "37872311", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7057811154988535, "res": {"Yes": 0.7057811154988535, "No": 0.2942133237213215}, "ground_truth": 0}, {"key": "37872311", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057815782451646, "res": {"Yes": 0.7057815782451646, "No": 0.2942135341591645}, "ground_truth": 0}, {"key": "37872311", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7981826979036452, "res": {"Yes": 0.7981826979036452, "No": 0.20181219673077175}, "ground_truth": 1}, {"key": "35553131", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621752292535293, "res": {"Yes": 0.5621752292535293, "No": 0.43782250876599516}, "ground_truth": 0}, {"key": "35553131", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057831347577106, "res": {"Yes": 0.7057831347577106, "No": 0.29421416547359674}, "ground_truth": 0}, {"key": "35553131", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772975962753949, "res": {"Yes": 0.7772975962753949, "No": 0.22269948328383415}, "ground_truth": 0}, {"key": "35553131", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981848269054633, "res": {"Yes": 0.7981848269054633, "No": 0.20181272600501488}, "ground_truth": 0}, {"key": "35553131", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224572892969449, "res": {"Yes": 0.6224572892969449, "No": 0.3775394303202135}, "ground_truth": 0}, {"key": "35553131", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057828402821008, "res": {"Yes": 0.7057828402821008, "No": 0.29421406025443064}, "ground_truth": 1}, {"key": "39038936", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.43782235218849247, "res": {"No": 0.5621750282040362, "Yes": 0.43782235218849247}, "ground_truth": 0}, {"key": "39038936", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.3486440106499951, "res": {"No": 0.6513527634798101, "Yes": 0.3486440106499951}, "ground_truth": 0}, {"key": "39038936", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.622457215094258, "res": {"Yes": 0.622457215094258, "No": 0.3775393853140089}, "ground_truth": 0}, {"key": "39038936", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791769355188836, "res": {"Yes": 0.6791769355188836, "No": 0.32082046773226147}, "ground_truth": 0}, {"key": "39038936", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6513530158335846, "res": {"Yes": 0.6513530158335846, "No": 0.3486441353348319}, "ground_truth": 0}, {"key": "39038936", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8670336672693123, "res": {"Yes": 0.8670336672693123, "No": 0.13296390939093852}, "ground_truth": 1}, {"key": "38735486", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.09534934602540406, "res": {"No": 0.9046493398569447, "Yes": 0.09534934602540406}, "ground_truth": 0}, {"key": "38735486", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.060086591530428016, "res": {"No": 0.9399123764629193, "Yes": 0.060086591530428016}, "ground_truth": 0}, {"key": "38735486", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.02931220488217661, "res": {"No": 0.9706868728020707, "Yes": 0.02931220488217661}, "ground_truth": 0}, {"key": "38735486", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.08509894672215414, "res": {"No": 0.9148998642484117, "Yes": 0.08509894672215414}, "ground_truth": 0}, {"key": "38735486", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.04208767985047811, "res": {"No": 0.9579112566337624, "Yes": 0.04208767985047811}, "ground_truth": 0}, {"key": "38735486", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.03732684353616975, "res": {"No": 0.9626720760757507, "Yes": 0.03732684353616975}, "ground_truth": 1}, {"key": "17087845", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.34864405221160244, "res": {"No": 0.6513528605389426, "Yes": 0.34864405221160244}, "ground_truth": 0}, {"key": "17087845", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.592664268361159, "res": {"Yes": 0.592664268361159, "No": 0.4073317975671202}, "ground_truth": 0}, {"key": "17087845", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.67917572105697, "res": {"Yes": 0.67917572105697, "No": 0.32081989406107386}, "ground_truth": 0}, {"key": "17087845", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8807929781741116, "res": {"Yes": 0.8807929781741116, "No": 0.1192023725027742}, "ground_truth": 0}, {"key": "17087845", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926637031527375, "res": {"Yes": 0.5926637031527375, "No": 0.4073314091054318}, "ground_truth": 0}, {"key": "17087845", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8670321427332571, "res": {"Yes": 0.8670321427332571, "No": 0.13296368748365925}, "ground_truth": 1}, {"key": "37443011", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.377539812873169, "res": {"No": 0.6224579385708318, "Yes": 0.377539812873169}, "ground_truth": 0}, {"key": "37443011", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8670328662415593, "res": {"Yes": 0.8670328662415593, "No": 0.1329637825867336}, "ground_truth": 0}, {"key": "37443011", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8519492057279907, "res": {"Yes": 0.8519492057279907, "No": 0.1480465730988275}, "ground_truth": 0}, {"key": "37443011", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4687886890387157, "res": {"No": 0.5312071777994462, "Yes": 0.4687886890387157}, "ground_truth": 0}, {"key": "37443011", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8670314321453338, "res": {"Yes": 0.8670314321453338, "No": 0.13296356067966597}, "ground_truth": 0}, {"key": "37443011", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8175718846698616, "res": {"Yes": 0.8175718846698616, "No": 0.18242493740420945}, "ground_truth": 1}, {"key": "36855749", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.37753972286067405, "res": {"No": 0.6224577530639378, "Yes": 0.37753972286067405}, "ground_truth": 0}, {"key": "36855749", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.798183756456912, "res": {"Yes": 0.798183756456912, "No": 0.20181246136771983}, "ground_truth": 0}, {"key": "36855749", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621743245313765, "res": {"Yes": 0.5621743245313765, "No": 0.43782180416767413}, "ground_truth": 0}, {"key": "36855749", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312073044491218, "res": {"Yes": 0.5312073044491218, "No": 0.46878880080666213}, "ground_truth": 0}, {"key": "36855749", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057822513312497, "res": {"Yes": 0.7057822513312497, "No": 0.2942138147431894}, "ground_truth": 0}, {"key": "36855749", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7549121549890477, "res": {"Yes": 0.7549121549890477, "No": 0.24508408645192822}, "ground_truth": 1}, {"key": "35613141", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3775387552277081, "res": {"No": 0.6224561762575714, "Yes": 0.3775387552277081}, "ground_truth": 0}, {"key": "35613141", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.294212902846087, "res": {"No": 0.7057801058715913, "Yes": 0.294212902846087}, "ground_truth": 0}, {"key": "35613141", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.3486431378573865, "res": {"No": 0.6513510940649956, "Yes": 0.3486431378573865}, "ground_truth": 0}, {"key": "35613141", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4378209951858151, "res": {"No": 0.5621732857781079, "Yes": 0.4378209951858151}, "ground_truth": 0}, {"key": "35613141", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4378209429934884, "res": {"No": 0.5621732187618338, "Yes": 0.4378209429934884}, "ground_truth": 0}, {"key": "35613141", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.22269855411112108, "res": {"No": 0.7772942836483352, "Yes": 0.22269855411112108}, "ground_truth": 1}, {"key": "39088847", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.20181270194706463, "res": {"No": 0.7981847436483023, "Yes": 0.20181270194706463}, "ground_truth": 0}, {"key": "39088847", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5312067978506004, "res": {"Yes": 0.5312067978506004, "No": 0.46878835373503613}, "ground_truth": 0}, {"key": "39088847", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.4073316033362297, "res": {"No": 0.592663985756881, "Yes": 0.4073316033362297}, "ground_truth": 0}, {"key": "39088847", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.43782180416767413, "res": {"No": 0.5621743245313765, "Yes": 0.43782180416767413}, "ground_truth": 0}, {"key": "39088847", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3486436365957525, "res": {"No": 0.6513520452426794, "Yes": 0.3486436365957525}, "ground_truth": 0}, {"key": "39088847", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.49999803209826793, "res": {"No": 0.49999803209826793, "Yes": 0.49999803209826793}, "ground_truth": 1}, {"key": "33197277", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6513523558316118, "res": {"Yes": 0.6513523558316118, "No": 0.348643802842033}, "ground_truth": 0}, {"key": "33197277", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513522975961756, "res": {"Yes": 0.6513522975961756, "No": 0.34864376128045543}, "ground_truth": 0}, {"key": "33197277", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224572521956003, "res": {"Yes": 0.6224572521956003, "No": 0.3775394078171105}, "ground_truth": 0}, {"key": "33197277", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224574748037005, "res": {"Yes": 0.6224574748037005, "No": 0.3775395428357484}, "ground_truth": 0}, {"key": "33197277", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5621747601381573, "res": {"Yes": 0.5621747601381573, "No": 0.43782214341857606}, "ground_truth": 0}, {"key": "33197277", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.79818383971397, "res": {"Yes": 0.79818383971397, "No": 0.2018124854256414}, "ground_truth": 1}, {"key": "33815489", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.705782188229402, "res": {"Yes": 0.705782188229402, "No": 0.29421377967017165}, "ground_truth": 0}, {"key": "33815489", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8354791086516091, "res": {"Yes": 0.8354791086516091, "No": 0.1645155859797486}, "ground_truth": 0}, {"key": "33815489", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791756603339313, "res": {"Yes": 0.6791756603339313, "No": 0.3208198558163645}, "ground_truth": 0}, {"key": "33815489", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981825432836226, "res": {"Yes": 0.7981825432836226, "No": 0.2018121486150003}, "ground_truth": 0}, {"key": "33815489", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175706907592302, "res": {"Yes": 0.8175706907592302, "No": 0.1824246764434299}, "ground_truth": 0}, {"key": "33815489", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9241374333001872, "res": {"Yes": 0.9241374333001872, "No": 0.07585782785332686}, "ground_truth": 1}, {"key": "35862754", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.37753979037004326, "res": {"No": 0.6224578829187577, "Yes": 0.37753979037004326}, "ground_truth": 0}, {"key": "35862754", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.731055920417612, "res": {"Yes": 0.731055920417612, "No": 0.26894044346830553}, "ground_truth": 0}, {"key": "35862754", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5926646922678288, "res": {"Yes": 0.5926646922678288, "No": 0.4073320889136296}, "ground_truth": 0}, {"key": "35862754", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8933062041785383, "res": {"Yes": 0.8933062041785383, "No": 0.1066902107412151}, "ground_truth": 0}, {"key": "35862754", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8670328662415593, "res": {"Yes": 0.8670328662415593, "No": 0.1329637825867336}, "ground_truth": 0}, {"key": "35862754", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.705783260961581, "res": {"Yes": 0.705783260961581, "No": 0.2942142356197284}, "ground_truth": 1}, {"key": "36080615", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7057829454519473, "res": {"Yes": 0.7057829454519473, "No": 0.29421409532748183}, "ground_truth": 0}, {"key": "36080615", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981834591103469, "res": {"Yes": 0.7981834591103469, "No": 0.2018123891939723}, "ground_truth": 0}, {"key": "36080615", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9525694989978181, "res": {"Yes": 0.9525694989978181, "No": 0.04742564842532379}, "ground_truth": 0}, {"key": "36080615", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8354804407608204, "res": {"Yes": 0.8354804407608204, "No": 0.16451586054498346}, "ground_truth": 0}, {"key": "36080615", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7772968781522464, "res": {"Yes": 0.7772968781522464, "No": 0.2226992974489814}, "ground_truth": 0}, {"key": "36080615", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057822933991513, "res": {"Yes": 0.7057822933991513, "No": 0.2942138147431894}, "ground_truth": 1}, {"key": "22822742", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4687890522846391, "res": {"No": 0.5312075894110023, "Yes": 0.4687890522846391}, "ground_truth": 0}, {"key": "22822742", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057821251275599, "res": {"Yes": 0.7057821251275599, "No": 0.2942137445971581}, "ground_truth": 0}, {"key": "22822742", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.705783260961581, "res": {"Yes": 0.705783260961581, "No": 0.2942142356197284}, "ground_truth": 0}, {"key": "22822742", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8354808640483042, "res": {"Yes": 0.8354808640483042, "No": 0.1645159389922776}, "ground_truth": 0}, {"key": "22822742", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791769355188836, "res": {"Yes": 0.6791769355188836, "No": 0.32082046773226147}, "ground_truth": 0}, {"key": "22822742", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5312074310988276, "res": {"Yes": 0.5312074310988276, "No": 0.46878891257463523}, "ground_truth": 1}, {"key": "39747536", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.09534911869511907, "res": {"No": 0.9046472975899159, "Yes": 0.09534911869511907}, "ground_truth": 0}, {"key": "39747536", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.08509874383069639, "res": {"No": 0.9148977715745058, "Yes": 0.08509874383069639}, "ground_truth": 0}, {"key": "39747536", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.18242482867050594, "res": {"No": 0.8175713973591893, "Yes": 0.18242482867050594}, "ground_truth": 0}, {"key": "39747536", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.14804671428710922, "res": {"No": 0.8519499928203658, "Yes": 0.14804671428710922}, "ground_truth": 0}, {"key": "39747536", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.22269916470989579, "res": {"No": 0.7772964380125801, "Yes": 0.22269916470989579}, "ground_truth": 0}, {"key": "39747536", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.18242487216397957, "res": {"No": 0.8175715679178915, "Yes": 0.18242487216397957}, "ground_truth": 1}, {"key": "34218396", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6791763282876553, "res": {"Yes": 0.6791763282876553, "No": 0.3208202000189129}, "ground_truth": 0}, {"key": "34218396", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8175717262938613, "res": {"Yes": 0.8175717262938613, "No": 0.18242491565746358}, "ground_truth": 0}, {"key": "34218396", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.817571482638536, "res": {"Yes": 0.817571482638536, "No": 0.18242485041724146}, "ground_truth": 0}, {"key": "34218396", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8175717993904731, "res": {"Yes": 0.8175717993904731, "No": 0.18242493740420945}, "ground_truth": 0}, {"key": "34218396", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310556807588449, "res": {"Yes": 0.7310556807588449, "No": 0.2689403472877251}, "ground_truth": 0}, {"key": "34218396", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6224571037902444, "res": {"Yes": 0.6224571037902444, "No": 0.37753931780471206}, "ground_truth": 1}, {"key": "39150388", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2689402511071791, "res": {"No": 0.7310553539515616, "Yes": 0.2689402511071791}, "ground_truth": 0}, {"key": "39150388", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057789700426478, "res": {"Yes": 0.7057789700426478, "No": 0.2942124468985956}, "ground_truth": 0}, {"key": "39150388", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.67917572105697, "res": {"Yes": 0.67917572105697, "No": 0.32081989406107386}, "ground_truth": 0}, {"key": "39150388", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.679174729248018, "res": {"Yes": 0.679174729248018, "No": 0.3208194351248624}, "ground_truth": 0}, {"key": "39150388", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5312049930972943, "res": {"Yes": 0.5312049930972943, "No": 0.46878676104583367}, "ground_truth": 0}, {"key": "39150388", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8354786106674027, "res": {"Yes": 0.8354786106674027, "No": 0.1645154879208472}, "ground_truth": 1}, {"key": "28765782", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7057831347577106, "res": {"Yes": 0.7057831347577106, "No": 0.29421416547359674}, "ground_truth": 0}, {"key": "28765782", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7772974341184968, "res": {"Yes": 0.7772974341184968, "No": 0.22269945673598857}, "ground_truth": 0}, {"key": "28765782", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8807942644091891, "res": {"Yes": 0.8807942644091891, "No": 0.11920254302325782}, "ground_truth": 0}, {"key": "28765782", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8354812748863611, "res": {"Yes": 0.8354812748863611, "No": 0.1645160174396091}, "ground_truth": 0}, {"key": "28765782", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.851950246721287, "res": {"Yes": 0.851950246721287, "No": 0.1480467495842007}, "ground_truth": 0}, {"key": "28765782", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310561165021163, "res": {"Yes": 0.7310561165021163, "No": 0.2689405075887116}, "ground_truth": 1}, {"key": "35828022", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.222699323996808, "res": {"No": 0.7772970171437718, "Yes": 0.222699323996808}, "ground_truth": 0}, {"key": "35828022", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.46878838167700027, "res": {"No": 0.5312068295129938, "Yes": 0.46878838167700027}, "ground_truth": 0}, {"key": "35828022", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5312071777994462, "res": {"Yes": 0.5312071777994462, "No": 0.4687886890387157}, "ground_truth": 0}, {"key": "35828022", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3775387552277081, "res": {"No": 0.6224561762575714, "Yes": 0.3775387552277081}, "ground_truth": 0}, {"key": "35828022", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.24508402801933554, "res": {"No": 0.7549119525058562, "Yes": 0.24508402801933554}, "ground_truth": 0}, {"key": "35828022", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8175710075108604, "res": {"Yes": 0.8175710075108604, "No": 0.1824247416835898}, "ground_truth": 1}, {"key": "27717735", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621745590888318, "res": {"Yes": 0.5621745590888318, "No": 0.43782198684120405}, "ground_truth": 0}, {"key": "27717735", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5312073994363983, "res": {"Yes": 0.5312073994363983, "No": 0.46878888463263946}, "ground_truth": 0}, {"key": "27717735", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8175709222315634, "res": {"Yes": 0.8175709222315634, "No": 0.18242471993686724}, "ground_truth": 0}, {"key": "27717735", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7057825458066138, "res": {"Yes": 0.7057825458066138, "No": 0.2942139550353022}, "ground_truth": 0}, {"key": "27717735", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8354811130410419, "res": {"Yes": 0.8354811130410419, "No": 0.1645159782159387}, "ground_truth": 0}, {"key": "27717735", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8354803660630514, "res": {"Yes": 0.8354803660630514, "No": 0.1645158409331658}, "ground_truth": 1}, {"key": "37977826", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.40733165189394366, "res": {"No": 0.5926640564079378, "Yes": 0.40733165189394366}, "ground_truth": 0}, {"key": "37977826", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6224571037902444, "res": {"Yes": 0.6224571037902444, "No": 0.37753931780471206}, "ground_truth": 0}, {"key": "37977826", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5312067028634314, "res": {"Yes": 0.5312067028634314, "No": 0.46878826990915373}, "ground_truth": 0}, {"key": "37977826", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621736878759197, "res": {"Yes": 0.5621736878759197, "No": 0.4378213083399058}, "ground_truth": 0}, {"key": "37977826", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.46878829785111287, "res": {"No": 0.5312067345258192, "Yes": 0.46878829785111287}, "ground_truth": 0}, {"key": "37977826", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6224562875614192, "res": {"Yes": 0.6224562875614192, "No": 0.37753882273690426}, "ground_truth": 1}, {"key": "31768588", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6513524528906834, "res": {"Yes": 0.6513524528906834, "No": 0.3486438444036155}, "ground_truth": 0}, {"key": "31768588", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9465935592213209, "res": {"Yes": 0.9465935592213209, "No": 0.053403158468194635}, "ground_truth": 0}, {"key": "31768588", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8933065835506615, "res": {"Yes": 0.8933065835506615, "No": 0.10669026161508413}, "ground_truth": 0}, {"key": "31768588", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8807935294174862, "res": {"Yes": 0.8807935294174862, "No": 0.1192024293429083}, "ground_truth": 0}, {"key": "31768588", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9046477828806735, "res": {"Yes": 0.9046477828806735, "No": 0.0953491641611327}, "ground_truth": 0}, {"key": "31768588", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7549117500227189, "res": {"Yes": 0.7549117500227189, "No": 0.24508396958675677}, "ground_truth": 1}, {"key": "37183351", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.43782096908965096, "res": {"No": 0.5621732522699698, "Yes": 0.43782096908965096}, "ground_truth": 0}, {"key": "37183351", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9525669014276872, "res": {"Yes": 0.9525669014276872, "No": 0.04742551273964936}, "ground_truth": 0}, {"key": "37183351", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9148949768057446, "res": {"Yes": 0.9148949768057446, "No": 0.0850984800725245}, "ground_truth": 0}, {"key": "37183351", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9046457338770236, "res": {"Yes": 0.9046457338770236, "No": 0.09534895956424208}, "ground_truth": 0}, {"key": "37183351", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9241360011463275, "res": {"Yes": 0.9241360011463275, "No": 0.07585770125202379}, "ground_truth": 0}, {"key": "37183351", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9465912106845897, "res": {"Yes": 0.9465912106845897, "No": 0.05340301841302151}, "ground_truth": 1}, {"key": "39622090", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6224575861077806, "res": {"Yes": 0.6224575861077806, "No": 0.37753961034508543}, "ground_truth": 0}, {"key": "39622090", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4687891361106614, "res": {"No": 0.5312076843983299, "Yes": 0.4687891361106614}, "ground_truth": 0}, {"key": "39622090", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.49999844932931325, "res": {"No": 0.49999844932931325, "Yes": 0.49999844932931325}, "ground_truth": 0}, {"key": "39622090", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3486439275267954, "res": {"No": 0.6513526081852282, "Yes": 0.3486439275267954}, "ground_truth": 0}, {"key": "39622090", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057815782451646, "res": {"Yes": 0.7057815782451646, "No": 0.2942135341591645}, "ground_truth": 0}, {"key": "39622090", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4073321374714014, "res": {"No": 0.59266476291897, "Yes": 0.4073321374714014}, "ground_truth": 1}, {"key": "39272756", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4073316761728028, "res": {"No": 0.5926640917334695, "Yes": 0.4073316761728028}, "ground_truth": 0}, {"key": "39272756", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513516375949305, "res": {"Yes": 0.6513516375949305, "No": 0.3486433872264803}, "ground_truth": 0}, {"key": "39272756", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224567327770094, "res": {"Yes": 0.6224567327770094, "No": 0.37753909277380987}, "ground_truth": 0}, {"key": "39272756", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4999979724938613, "res": {"No": 0.4999979724938613, "Yes": 0.4999979724938613}, "ground_truth": 0}, {"key": "39272756", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926632085958109, "res": {"Yes": 0.5926632085958109, "No": 0.4073310692017584}, "ground_truth": 0}, {"key": "39272756", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6791753972008264, "res": {"Yes": 0.6791753972008264, "No": 0.3208197410822638}, "ground_truth": 1}, {"key": "32138822", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3486435119110941, "res": {"No": 0.651351851124672, "Yes": 0.3486435119110941}, "ground_truth": 0}, {"key": "32138822", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8807921381848708, "res": {"Yes": 0.8807921381848708, "No": 0.1192022588225873}, "ground_truth": 0}, {"key": "32138822", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8933065835506615, "res": {"Yes": 0.8933065835506615, "No": 0.10669026161508413}, "ground_truth": 0}, {"key": "32138822", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7549120200002474, "res": {"Yes": 0.7549120200002474, "No": 0.24508405723563015}, "ground_truth": 0}, {"key": "32138822", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9399086929484639, "res": {"Yes": 0.9399086929484639, "No": 0.06008634799300537}, "ground_truth": 0}, {"key": "32138822", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9148965718678455, "res": {"Yes": 0.9148965718678455, "No": 0.08509864238514891}, "ground_truth": 1}, {"key": "31070114", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4687875434188008, "res": {"No": 0.5312058796420118, "Yes": 0.4687875434188008}, "ground_truth": 0}, {"key": "31070114", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.34864293004994457, "res": {"No": 0.6513507252413694, "Yes": 0.34864293004994457}, "ground_truth": 0}, {"key": "31070114", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.437820525455099, "res": {"No": 0.5621726826319293, "Yes": 0.437820525455099}, "ground_truth": 0}, {"key": "31070114", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3775360098639558, "res": {"No": 0.6224516499179573, "Yes": 0.3775360098639558}, "ground_truth": 0}, {"key": "31070114", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.46878514042026964, "res": {"No": 0.5312031566879435, "Yes": 0.46878514042026964}, "ground_truth": 0}, {"key": "31070114", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.37753612237847134, "res": {"No": 0.6224518354230324, "Yes": 0.37753612237847134}, "ground_truth": 1}, {"key": "39652762", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3775394078171105, "res": {"No": 0.6224572521956003, "Yes": 0.3775394078171105}, "ground_truth": 0}, {"key": "39652762", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5621738219085876, "res": {"Yes": 0.5621738219085876, "No": 0.43782141272465247}, "ground_truth": 0}, {"key": "39652762", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8519499928203658, "res": {"Yes": 0.8519499928203658, "No": 0.14804671428710922}, "ground_truth": 0}, {"key": "39652762", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.468788772864673, "res": {"No": 0.5312072727867, "Yes": 0.468788772864673}, "ground_truth": 0}, {"key": "39652762", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.2689405717091329, "res": {"No": 0.7310563125866733, "Yes": 0.2689405717091329}, "ground_truth": 0}, {"key": "39652762", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8519495611889732, "res": {"Yes": 0.8519495611889732, "No": 0.14804662604441737}, "ground_truth": 1}, {"key": "33258866", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.43782263924729015, "res": {"No": 0.5621753967948284, "Yes": 0.43782263924729015}, "ground_truth": 0}, {"key": "33258866", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8933074421302722, "res": {"Yes": 0.8933074421302722, "No": 0.10669036336289496}, "ground_truth": 0}, {"key": "33258866", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791771986525844, "res": {"Yes": 0.6791771986525844, "No": 0.3208205824666221}, "ground_truth": 0}, {"key": "33258866", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.817572359798047, "res": {"Yes": 0.817572359798047, "No": 0.1824250461379778}, "ground_truth": 0}, {"key": "33258866", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.867033576830658, "res": {"Yes": 0.867033576830658, "No": 0.13296390939093852}, "ground_truth": 0}, {"key": "33258866", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310571404998266, "res": {"Yes": 0.7310571404998266, "No": 0.26894089231146884}, "ground_truth": 1}, {"key": "36962388", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.43782240438098713, "res": {"No": 0.5621750952205259, "Yes": 0.43782240438098713}, "ground_truth": 0}, {"key": "36962388", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8670334088731821, "res": {"Yes": 0.8670334088731821, "No": 0.13296387768987597}, "ground_truth": 0}, {"key": "36962388", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.731056051140609, "res": {"Yes": 0.731056051140609, "No": 0.2689405075887116}, "ground_truth": 0}, {"key": "36962388", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.754912829933412, "res": {"Yes": 0.754912829933412, "No": 0.24508432018243828}, "ground_truth": 0}, {"key": "36962388", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791760449132679, "res": {"Yes": 0.6791760449132679, "No": 0.3208200470399569}, "ground_truth": 0}, {"key": "36962388", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7981840656974571, "res": {"Yes": 0.7981840656974571, "No": 0.20181253354149314}, "ground_truth": 1}, {"key": "32282272", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.14804682017840887, "res": {"No": 0.8519505894876508, "Yes": 0.14804682017840887}, "ground_truth": 0}, {"key": "32282272", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.622457215094258, "res": {"Yes": 0.622457215094258, "No": 0.3775393853140089}, "ground_truth": 0}, {"key": "32282272", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9046476817784108, "res": {"Yes": 0.9046476817784108, "No": 0.0953491641611327}, "ground_truth": 0}, {"key": "32282272", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312068928377863, "res": {"Yes": 0.5312068928377863, "No": 0.4687884375609335}, "ground_truth": 0}, {"key": "32282272", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.67917572105697, "res": {"Yes": 0.67917572105697, "No": 0.32081989406107386}, "ground_truth": 0}, {"key": "32282272", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7549126949444909, "res": {"Yes": 0.7549126949444909, "No": 0.24508426174978987}, "ground_truth": 1}, {"key": "36093072", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5926650101980302, "res": {"Yes": 0.5926650101980302, "No": 0.4073323074236484}, "ground_truth": 0}, {"key": "36093072", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7772975036143062, "res": {"Yes": 0.7772975036143062, "No": 0.22269945673598857}, "ground_truth": 0}, {"key": "36093072", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.893306962922946, "res": {"Yes": 0.893306962922946, "No": 0.10669031248897741}, "ground_truth": 0}, {"key": "36093072", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.43782180416767413, "res": {"No": 0.5621743245313765, "Yes": 0.43782180416767413}, "ground_truth": 0}, {"key": "36093072", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310566829687575, "res": {"Yes": 0.7310566829687575, "No": 0.2689407320102531}, "ground_truth": 0}, {"key": "36093072", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.777298152242159, "res": {"Yes": 0.777298152242159, "No": 0.22269964257097424}, "ground_truth": 1}, {"key": "38879972", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.08509890614382389, "res": {"No": 0.9148993666414792, "Yes": 0.08509890614382389}, "ground_truth": 0}, {"key": "38879972", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.2942140251813836, "res": {"No": 0.7057827771802003, "Yes": 0.2942140251813836}, "ground_truth": 0}, {"key": "38879972", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.3775394303202135, "res": {"No": 0.6224572892969449, "Yes": 0.3775394303202135}, "ground_truth": 0}, {"key": "38879972", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3486436365957525, "res": {"No": 0.6513520452426794, "Yes": 0.3486436365957525}, "ground_truth": 0}, {"key": "38879972", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3486443431429922, "res": {"No": 0.6513533652466645, "Yes": 0.3486443431429922}, "ground_truth": 0}, {"key": "38879972", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.14804682017840887, "res": {"No": 0.8519505894876508, "Yes": 0.14804682017840887}, "ground_truth": 1}, {"key": "32106473", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7772965770040267, "res": {"Yes": 0.7772965770040267, "No": 0.2226991912577066}, "ground_truth": 0}, {"key": "32106473", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8519495611889732, "res": {"Yes": 0.8519495611889732, "No": 0.14804662604441737}, "ground_truth": 0}, {"key": "32106473", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9148972739687115, "res": {"Yes": 0.9148972739687115, "No": 0.0850987032524629}, "ground_truth": 0}, {"key": "32106473", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9399099569665312, "res": {"Yes": 0.9399099569665312, "No": 0.060086433947277126}, "ground_truth": 0}, {"key": "32106473", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7981843630442481, "res": {"Yes": 0.7981843630442481, "No": 0.20181260571529228}, "ground_truth": 0}, {"key": "32106473", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621726156157273, "res": {"Yes": 0.5621726156157273, "No": 0.4378204732628283}, "ground_truth": 1}, {"key": "40415815", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3486440106499951, "res": {"No": 0.6513527634798101, "Yes": 0.3486440106499951}, "ground_truth": 0}, {"key": "40415815", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7549126274500394, "res": {"Yes": 0.7549126274500394, "No": 0.24508426174978987}, "ground_truth": 0}, {"key": "40415815", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7310558768432849, "res": {"Yes": 0.7310558768432849, "No": 0.26894044346830553}, "ground_truth": 0}, {"key": "40415815", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.754911480045287, "res": {"Yes": 0.754911480045287, "No": 0.24508388193791478}, "ground_truth": 0}, {"key": "40415815", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175712389832833, "res": {"Yes": 0.8175712389832833, "No": 0.18242480692377303}, "ground_truth": 0}, {"key": "40415815", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7981834591103469, "res": {"Yes": 0.7981834591103469, "No": 0.2018123891939723}, "ground_truth": 1}, {"key": "34581918", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.1329640044941716, "res": {"No": 0.8670342099014364, "Yes": 0.1329640044941716}, "ground_truth": 0}, {"key": "34581918", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057823565010085, "res": {"Yes": 0.7057823565010085, "No": 0.2942138498162113}, "ground_truth": 0}, {"key": "34581918", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621749276793165, "res": {"Yes": 0.5621749276793165, "No": 0.43782227389976214}, "ground_truth": 0}, {"key": "34581918", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224567884289806, "res": {"Yes": 0.6224567884289806, "No": 0.37753913777997955}, "ground_truth": 0}, {"key": "34581918", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6513517540656899, "res": {"Yes": 0.6513517540656899, "No": 0.3486434703495512}, "ground_truth": 0}, {"key": "34581918", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310549835701506, "res": {"Yes": 0.7310549835701506, "No": 0.26894009080634557}, "ground_truth": 1}, {"key": "33004157", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7310550489315625, "res": {"Yes": 0.7310550489315625, "No": 0.26894012286650465}, "ground_truth": 0}, {"key": "33004157", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9241387552903352, "res": {"Yes": 0.9241387552903352, "No": 0.07585793636889766}, "ground_truth": 0}, {"key": "33004157", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8670316130222044, "res": {"Yes": 0.8670316130222044, "No": 0.13296359238065295}, "ground_truth": 0}, {"key": "33004157", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7772965075083003, "res": {"Yes": 0.7772965075083003, "No": 0.2226991912577066}, "ground_truth": 0}, {"key": "33004157", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7981833044901768, "res": {"Yes": 0.7981833044901768, "No": 0.20181234107815496}, "ground_truth": 0}, {"key": "33004157", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9465927058484414, "res": {"Yes": 0.9465927058484414, "No": 0.053403107538998275}, "ground_truth": 1}, {"key": "30334943", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4378220912261125, "res": {"No": 0.5621746931217074, "Yes": 0.4378220912261125}, "ground_truth": 0}, {"key": "30334943", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7549125599555939, "res": {"Yes": 0.7549125599555939, "No": 0.2450842325334709}, "ground_truth": 0}, {"key": "30334943", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.754911480045287, "res": {"Yes": 0.754911480045287, "No": 0.24508388193791478}, "ground_truth": 0}, {"key": "30334943", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.592663985756881, "res": {"Yes": 0.592663985756881, "No": 0.4073316033362297}, "ground_truth": 0}, {"key": "30334943", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.40733196751922535, "res": {"No": 0.5926645156400129, "Yes": 0.40733196751922535}, "ground_truth": 0}, {"key": "30334943", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772962990211583, "res": {"Yes": 0.7772962990211583, "No": 0.2226991116142837}, "ground_truth": 1}, {"key": "33280503", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.40733196751922535, "res": {"No": 0.5926645156400129, "Yes": 0.40733196751922535}, "ground_truth": 0}, {"key": "33280503", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513527052443376, "res": {"Yes": 0.6513527052443376, "No": 0.3486439690883928}, "ground_truth": 0}, {"key": "33280503", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224576232091449, "res": {"Yes": 0.6224576232091449, "No": 0.37753963284820047}, "ground_truth": 0}, {"key": "33280503", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7057822513312497, "res": {"Yes": 0.7057822513312497, "No": 0.2942138147431894}, "ground_truth": 0}, {"key": "33280503", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791763890107537, "res": {"Yes": 0.6791763890107537, "No": 0.3208202000189129}, "ground_truth": 0}, {"key": "33280503", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8175711658867216, "res": {"Yes": 0.8175711658867216, "No": 0.1824247851770427}, "ground_truth": 1}, {"key": "25726782", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621740229576492, "res": {"Yes": 0.5621740229576492, "No": 0.43782156930181915}, "ground_truth": 0}, {"key": "25726782", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8807930700479834, "res": {"Yes": 0.8807930700479834, "No": 0.1192023725027742}, "ground_truth": 0}, {"key": "25726782", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9669110564829068, "res": {"Yes": 0.9669110564829068, "No": 0.03308587816013509}, "ground_truth": 0}, {"key": "25726782", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9148979692535951, "res": {"Yes": 0.9148979692535951, "No": 0.0850987641198204}, "ground_truth": 0}, {"key": "25726782", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8933053522557609, "res": {"Yes": 0.8933053522557609, "No": 0.10669010899354982}, "ground_truth": 0}, {"key": "25726782", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9579086302231948, "res": {"Yes": 0.9579086302231948, "No": 0.04208756947128974}, "ground_truth": 1}, {"key": "35479854", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.49999892616522, "res": {"No": 0.49999892616522, "Yes": 0.49999892616522}, "ground_truth": 0}, {"key": "35479854", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5621751287287737, "res": {"Yes": 0.5621751287287737, "No": 0.4378224304772368}, "ground_truth": 0}, {"key": "35479854", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.49999904537426776, "res": {"No": 0.49999904537426776, "Yes": 0.49999904537426776}, "ground_truth": 0}, {"key": "35479854", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224574748037005, "res": {"Yes": 0.6224574748037005, "No": 0.3775395428357484}, "ground_truth": 0}, {"key": "35479854", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4999988069562007, "res": {"No": 0.4999988069562007, "Yes": 0.4999988069562007}, "ground_truth": 0}, {"key": "35479854", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7549130999113267, "res": {"Yes": 0.7549130999113267, "No": 0.24508440783143703}, "ground_truth": 1}, {"key": "32716226", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.24508446626412025, "res": {"No": 0.754913302394826, "Yes": 0.24508446626412025}, "ground_truth": 0}, {"key": "32716226", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5312073044491218, "res": {"Yes": 0.5312073044491218, "No": 0.46878880080666213}, "ground_truth": 0}, {"key": "32716226", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.4999988069562007, "res": {"No": 0.4999988069562007, "Yes": 0.4999988069562007}, "ground_truth": 0}, {"key": "32716226", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4999987473517017, "res": {"No": 0.4999987473517017, "Yes": 0.4999987473517017}, "ground_truth": 0}, {"key": "32716226", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.29421437591204186, "res": {"No": 0.7057835554373664, "Yes": 0.29421437591204186}, "ground_truth": 0}, {"key": "32716226", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621746596134856, "res": {"Yes": 0.5621746596134856, "No": 0.43782206512988303}, "ground_truth": 1}, {"key": "37047554", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.40733218602917903, "res": {"No": 0.5926648335701196, "Yes": 0.40733218602917903}, "ground_truth": 0}, {"key": "37047554", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.731055550035914, "res": {"Yes": 0.731055550035914, "No": 0.2689403152275393}, "ground_truth": 0}, {"key": "37047554", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772960673688438, "res": {"Yes": 0.7772960673688438, "No": 0.22269905851868427}, "ground_truth": 0}, {"key": "37047554", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621748606628468, "res": {"Yes": 0.5621748606628468, "No": 0.437822221707283}, "ground_truth": 0}, {"key": "37047554", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175701303528004, "res": {"Yes": 0.8175701303528004, "No": 0.1824245459631801}, "ground_truth": 0}, {"key": "37047554", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6513521423017049, "res": {"Yes": 0.6513521423017049, "No": 0.3486436781573152}, "ground_truth": 1}, {"key": "36565290", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.49999844932931325, "res": {"No": 0.49999844932931325, "Yes": 0.49999844932931325}, "ground_truth": 0}, {"key": "36565290", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6224566585743889, "res": {"Yes": 0.6224566585743889, "No": 0.3775390477676455}, "ground_truth": 0}, {"key": "36565290", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791762675645624, "res": {"Yes": 0.6791762675645624, "No": 0.3208201617741671}, "ground_truth": 0}, {"key": "36565290", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6513528993625997, "res": {"Yes": 0.6513528993625997, "No": 0.3486440937732147}, "ground_truth": 0}, {"key": "36565290", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926648335701196, "res": {"Yes": 0.5926648335701196, "No": 0.40733218602917903}, "ground_truth": 0}, {"key": "36565290", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.67917572105697, "res": {"Yes": 0.67917572105697, "No": 0.32081989406107386}, "ground_truth": 1}, {"key": "27758640", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.26894092437172346, "res": {"No": 0.7310572058614313, "Yes": 0.26894092437172346}, "ground_truth": 0}, {"key": "27758640", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.731055811481799, "res": {"Yes": 0.731055811481799, "No": 0.2689404114081082}, "ground_truth": 0}, {"key": "27758640", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772959283774883, "res": {"Yes": 0.7772959283774883, "No": 0.2226990054230975}, "ground_truth": 0}, {"key": "27758640", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8175704471042136, "res": {"Yes": 0.8175704471042136, "No": 0.18242463295000294}, "ground_truth": 0}, {"key": "27758640", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.679176105636341, "res": {"Yes": 0.679176105636341, "No": 0.3208200852846891}, "ground_truth": 0}, {"key": "27758640", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310550489315625, "res": {"Yes": 0.7310550489315625, "No": 0.26894012286650465}, "ground_truth": 1}, {"key": "28897118", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.46878896845863177, "res": {"No": 0.5312074944236919, "Yes": 0.46878896845863177}, "ground_truth": 0}, {"key": "28897118", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8354816981742675, "res": {"Yes": 0.8354816981742675, "No": 0.16451609588697805}, "ground_truth": 0}, {"key": "28897118", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8670322331717619, "res": {"Yes": 0.8670322331717619, "No": 0.13296368748365925}, "ground_truth": 0}, {"key": "28897118", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7549130999113267, "res": {"Yes": 0.7549130999113267, "No": 0.24508440783143703}, "ground_truth": 0}, {"key": "28897118", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7981846722850283, "res": {"Yes": 0.7981846722850283, "No": 0.20181270194706463}, "ground_truth": 0}, {"key": "28897118", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772974341184968, "res": {"Yes": 0.7772974341184968, "No": 0.22269945673598857}, "ground_truth": 1}, {"key": "38452661", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.0031726755436204375, "res": {"No": 0.996824841498546, "Yes": 0.0031726755436204375}, "ground_truth": 0}, {"key": "38452661", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7310551578672618, "res": {"Yes": 0.7310551578672618, "No": 0.2689401549266675}, "ground_truth": 0}, {"key": "38452661", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.46878768312839664, "res": {"No": 0.5312060379537242, "Yes": 0.46878768312839664}, "ground_truth": 0}, {"key": "38452661", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7057814730755217, "res": {"Yes": 0.7057814730755217, "No": 0.2942134990861802}, "ground_truth": 0}, {"key": "38452661", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.731055550035914, "res": {"Yes": 0.731055550035914, "No": 0.2689403152275393}, "ground_truth": 0}, {"key": "38452661", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8807927944263967, "res": {"Yes": 0.8807927944263967, "No": 0.11920234408271731}, "ground_truth": 1}, {"key": "38033492", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.8354789468067094, "res": {"Yes": 0.8354789468067094, "No": 0.16451556636796366}, "ground_truth": 0}, {"key": "38033492", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6791747899709735, "res": {"Yes": 0.6791747899709735, "No": 0.3208194351248624}, "ground_truth": 0}, {"key": "38033492", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8519488629621836, "res": {"Yes": 0.8519488629621836, "No": 0.14804652015325656}, "ground_truth": 0}, {"key": "38033492", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7057824827047398, "res": {"Yes": 0.7057824827047398, "No": 0.2942139199622677}, "ground_truth": 0}, {"key": "38033492", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7981813301121771, "res": {"Yes": 0.7981813301121771, "No": 0.20181183586276547}, "ground_truth": 0}, {"key": "38033492", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310546567631792, "res": {"Yes": 0.7310546567631792, "No": 0.2689399946258913}, "ground_truth": 1}, {"key": "35949555", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.201812750062968, "res": {"No": 0.798184898268751, "Yes": 0.201812750062968}, "ground_truth": 0}, {"key": "35949555", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981836018366844, "res": {"Yes": 0.7981836018366844, "No": 0.20181241325188526}, "ground_truth": 0}, {"key": "35949555", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.731055746120319, "res": {"Yes": 0.731055746120319, "No": 0.26894037934791476}, "ground_truth": 0}, {"key": "35949555", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3208203147531778, "res": {"No": 0.6791765914211209, "Yes": 0.3208203147531778}, "ground_truth": 0}, {"key": "35949555", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310551578672618, "res": {"Yes": 0.7310551578672618, "No": 0.2689401549266675}, "ground_truth": 0}, {"key": "35949555", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772969476480059, "res": {"Yes": 0.7772969476480059, "No": 0.2226992974489814}, "ground_truth": 1}, {"key": "15263826", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2942136744511435, "res": {"No": 0.7057819358220674, "Yes": 0.2942136744511435}, "ground_truth": 0}, {"key": "15263826", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.651351792889281, "res": {"Yes": 0.651351792889281, "No": 0.3486434703495512}, "ground_truth": 0}, {"key": "15263826", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621738554167595, "res": {"Yes": 0.5621738554167595, "No": 0.437821438820843}, "ground_truth": 0}, {"key": "15263826", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621738554167595, "res": {"Yes": 0.5621738554167595, "No": 0.437821438820843}, "ground_truth": 0}, {"key": "15263826", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057810523971073, "res": {"Yes": 0.7057810523971073, "No": 0.2942133237213215}, "ground_truth": 0}, {"key": "15263826", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4073314091054318, "res": {"No": 0.5926637031527375, "Yes": 0.4073314091054318}, "ground_truth": 1}, {"key": "37313866", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621744920724061, "res": {"Yes": 0.5621744920724061, "No": 0.4378219346487591}, "ground_truth": 0}, {"key": "37313866", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4687888287486529, "res": {"No": 0.5312073361115454, "Yes": 0.4687888287486529}, "ground_truth": 0}, {"key": "37313866", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621734198106798, "res": {"Yes": 0.5621734198106798, "No": 0.4378210995704871}, "ground_truth": 0}, {"key": "37313866", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.46878885669064535, "res": {"No": 0.5312073677739709, "Yes": 0.46878885669064535}, "ground_truth": 0}, {"key": "37313866", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8670321427332571, "res": {"Yes": 0.8670321427332571, "No": 0.13296368748365925}, "ground_truth": 0}, {"key": "37313866", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6791753972008264, "res": {"Yes": 0.6791753972008264, "No": 0.3208197410822638}, "ground_truth": 1}, {"key": "13911157", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4999983301204076, "res": {"No": 0.4999983301204076, "Yes": 0.4999983301204076}, "ground_truth": 0}, {"key": "13911157", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5312070511498007, "res": {"Yes": 0.5312070511498007, "No": 0.4687885772707958}, "ground_truth": 0}, {"key": "13911157", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6513516375949305, "res": {"Yes": 0.6513516375949305, "No": 0.3486433872264803}, "ground_truth": 0}, {"key": "13911157", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7057816413469579, "res": {"Yes": 0.7057816413469579, "No": 0.294213569232153}, "ground_truth": 0}, {"key": "13911157", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224563617639954, "res": {"Yes": 0.6224563617639954, "No": 0.3775388677430418}, "ground_truth": 0}, {"key": "13911157", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057812837702042, "res": {"Yes": 0.7057812837702042, "No": 0.2942133938672524}, "ground_truth": 1}, {"key": "39594894", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.40733148194197016, "res": {"No": 0.5926638091292755, "Yes": 0.40733148194197016}, "ground_truth": 0}, {"key": "39594894", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8175691679165672, "res": {"Yes": 0.8175691679165672, "No": 0.18242432849630452}, "ground_truth": 0}, {"key": "39594894", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224565472704748, "res": {"Yes": 0.6224565472704748, "No": 0.37753898025840904}, "ground_truth": 0}, {"key": "39594894", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.67917572105697, "res": {"Yes": 0.67917572105697, "No": 0.32081989406107386}, "ground_truth": 0}, {"key": "39594894", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7981829952499266, "res": {"Yes": 0.7981829952499266, "No": 0.20181226890445045}, "ground_truth": 0}, {"key": "39594894", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5312070511498007, "res": {"Yes": 0.5312070511498007, "No": 0.4687885772707958}, "ground_truth": 1}, {"key": "34096170", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.754912829933412, "res": {"Yes": 0.754912829933412, "No": 0.24508432018243828}, "ground_truth": 0}, {"key": "34096170", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7310556807588449, "res": {"Yes": 0.7310556807588449, "No": 0.2689403472877251}, "ground_truth": 0}, {"key": "34096170", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791760044312222, "res": {"Yes": 0.6791760044312222, "No": 0.3208200470399569}, "ground_truth": 0}, {"key": "34096170", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8175713973591893, "res": {"Yes": 0.8175713973591893, "No": 0.18242482867050594}, "ground_truth": 0}, {"key": "34096170", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7549120200002474, "res": {"Yes": 0.7549120200002474, "No": 0.24508405723563015}, "ground_truth": 0}, {"key": "34096170", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6513525111261335, "res": {"Yes": 0.6513525111261335, "No": 0.348643885965203}, "ground_truth": 1}, {"key": "37891952", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7310561818636294, "res": {"Yes": 0.7310561818636294, "No": 0.2689405396489203}, "ground_truth": 0}, {"key": "37891952", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6791760044312222, "res": {"Yes": 0.6791760044312222, "No": 0.3208200470399569}, "ground_truth": 0}, {"key": "37891952", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.754911885011471, "res": {"Yes": 0.754911885011471, "No": 0.2450839988030444}, "ground_truth": 0}, {"key": "37891952", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7549120874946446, "res": {"Yes": 0.7549120874946446, "No": 0.24508408645192822}, "ground_truth": 0}, {"key": "37891952", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175716410144892, "res": {"Yes": 0.8175716410144892, "No": 0.18242489391072028}, "ground_truth": 0}, {"key": "37891952", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8175713242626135, "res": {"Yes": 0.8175713242626135, "No": 0.18242482867050594}, "ground_truth": 1}, {"key": "40186158", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4378221695148102, "res": {"No": 0.5621747936463851, "Yes": 0.4378221695148102}, "ground_truth": 0}, {"key": "40186158", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981817820777942, "res": {"Yes": 0.7981817820777942, "No": 0.2018119561520292}, "ground_truth": 0}, {"key": "40186158", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6513519481836685, "res": {"Yes": 0.6513519481836685, "No": 0.3486435534726419}, "ground_truth": 0}, {"key": "40186158", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224565472704748, "res": {"Yes": 0.6224565472704748, "No": 0.37753898025840904}, "ground_truth": 0}, {"key": "40186158", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057807579223663, "res": {"Yes": 0.7057807579223663, "No": 0.29421318342950975}, "ground_truth": 0}, {"key": "40186158", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6224566956756981, "res": {"Yes": 0.6224566956756981, "No": 0.37753907027072703}, "ground_truth": 1}, {"key": "37049719", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.49999827051596546, "res": {"No": 0.49999827051596546, "Yes": 0.49999827051596546}, "ground_truth": 0}, {"key": "37049719", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7549117500227189, "res": {"Yes": 0.7549117500227189, "No": 0.24508396958675677}, "ground_truth": 0}, {"key": "37049719", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7057829033840068, "res": {"Yes": 0.7057829033840068, "No": 0.29421409532748183}, "ground_truth": 0}, {"key": "37049719", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310563125866733, "res": {"Yes": 0.7310563125866733, "No": 0.2689405717091329}, "ground_truth": 0}, {"key": "37049719", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057827771802003, "res": {"Yes": 0.7057827771802003, "No": 0.2942140251813836}, "ground_truth": 0}, {"key": "37049719", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772962990211583, "res": {"Yes": 0.7772962990211583, "No": 0.2226991116142837}, "ground_truth": 1}, {"key": "34610504", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.06754625120008421, "res": {"No": 0.9324471662095559, "Yes": 0.06754625120008421}, "ground_truth": 0}, {"key": "34610504", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.03732669224645538, "res": {"No": 0.9626679913650915, "Yes": 0.03732669224645538}, "ground_truth": 0}, {"key": "34610504", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.08509856122879801, "res": {"No": 0.9148956789053865, "Yes": 0.08509856122879801}, "ground_truth": 0}, {"key": "34610504", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.07585788211109286, "res": {"No": 0.924138245773075, "Yes": 0.07585788211109286}, "ground_truth": 0}, {"key": "34610504", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.033085720394750044, "res": {"No": 0.9669063738625538, "Yes": 0.033085720394750044}, "ground_truth": 0}, {"key": "34610504", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.04742555796816437, "res": {"No": 0.9525677672836105, "Yes": 0.04742555796816437}, "ground_truth": 1}, {"key": "37595429", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4378221695148102, "res": {"No": 0.5621747936463851, "Yes": 0.4378221695148102}, "ground_truth": 0}, {"key": "37595429", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7549124924611544, "res": {"Yes": 0.7549124924611544, "No": 0.24508420331715539}, "ground_truth": 0}, {"key": "37595429", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7549127624389484, "res": {"Yes": 0.7549127624389484, "No": 0.24508429096611234}, "ground_truth": 0}, {"key": "37595429", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224572892969449, "res": {"Yes": 0.6224572892969449, "No": 0.3775394303202135}, "ground_truth": 0}, {"key": "37595429", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7549116150339908, "res": {"Yes": 0.7549116150339908, "No": 0.24508391115419195}, "ground_truth": 0}, {"key": "37595429", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.932451417950181, "res": {"Yes": 0.932451417950181, "No": 0.06754655718212071}, "ground_truth": 1}, {"key": "29772670", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.26894012286650465, "res": {"No": 0.7310550489315625, "Yes": 0.26894012286650465}, "ground_truth": 0}, {"key": "29772670", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.32081989406107386, "res": {"No": 0.67917572105697, "Yes": 0.32081989406107386}, "ground_truth": 0}, {"key": "29772670", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.46878821402524046, "res": {"No": 0.5312066395386615, "Yes": 0.46878821402524046}, "ground_truth": 0}, {"key": "29772670", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3775390477676455, "res": {"No": 0.6224566585743889, "Yes": 0.3775390477676455}, "ground_truth": 0}, {"key": "29772670", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3775384851910439, "res": {"No": 0.6224557310423794, "Yes": 0.3775384851910439}, "ground_truth": 0}, {"key": "29772670", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4073313605477468, "res": {"No": 0.5926636325017227, "Yes": 0.4073313605477468}, "ground_truth": 1}, {"key": "36369872", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7772979437545758, "res": {"Yes": 0.7772979437545758, "No": 0.22269958947524823}, "ground_truth": 0}, {"key": "36369872", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7310570751382278, "res": {"Yes": 0.7310570751382278, "No": 0.26894086025121805}, "ground_truth": 0}, {"key": "36369872", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9324518278412331, "res": {"Yes": 0.9324518278412331, "No": 0.06754658939083677}, "ground_truth": 0}, {"key": "36369872", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981851242525378, "res": {"Yes": 0.7981851242525378, "No": 0.20181279817888287}, "ground_truth": 0}, {"key": "36369872", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791768140725944, "res": {"Yes": 0.6791768140725944, "No": 0.32082042948748374}, "ground_truth": 0}, {"key": "36369872", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9241398707209936, "res": {"Yes": 0.9241398707209936, "No": 0.07585802679865858}, "ground_truth": 1}, {"key": "34527433", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.37753976786691884, "res": {"No": 0.6224578458173778, "Yes": 0.37753976786691884}, "ground_truth": 0}, {"key": "34527433", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.851950246721287, "res": {"Yes": 0.851950246721287, "No": 0.1480467495842007}, "ground_truth": 0}, {"key": "34527433", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.37753965535131684, "res": {"No": 0.6224576603105115, "Yes": 0.37753965535131684}, "ground_truth": 0}, {"key": "34527433", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310561818636294, "res": {"Yes": 0.7310561818636294, "No": 0.2689405396489203}, "ground_truth": 0}, {"key": "34527433", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7981840656974571, "res": {"Yes": 0.7981840656974571, "No": 0.20181253354149314}, "ground_truth": 0}, {"key": "34527433", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7549125599555939, "res": {"Yes": 0.7549125599555939, "No": 0.2450842325334709}, "ground_truth": 1}, {"key": "31111734", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5312069561625864, "res": {"Yes": 0.5312069561625864, "No": 0.46878849344487344}, "ground_truth": 0}, {"key": "31111734", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5926633498977478, "res": {"Yes": 0.5926633498977478, "No": 0.40733116631706473}, "ground_truth": 0}, {"key": "31111734", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.731055811481799, "res": {"Yes": 0.731055811481799, "No": 0.2689404114081082}, "ground_truth": 0}, {"key": "31111734", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310543953177071, "res": {"Yes": 0.7310543953177071, "No": 0.2689398663853391}, "ground_truth": 0}, {"key": "31111734", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175702034492695, "res": {"Yes": 0.8175702034492695, "No": 0.18242456770988194}, "ground_truth": 0}, {"key": "31111734", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310545260404314, "res": {"Yes": 0.7310545260404314, "No": 0.26893993050560755}, "ground_truth": 1}, {"key": "40303872", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.047425750189834366, "res": {"No": 0.9525715536382257, "Yes": 0.047425750189834366}, "ground_truth": 0}, {"key": "40303872", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981840656974571, "res": {"Yes": 0.7981840656974571, "No": 0.20181253354149314}, "ground_truth": 0}, {"key": "40303872", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224566956756981, "res": {"Yes": 0.6224566956756981, "No": 0.37753907027072703}, "ground_truth": 0}, {"key": "40303872", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224570295875796, "res": {"Yes": 0.6224570295875796, "No": 0.3775392727985209}, "ground_truth": 0}, {"key": "40303872", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8354810258935753, "res": {"Yes": 0.8354810258935753, "No": 0.1645159782159387}, "ground_truth": 0}, {"key": "40303872", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5926646922678288, "res": {"Yes": 0.5926646922678288, "No": 0.4073320889136296}, "ground_truth": 1}, {"key": "33653553", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2018128462948092, "res": {"No": 0.7981852788730605, "Yes": 0.2018128462948092}, "ground_truth": 0}, {"key": "33653553", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9046453429492228, "res": {"Yes": 0.9046453429492228, "No": 0.09534891409832601}, "ground_truth": 0}, {"key": "33653553", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8175698866979507, "res": {"Yes": 0.8175698866979507, "No": 0.18242450246978426}, "ground_truth": 0}, {"key": "33653553", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8175705323834611, "res": {"Yes": 0.8175705323834611, "No": 0.18242463295000294}, "ground_truth": 0}, {"key": "33653553", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8670301789280519, "res": {"Yes": 0.8670301789280519, "No": 0.13296337047390275}, "ground_truth": 0}, {"key": "33653553", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9241376329756612, "res": {"Yes": 0.9241376329756612, "No": 0.07585782785332686}, "ground_truth": 1}, {"key": "34404510", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.24508420331715539, "res": {"No": 0.7549124924611544, "Yes": 0.24508420331715539}, "ground_truth": 0}, {"key": "34404510", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6224572521956003, "res": {"Yes": 0.6224572521956003, "No": 0.3775394078171105}, "ground_truth": 0}, {"key": "34404510", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8807936212914155, "res": {"Yes": 0.8807936212914155, "No": 0.11920245776298552}, "ground_truth": 0}, {"key": "34404510", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5926644096633487, "res": {"Yes": 0.5926644096633487, "No": 0.40733189468260017}, "ground_truth": 0}, {"key": "34404510", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926644449889013, "res": {"Yes": 0.5926644449889013, "No": 0.40733191896147375}, "ground_truth": 0}, {"key": "34404510", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8519489518273796, "res": {"Yes": 0.8519489518273796, "No": 0.14804652015325656}, "ground_truth": 1}, {"key": "35568692", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.07585793636889766, "res": {"No": 0.9241388585708952, "Yes": 0.07585793636889766}, "ground_truth": 0}, {"key": "35568692", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.06754654107776845, "res": {"No": 0.9324512095310711, "Yes": 0.06754654107776845}, "ground_truth": 0}, {"key": "35568692", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.2018123891939723, "res": {"No": 0.7981834591103469, "Yes": 0.2018123891939723}, "ground_truth": 0}, {"key": "35568692", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.14804664369295154, "res": {"No": 0.8519496373592031, "Yes": 0.14804664369295154}, "ground_truth": 0}, {"key": "35568692", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.16451586054498346, "res": {"No": 0.8354804407608204, "Yes": 0.16451586054498346}, "ground_truth": 0}, {"key": "35568692", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.07585791828295842, "res": {"No": 0.9241385487292499, "Yes": 0.07585791828295842}, "ground_truth": 1}, {"key": "39151664", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.40733191896147375, "res": {"No": 0.5926644449889013, "Yes": 0.40733191896147375}, "ground_truth": 0}, {"key": "39151664", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.46878846550290265, "res": {"No": 0.5312069245001855, "Yes": 0.46878846550290265}, "ground_truth": 0}, {"key": "39151664", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.46878885669064535, "res": {"No": 0.5312073677739709, "Yes": 0.46878885669064535}, "ground_truth": 0}, {"key": "39151664", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4073319432403488, "res": {"No": 0.5926644803144561, "Yes": 0.4073319432403488}, "ground_truth": 0}, {"key": "39151664", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4687877110703208, "res": {"No": 0.5312060696160723, "Yes": 0.4687877110703208}, "ground_truth": 0}, {"key": "39151664", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.32081951161418537, "res": {"No": 0.6791748911759113, "Yes": 0.32081951161418537}, "ground_truth": 1}, {"key": "37493670", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.22269974876246426, "res": {"No": 0.7772985228868894, "Yes": 0.22269974876246426}, "ground_truth": 0}, {"key": "37493670", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.49999844932931325, "res": {"No": 0.49999844932931325, "Yes": 0.49999844932931325}, "ground_truth": 0}, {"key": "37493670", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.37753965535131684, "res": {"No": 0.6224576603105115, "Yes": 0.37753965535131684}, "ground_truth": 0}, {"key": "37493670", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.437822378284739, "res": {"No": 0.56217506171228, "Yes": 0.437822378284739}, "ground_truth": 0}, {"key": "37493670", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.377539812873169, "res": {"No": 0.6224579385708318, "Yes": 0.377539812873169}, "ground_truth": 0}, {"key": "37493670", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.3775395878419718, "res": {"No": 0.622457530455738, "Yes": 0.3775395878419718}, "ground_truth": 1}, {"key": "21935983", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3208201617741671, "res": {"No": 0.6791762675645624, "Yes": 0.3208201617741671}, "ground_truth": 0}, {"key": "21935983", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5312064179020264, "res": {"Yes": 0.5312064179020264, "No": 0.46878801843159645}, "ground_truth": 0}, {"key": "21935983", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224551374226187, "res": {"Yes": 0.6224551374226187, "No": 0.3775381251424588}, "ground_truth": 0}, {"key": "21935983", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621731182374378, "res": {"Yes": 0.5621731182374378, "No": 0.43782086470501}, "ground_truth": 0}, {"key": "21935983", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5312050880841576, "res": {"Yes": 0.5312050880841576, "No": 0.46878684487144623}, "ground_truth": 0}, {"key": "21935983", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621721800106083, "res": {"Yes": 0.5621721800106083, "No": 0.4378201340132205}, "ground_truth": 1}, {"key": "38174214", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621752292535293, "res": {"Yes": 0.5621752292535293, "No": 0.43782250876599516}, "ground_truth": 0}, {"key": "38174214", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8175722745186087, "res": {"Yes": 0.8175722745186087, "No": 0.18242502439121894}, "ground_truth": 0}, {"key": "38174214", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772978047628848, "res": {"Yes": 0.7772978047628848, "No": 0.22269956292738996}, "ground_truth": 0}, {"key": "38174214", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6513528605389426, "res": {"Yes": 0.6513528605389426, "No": 0.34864405221160244}, "ground_truth": 0}, {"key": "38174214", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057829454519473, "res": {"Yes": 0.7057829454519473, "No": 0.29421409532748183}, "ground_truth": 0}, {"key": "38174214", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6513526470088703, "res": {"Yes": 0.6513526470088703, "No": 0.3486439690883928}, "ground_truth": 1}, {"key": "40319923", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.29421437591204186, "res": {"No": 0.7057835975053457, "Yes": 0.29421437591204186}, "ground_truth": 0}, {"key": "40319923", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8354803660630514, "res": {"Yes": 0.8354803660630514, "No": 0.1645158409331658}, "ground_truth": 0}, {"key": "40319923", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7549119525058562, "res": {"Yes": 0.7549119525058562, "No": 0.24508402801933554}, "ground_truth": 0}, {"key": "40319923", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981830785069053, "res": {"Yes": 0.7981830785069053, "No": 0.2018122929623491}, "ground_truth": 0}, {"key": "40319923", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.34864430158135024, "res": {"No": 0.6513532681874569, "Yes": 0.34864430158135024}, "ground_truth": 0}, {"key": "40319923", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8354797809307587, "res": {"Yes": 0.8354797809307587, "No": 0.16451572326230876}, "ground_truth": 1}, {"key": "36478264", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3486440106499951, "res": {"No": 0.6513527634798101, "Yes": 0.3486440106499951}, "ground_truth": 0}, {"key": "36478264", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513519481836685, "res": {"Yes": 0.6513519481836685, "No": 0.3486435534726419}, "ground_truth": 0}, {"key": "36478264", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.3208200470399569, "res": {"No": 0.6791760044312222, "Yes": 0.3208200470399569}, "ground_truth": 0}, {"key": "36478264", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312069561625864, "res": {"Yes": 0.5312069561625864, "No": 0.46878849344487344}, "ground_truth": 0}, {"key": "36478264", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5312076843983299, "res": {"Yes": 0.5312076843983299, "No": 0.4687891361106614}, "ground_truth": 0}, {"key": "36478264", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6791763890107537, "res": {"Yes": 0.6791763890107537, "No": 0.3208202000189129}, "ground_truth": 1}, {"key": "11935769", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.05340319666512378, "res": {"No": 0.9465943068048063, "Yes": 0.05340319666512378}, "ground_truth": 0}, {"key": "11935769", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9796637563781571, "res": {"Yes": 0.9796637563781571, "No": 0.0203322708225152}, "ground_truth": 0}, {"key": "11935769", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9046471021256566, "res": {"Yes": 0.9046471021256566, "No": 0.09534909596212039}, "ground_truth": 0}, {"key": "11935769", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9579079736216781, "res": {"Yes": 0.9579079736216781, "No": 0.042087539367924975}, "ground_truth": 0}, {"key": "11935769", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9046479783450799, "res": {"Yes": 0.9046479783450799, "No": 0.09534918689414766}, "ground_truth": 0}, {"key": "11935769", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9669100515186275, "res": {"Yes": 0.9669100515186275, "No": 0.033085838718718306}, "ground_truth": 1}, {"key": "33373410", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.11920265670371576, "res": {"No": 0.8807951044004576, "Yes": 0.11920265670371576}, "ground_truth": 0}, {"key": "33373410", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.437822299996004, "res": {"No": 0.5621749611875544, "Yes": 0.437822299996004}, "ground_truth": 0}, {"key": "33373410", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5312079060354934, "res": {"Yes": 0.5312079060354934, "No": 0.4687893317047717}, "ground_truth": 0}, {"key": "33373410", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.437822221707283, "res": {"No": 0.5621748606628468, "Yes": 0.437822221707283}, "ground_truth": 0}, {"key": "33373410", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310552232286893, "res": {"Yes": 0.7310552232286893, "No": 0.26894018698683425}, "ground_truth": 0}, {"key": "33373410", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.777295997873163, "res": {"Yes": 0.777295997873163, "No": 0.2226990319708893}, "ground_truth": 1}, {"key": "11130680", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3775395428357484, "res": {"No": 0.6224574748037005, "Yes": 0.3775395428357484}, "ground_truth": 0}, {"key": "11130680", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.017986185584564048, "res": {"No": 0.9820123785878146, "Yes": 0.017986185584564048}, "ground_truth": 0}, {"key": "11130680", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7057820620257235, "res": {"Yes": 0.7057820620257235, "No": 0.2942137445971581}, "ground_truth": 0}, {"key": "11130680", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.49999827051596546, "res": {"No": 0.49999827051596546, "Yes": 0.49999827051596546}, "ground_truth": 0}, {"key": "11130680", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7981835304735124, "res": {"Yes": 0.7981835304735124, "No": 0.20181241325188526}, "ground_truth": 0}, {"key": "11130680", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6513517540656899, "res": {"Yes": 0.6513517540656899, "No": 0.3486434703495512}, "ground_truth": 1}, {"key": "34868650", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.67917572105697, "res": {"Yes": 0.67917572105697, "No": 0.32081989406107386}, "ground_truth": 0}, {"key": "34868650", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8175720430458927, "res": {"Yes": 0.8175720430458927, "No": 0.182424980897709}, "ground_truth": 0}, {"key": "34868650", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.835480191768283, "res": {"Yes": 0.835480191768283, "No": 0.16451580170953742}, "ground_truth": 0}, {"key": "34868650", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9046463202690415, "res": {"Yes": 0.9046463202690415, "No": 0.09534902776315685}, "ground_truth": 0}, {"key": "34868650", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8519482536010895, "res": {"Yes": 0.8519482536010895, "No": 0.1480464142621715}, "ground_truth": 0}, {"key": "34868650", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8670322331717619, "res": {"Yes": 0.8670322331717619, "No": 0.13296368748365925}, "ground_truth": 1}, {"key": "33960561", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4687891640526722, "res": {"No": 0.5312077160607761, "Yes": 0.4687891640526722}, "ground_truth": 0}, {"key": "33960561", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6224578087160002, "res": {"Yes": 0.6224578087160002, "No": 0.37753974536379575}, "ground_truth": 0}, {"key": "33960561", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621750282040362, "res": {"Yes": 0.5621750282040362, "No": 0.43782235218849247}, "ground_truth": 0}, {"key": "33960561", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4999986877472098, "res": {"No": 0.4999986877472098, "Yes": 0.4999986877472098}, "ground_truth": 0}, {"key": "33960561", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6513531517164267, "res": {"Yes": 0.6513531517164267, "No": 0.34864421845808113}, "ground_truth": 0}, {"key": "33960561", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4687891640526722, "res": {"No": 0.5312077160607761, "Yes": 0.4687891640526722}, "ground_truth": 1}, {"key": "22504858", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7981835304735124, "res": {"Yes": 0.7981835304735124, "No": 0.20181241325188526}, "ground_truth": 0}, {"key": "22504858", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8519475680703794, "res": {"Yes": 0.8519475680703794, "No": 0.148046290722668}, "ground_truth": 0}, {"key": "22504858", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8175695699467547, "res": {"Yes": 0.8175695699467547, "No": 0.1824244372297099}, "ground_truth": 0}, {"key": "22504858", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8933040144724141, "res": {"Yes": 0.8933040144724141, "No": 0.10668995637223384}, "ground_truth": 0}, {"key": "22504858", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310551578672618, "res": {"Yes": 0.7310551578672618, "No": 0.2689401549266675}, "ground_truth": 0}, {"key": "22504858", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8807936212914155, "res": {"Yes": 0.8807936212914155, "No": 0.11920245776298552}, "ground_truth": 1}, {"key": "32283530", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.20181289441074698, "res": {"No": 0.7981854334936129, "Yes": 0.20181289441074698}, "ground_truth": 0}, {"key": "32283530", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7772978047628848, "res": {"Yes": 0.7772978047628848, "No": 0.22269956292738996}, "ground_truth": 0}, {"key": "32283530", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7310565740328309, "res": {"Yes": 0.7310565740328309, "No": 0.2689406999500214}, "ground_truth": 0}, {"key": "32283530", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8670327758029885, "res": {"Yes": 0.8670327758029885, "No": 0.1329637825867336}, "ground_truth": 0}, {"key": "32283530", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7549131674058205, "res": {"Yes": 0.7549131674058205, "No": 0.2450844370477769}, "ground_truth": 0}, {"key": "32283530", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7981846722850283, "res": {"Yes": 0.7981846722850283, "No": 0.20181270194706463}, "ground_truth": 1}, {"key": "38377099", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.22269974876246426, "res": {"No": 0.7772985228868894, "Yes": 0.22269974876246426}, "ground_truth": 0}, {"key": "38377099", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6224566956756981, "res": {"Yes": 0.6224566956756981, "No": 0.37753907027072703}, "ground_truth": 0}, {"key": "38377099", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8807937131653544, "res": {"Yes": 0.8807937131653544, "No": 0.11920245776298552}, "ground_truth": 0}, {"key": "38377099", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9046471021256566, "res": {"Yes": 0.9046471021256566, "No": 0.09534909596212039}, "ground_truth": 0}, {"key": "38377099", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310556153973765, "res": {"Yes": 0.7310556153973765, "No": 0.2689403152275393}, "ground_truth": 0}, {"key": "38377099", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.731055550035914, "res": {"Yes": 0.731055550035914, "No": 0.2689403152275393}, "ground_truth": 1}, {"key": "36105123", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7981832331270315, "res": {"Yes": 0.7981832331270315, "No": 0.20181231702025057}, "ground_truth": 0}, {"key": "36105123", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6791762068414748, "res": {"Yes": 0.6791762068414748, "No": 0.32082012352942585}, "ground_truth": 0}, {"key": "36105123", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8354794447911162, "res": {"Yes": 0.8354794447911162, "No": 0.16451566442691182}, "ground_truth": 0}, {"key": "36105123", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5926638444547924, "res": {"Yes": 0.5926638444547924, "No": 0.4073315062208192}, "ground_truth": 0}, {"key": "36105123", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3775392052892442, "res": {"No": 0.6224569182835993, "Yes": 0.3775392052892442}, "ground_truth": 0}, {"key": "36105123", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5926638444547924, "res": {"Yes": 0.5926638444547924, "No": 0.4073315062208192}, "ground_truth": 1}, {"key": "33527826", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.29421377967017165, "res": {"No": 0.705782188229402, "Yes": 0.29421377967017165}, "ground_truth": 0}, {"key": "33527826", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981826146467061, "res": {"Yes": 0.7981826146467061, "No": 0.2018121726728846}, "ground_truth": 0}, {"key": "33527826", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8354787849618411, "res": {"Yes": 0.8354787849618411, "No": 0.16451552714440076}, "ground_truth": 0}, {"key": "33527826", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310536981302389, "res": {"Yes": 0.7310536981302389, "No": 0.2689396099044182}, "ground_truth": 0}, {"key": "33527826", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057805265494417, "res": {"Yes": 0.7057805265494417, "No": 0.294213113283629}, "ground_truth": 0}, {"key": "33527826", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6791741827416635, "res": {"Yes": 0.6791741827416635, "No": 0.32081916741237554}, "ground_truth": 1}, {"key": "32349891", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.20181279817888287, "res": {"No": 0.7981850528892299, "Yes": 0.20181279817888287}, "ground_truth": 0}, {"key": "32349891", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.40733196751922535, "res": {"No": 0.5926645156400129, "Yes": 0.40733196751922535}, "ground_truth": 0}, {"key": "32349891", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.2942139901083408, "res": {"No": 0.7057826509764165, "Yes": 0.2942139901083408}, "ground_truth": 0}, {"key": "32349891", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3208201617741671, "res": {"No": 0.6791762675645624, "Yes": 0.3208201617741671}, "ground_truth": 0}, {"key": "32349891", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.2689405717091329, "res": {"No": 0.7310562472251484, "Yes": 0.2689405717091329}, "ground_truth": 0}, {"key": "32349891", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.26894018698683425, "res": {"No": 0.7310552232286893, "Yes": 0.26894018698683425}, "ground_truth": 1}, {"key": "34281974", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2450842325334709, "res": {"No": 0.7549125599555939, "Yes": 0.2450842325334709}, "ground_truth": 0}, {"key": "34281974", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7772967854912433, "res": {"Yes": 0.7772967854912433, "No": 0.22269924435333766}, "ground_truth": 0}, {"key": "34281974", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224561762575714, "res": {"Yes": 0.6224561762575714, "No": 0.3775387552277081}, "ground_truth": 0}, {"key": "34281974", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8933042074858082, "res": {"Yes": 0.8933042074858082, "No": 0.10668998180910468}, "ground_truth": 0}, {"key": "34281974", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310537634915357, "res": {"Yes": 0.7310537634915357, "No": 0.2689396419645199}, "ground_truth": 0}, {"key": "34281974", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7981836018366844, "res": {"Yes": 0.7981836018366844, "No": 0.20181241325188526}, "ground_truth": 1}, {"key": "29387866", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4687884375609335, "res": {"No": 0.5312068928377863, "Yes": 0.4687884375609335}, "ground_truth": 0}, {"key": "29387866", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5926637031527375, "res": {"Yes": 0.5926637031527375, "No": 0.4073314091054318}, "ground_truth": 0}, {"key": "29387866", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621734533188278, "res": {"Yes": 0.5621734533188278, "No": 0.437821125666659}, "ground_truth": 0}, {"key": "29387866", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310543953177071, "res": {"Yes": 0.7310543953177071, "No": 0.2689398663853391}, "ground_truth": 0}, {"key": "29387866", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5621738219085876, "res": {"Yes": 0.5621738219085876, "No": 0.43782141272465247}, "ground_truth": 0}, {"key": "29387866", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6224561391562933, "res": {"Yes": 0.6224561391562933, "No": 0.37753873272464533}, "ground_truth": 1}, {"key": "35731925", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.09534932329235117, "res": {"No": 0.9046492454946702, "Yes": 0.09534932329235117}, "ground_truth": 0}, {"key": "35731925", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.20181294252669624, "res": {"No": 0.7981856594775513, "Yes": 0.20181294252669624}, "ground_truth": 0}, {"key": "35731925", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.20181289441074698, "res": {"No": 0.7981855048569549, "Yes": 0.20181289441074698}, "ground_truth": 0}, {"key": "35731925", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.1824252201121419, "res": {"No": 0.8175731516789693, "Yes": 0.1824252201121419}, "ground_truth": 0}, {"key": "35731925", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.20181294252669624, "res": {"No": 0.7981856594775513, "Yes": 0.20181294252669624}, "ground_truth": 0}, {"key": "35731925", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.18242526360570888, "res": {"No": 0.8175733100552458, "Yes": 0.18242526360570888}, "ground_truth": 1}, {"key": "38829733", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2942142356197284, "res": {"No": 0.705783260961581, "Yes": 0.2942142356197284}, "ground_truth": 0}, {"key": "38829733", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7310537634915357, "res": {"Yes": 0.7310537634915357, "No": 0.2689396419645199}, "ground_truth": 0}, {"key": "38829733", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7549098376846565, "res": {"Yes": 0.7549098376846565, "No": 0.24508332682930994}, "ground_truth": 0}, {"key": "38829733", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7057801689732529, "res": {"Yes": 0.7057801689732529, "No": 0.29421293791900016}, "ground_truth": 0}, {"key": "38829733", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175698136015099, "res": {"Yes": 0.8175698136015099, "No": 0.18242448072309023}, "ground_truth": 0}, {"key": "38829733", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772968781522464, "res": {"Yes": 0.7772968781522464, "No": 0.2226992974489814}, "ground_truth": 1}, {"key": "24624736", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6224563617639954, "res": {"Yes": 0.6224563617639954, "No": 0.3775388677430418}, "ground_truth": 0}, {"key": "24624736", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.679175781780014, "res": {"Yes": 0.679175781780014, "No": 0.3208199323057878}, "ground_truth": 0}, {"key": "24624736", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772974341184968, "res": {"Yes": 0.7772974341184968, "No": 0.22269945673598857}, "ground_truth": 0}, {"key": "24624736", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7772967854912433, "res": {"Yes": 0.7772967854912433, "No": 0.22269924435333766}, "ground_truth": 0}, {"key": "24624736", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224565472704748, "res": {"Yes": 0.6224565472704748, "No": 0.37753898025840904}, "ground_truth": 0}, {"key": "24624736", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8175717993904731, "res": {"Yes": 0.8175717993904731, "No": 0.18242493740420945}, "ground_truth": 1}, {"key": "36928562", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.20181270194706463, "res": {"No": 0.7981847436483023, "Yes": 0.20181270194706463}, "ground_truth": 0}, {"key": "36928562", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.10669028705202774, "res": {"No": 0.8933067765646107, "Yes": 0.10669028705202774}, "ground_truth": 0}, {"key": "36928562", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.16451599782777274, "res": {"No": 0.8354811877388777, "Yes": 0.16451599782777274}, "ground_truth": 0}, {"key": "36928562", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.11920259986347324, "res": {"No": 0.8807946450301334, "Yes": 0.11920259986347324}, "ground_truth": 0}, {"key": "36928562", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.09534920962716803, "res": {"No": 0.9046480727072223, "Yes": 0.09534920962716803}, "ground_truth": 0}, {"key": "36928562", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.1645159782159387, "res": {"No": 0.8354810258935753, "Yes": 0.1645159782159387}, "ground_truth": 1}, {"key": "34941119", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6224574006009916, "res": {"Yes": 0.6224574006009916, "No": 0.3775394978295304}, "ground_truth": 0}, {"key": "34941119", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7772967159954982, "res": {"Yes": 0.7772967159954982, "No": 0.22269924435333766}, "ground_truth": 0}, {"key": "34941119", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.754911885011471, "res": {"Yes": 0.754911885011471, "No": 0.2450839988030444}, "ground_truth": 0}, {"key": "34941119", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8175703618249748, "res": {"Yes": 0.8175703618249748, "No": 0.18242461120329334}, "ground_truth": 0}, {"key": "34941119", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8933063971924055, "res": {"Yes": 0.8933063971924055, "No": 0.10669023617814659}, "ground_truth": 0}, {"key": "34941119", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9046461248049933, "res": {"Yes": 0.9046461248049933, "No": 0.09534900503017983}, "ground_truth": 1}, {"key": "30206231", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.32082012352942585, "res": {"No": 0.6791762068414748, "Yes": 0.32082012352942585}, "ground_truth": 0}, {"key": "30206231", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.3486434703495512, "res": {"No": 0.6513517540656899, "Yes": 0.3486434703495512}, "ground_truth": 0}, {"key": "30206231", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.2942136744511435, "res": {"No": 0.7057819358220674, "Yes": 0.2942136744511435}, "ground_truth": 0}, {"key": "30206231", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3486433041034292, "res": {"No": 0.6513514434770445, "Yes": 0.3486433041034292}, "ground_truth": 0}, {"key": "30206231", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.24508414488453484, "res": {"No": 0.7549122899778724, "Yes": 0.24508414488453484}, "ground_truth": 0}, {"key": "30206231", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.3486436781573152, "res": {"No": 0.6513521423017049, "Yes": 0.3486436781573152}, "ground_truth": 1}, {"key": "35584972", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.32082027650841827, "res": {"No": 0.6791764902159297, "Yes": 0.32082027650841827}, "ground_truth": 0}, {"key": "35584972", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.49999749565886403, "res": {"No": 0.49999749565886403, "Yes": 0.49999749565886403}, "ground_truth": 0}, {"key": "35584972", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6513523558316118, "res": {"Yes": 0.6513523558316118, "No": 0.348643802842033}, "ground_truth": 0}, {"key": "35584972", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6513521034780929, "res": {"Yes": 0.6513521034780929, "No": 0.3486436365957525}, "ground_truth": 0}, {"key": "35584972", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057814730755217, "res": {"Yes": 0.7057814730755217, "No": 0.2942134990861802}, "ground_truth": 0}, {"key": "35584972", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7549120200002474, "res": {"Yes": 0.7549120200002474, "No": 0.24508405723563015}, "ground_truth": 1}, {"key": "39277709", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7549120200002474, "res": {"Yes": 0.7549120200002474, "No": 0.24508405723563015}, "ground_truth": 0}, {"key": "39277709", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8670310703917056, "res": {"Yes": 0.8670310703917056, "No": 0.13296352897868652}, "ground_truth": 0}, {"key": "39277709", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7549115475396359, "res": {"Yes": 0.7549115475396359, "No": 0.24508391115419195}, "ground_truth": 0}, {"key": "39277709", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6513521423017049, "res": {"Yes": 0.6513521423017049, "No": 0.3486436781573152}, "ground_truth": 0}, {"key": "39277709", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791752352728125, "res": {"Yes": 0.6791752352728125, "No": 0.3208196645928861}, "ground_truth": 0}, {"key": "39277709", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057822933991513, "res": {"Yes": 0.7057822933991513, "No": 0.2942138147431894}, "ground_truth": 1}, {"key": "36123657", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.26894047552850664, "res": {"No": 0.7310560075662741, "Yes": 0.26894047552850664}, "ground_truth": 0}, {"key": "36123657", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057826509764165, "res": {"Yes": 0.7057826509764165, "No": 0.2942139901083408}, "ground_truth": 0}, {"key": "36123657", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772967159954982, "res": {"Yes": 0.7772967159954982, "No": 0.22269924435333766}, "ground_truth": 0}, {"key": "36123657", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791751745498174, "res": {"Yes": 0.6791751745498174, "No": 0.3208196263482041}, "ground_truth": 0}, {"key": "36123657", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926638444547924, "res": {"Yes": 0.5926638444547924, "No": 0.4073315062208192}, "ground_truth": 0}, {"key": "36123657", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5312067345258192, "res": {"Yes": 0.5312067345258192, "No": 0.46878829785111287}, "ground_truth": 1}, {"key": "33363938", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.06008653422741624, "res": {"No": 0.9399116411594508, "Yes": 0.06008653422741624}, "ground_truth": 0}, {"key": "33363938", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4999986877472098, "res": {"No": 0.4999986877472098, "Yes": 0.4999986877472098}, "ground_truth": 0}, {"key": "33363938", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.4999983897248569, "res": {"No": 0.4999983897248569, "Yes": 0.4999983897248569}, "ground_truth": 0}, {"key": "33363938", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.49999737645018577, "res": {"No": 0.49999737645018577, "Yes": 0.49999737645018577}, "ground_truth": 0}, {"key": "33363938", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3775395203326387, "res": {"No": 0.622457437702345, "Yes": 0.3775395203326387}, "ground_truth": 0}, {"key": "33363938", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772969476480059, "res": {"Yes": 0.7772969476480059, "No": 0.2226992974489814}, "ground_truth": 1}, {"key": "37349129", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4687890522846391, "res": {"No": 0.5312075894110023, "Yes": 0.4687890522846391}, "ground_truth": 0}, {"key": "37349129", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.2942139550353022, "res": {"No": 0.7057825458066138, "Yes": 0.2942139550353022}, "ground_truth": 0}, {"key": "37349129", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.26894066788979354, "res": {"No": 0.7310565086712827, "Yes": 0.26894066788979354}, "ground_truth": 0}, {"key": "37349129", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3775394978295304, "res": {"No": 0.6224574006009916, "Yes": 0.3775394978295304}, "ground_truth": 0}, {"key": "37349129", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.34864376128045543, "res": {"No": 0.6513522975961756, "Yes": 0.34864376128045543}, "ground_truth": 0}, {"key": "37349129", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.3486439690883928, "res": {"No": 0.6513526470088703, "Yes": 0.3486439690883928}, "ground_truth": 1}, {"key": "37160199", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4687891640526722, "res": {"No": 0.5312077160607761, "Yes": 0.4687891640526722}, "ground_truth": 0}, {"key": "37160199", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6791765914211209, "res": {"Yes": 0.6791765914211209, "No": 0.3208203147531778}, "ground_truth": 0}, {"key": "37160199", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.4687888287486529, "res": {"No": 0.5312073361115454, "Yes": 0.4687888287486529}, "ground_truth": 0}, {"key": "37160199", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4687893875888182, "res": {"No": 0.5312079693604143, "Yes": 0.4687893875888182}, "ground_truth": 0}, {"key": "37160199", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3486440106499951, "res": {"No": 0.6513527634798101, "Yes": 0.3486440106499951}, "ground_truth": 0}, {"key": "37160199", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6224574748037005, "res": {"Yes": 0.6224574748037005, "No": 0.3775395428357484}, "ground_truth": 1}, {"key": "35891053", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.32082035299794187, "res": {"No": 0.6791767128673701, "Yes": 0.32082035299794187}, "ground_truth": 0}, {"key": "35891053", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7549119525058562, "res": {"Yes": 0.7549119525058562, "No": 0.24508402801933554}, "ground_truth": 0}, {"key": "35891053", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772968781522464, "res": {"Yes": 0.7772968781522464, "No": 0.2226992974489814}, "ground_truth": 0}, {"key": "35891053", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312074944236919, "res": {"Yes": 0.5312074944236919, "No": 0.46878896845863177}, "ground_truth": 0}, {"key": "35891053", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7772967854912433, "res": {"Yes": 0.7772967854912433, "No": 0.22269924435333766}, "ground_truth": 0}, {"key": "35891053", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8354800299231736, "res": {"Yes": 0.8354800299231736, "No": 0.16451578209772674}, "ground_truth": 1}, {"key": "40694542", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.37753913777997955, "res": {"No": 0.6224567884289806, "Yes": 0.37753913777997955}, "ground_truth": 0}, {"key": "40694542", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5621735873514397, "res": {"Yes": 0.5621735873514397, "No": 0.4378212300513621}, "ground_truth": 0}, {"key": "40694542", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.49999803209826793, "res": {"No": 0.49999803209826793, "Yes": 0.49999803209826793}, "ground_truth": 0}, {"key": "40694542", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791760449132679, "res": {"Yes": 0.6791760449132679, "No": 0.3208200470399569}, "ground_truth": 0}, {"key": "40694542", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5312074944236919, "res": {"Yes": 0.5312074944236919, "No": 0.46878896845863177}, "ground_truth": 0}, {"key": "40694542", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621738219085876, "res": {"Yes": 0.5621738219085876, "No": 0.43782141272465247}, "ground_truth": 1}, {"key": "24645770", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5926646922678288, "res": {"Yes": 0.5926646922678288, "No": 0.4073320889136296}, "ground_truth": 0}, {"key": "24645770", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981842203177746, "res": {"Yes": 0.7981842203177746, "No": 0.20181258165735638}, "ground_truth": 0}, {"key": "24645770", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.731055550035914, "res": {"Yes": 0.731055550035914, "No": 0.2689403152275393}, "ground_truth": 0}, {"key": "24645770", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6513525499497697, "res": {"Yes": 0.6513525499497697, "No": 0.348643885965203}, "ground_truth": 0}, {"key": "24645770", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6513522587725544, "res": {"Yes": 0.6513522587725544, "No": 0.3486437197188828}, "ground_truth": 0}, {"key": "24645770", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6224571594422487, "res": {"Yes": 0.6224571594422487, "No": 0.3775393628109086}, "ground_truth": 1}, {"key": "37974587", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7310563125866733, "res": {"Yes": 0.7310563125866733, "No": 0.2689405717091329}, "ground_truth": 0}, {"key": "37974587", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513527634798101, "res": {"Yes": 0.6513527634798101, "No": 0.3486440106499951}, "ground_truth": 0}, {"key": "37974587", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5926640917334695, "res": {"Yes": 0.5926640917334695, "No": 0.4073316761728028}, "ground_truth": 0}, {"key": "37974587", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6513523558316118, "res": {"Yes": 0.6513523558316118, "No": 0.348643802842033}, "ground_truth": 0}, {"key": "37974587", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5312073361115454, "res": {"Yes": 0.5312073361115454, "No": 0.4687888287486529}, "ground_truth": 0}, {"key": "37974587", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6224568440809567, "res": {"Yes": 0.6224568440809567, "No": 0.37753916028306644}, "ground_truth": 1}, {"key": "40354149", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.06754658939083677, "res": {"No": 0.9324518278412331, "Yes": 0.06754658939083677}, "ground_truth": 0}, {"key": "40354149", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.2689402831673573, "res": {"No": 0.7310554846744574, "Yes": 0.2689402831673573}, "ground_truth": 0}, {"key": "40354149", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.26894044346830553, "res": {"No": 0.731055920417612, "Yes": 0.26894044346830553}, "ground_truth": 0}, {"key": "40354149", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.20181260571529228, "res": {"No": 0.7981842916810081, "Yes": 0.20181260571529228}, "ground_truth": 0}, {"key": "40354149", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.2689401549266675, "res": {"No": 0.7310551142929802, "Yes": 0.2689401549266675}, "ground_truth": 0}, {"key": "40354149", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4999977340763058, "res": {"No": 0.4999977340763058, "Yes": 0.4999977340763058}, "ground_truth": 1}, {"key": "35519470", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4378220912261125, "res": {"No": 0.5621746931217074, "Yes": 0.4378220912261125}, "ground_truth": 0}, {"key": "35519470", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4999988069562007, "res": {"No": 0.4999988069562007, "Yes": 0.4999988069562007}, "ground_truth": 0}, {"key": "35519470", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.4999983897248569, "res": {"No": 0.4999983897248569, "Yes": 0.4999983897248569}, "ground_truth": 0}, {"key": "35519470", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4999983301204076, "res": {"No": 0.4999983301204076, "Yes": 0.4999983301204076}, "ground_truth": 0}, {"key": "35519470", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791764902159297, "res": {"Yes": 0.6791764902159297, "No": 0.32082027650841827}, "ground_truth": 0}, {"key": "35519470", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5312075894110023, "res": {"Yes": 0.5312075894110023, "No": 0.4687890522846391}, "ground_truth": 1}, {"key": "36185624", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3486439690883928, "res": {"No": 0.6513526470088703, "Yes": 0.3486439690883928}, "ground_truth": 0}, {"key": "36185624", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9241387552903352, "res": {"Yes": 0.9241387552903352, "No": 0.07585793636889766}, "ground_truth": 0}, {"key": "36185624", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8807933456696563, "res": {"Yes": 0.8807933456696563, "No": 0.1192024293429083}, "ground_truth": 0}, {"key": "36185624", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8807931619218647, "res": {"Yes": 0.8807931619218647, "No": 0.11920240092283786}, "ground_truth": 0}, {"key": "36185624", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8519494723237138, "res": {"Yes": 0.8519494723237138, "No": 0.14804662604441737}, "ground_truth": 0}, {"key": "36185624", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9241379359316352, "res": {"Yes": 0.9241379359316352, "No": 0.07585786402516655}, "ground_truth": 1}, {"key": "39306113", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4073318461248573, "res": {"No": 0.5926643390122496, "Yes": 0.4073318461248573}, "ground_truth": 0}, {"key": "39306113", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513519481836685, "res": {"Yes": 0.6513519481836685, "No": 0.3486435534726419}, "ground_truth": 0}, {"key": "39306113", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224568440809567, "res": {"Yes": 0.6224568440809567, "No": 0.37753916028306644}, "ground_truth": 0}, {"key": "39306113", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.731055811481799, "res": {"Yes": 0.731055811481799, "No": 0.2689404114081082}, "ground_truth": 0}, {"key": "39306113", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.46878896845863177, "res": {"No": 0.5312074944236919, "Yes": 0.46878896845863177}, "ground_truth": 0}, {"key": "39306113", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8807935294174862, "res": {"Yes": 0.8807935294174862, "No": 0.1192024293429083}, "ground_truth": 1}, {"key": "19347718", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3775394303202135, "res": {"No": 0.6224572892969449, "Yes": 0.3775394303202135}, "ground_truth": 0}, {"key": "19347718", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.914897171720979, "res": {"Yes": 0.914897171720979, "No": 0.0850987032524629}, "ground_truth": 0}, {"key": "19347718", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8354802789156627, "res": {"Yes": 0.8354802789156627, "No": 0.16451582132135043}, "ground_truth": 0}, {"key": "19347718", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9399091131204861, "res": {"Yes": 0.9399091131204861, "No": 0.06008637664441563}, "ground_truth": 0}, {"key": "19347718", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9046467111972646, "res": {"Yes": 0.9046467111972646, "No": 0.09534907322912711}, "ground_truth": 0}, {"key": "19347718", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057825458066138, "res": {"Yes": 0.7057825458066138, "No": 0.2942139550353022}, "ground_truth": 1}, {"key": "21870064", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7057818306523713, "res": {"Yes": 0.7057818306523713, "No": 0.2942136393781425}, "ground_truth": 0}, {"key": "21870064", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9706826040167517, "res": {"Yes": 0.9706826040167517, "No": 0.029312072099566832}, "ground_truth": 0}, {"key": "21870064", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9626679913650915, "res": {"Yes": 0.9626679913650915, "No": 0.03732669224645538}, "ground_truth": 0}, {"key": "21870064", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981836850937263, "res": {"Yes": 0.7981836850937263, "No": 0.2018124373098011}, "ground_truth": 0}, {"key": "21870064", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8519494723237138, "res": {"Yes": 0.8519494723237138, "No": 0.14804662604441737}, "ground_truth": 0}, {"key": "21870064", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8519476569354404, "res": {"Yes": 0.8519476569354404, "No": 0.1480463083711622}, "ground_truth": 1}, {"key": "37675776", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4378219607449808, "res": {"No": 0.562174525580618, "Yes": 0.4378219607449808}, "ground_truth": 0}, {"key": "37675776", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7310549835701506, "res": {"Yes": 0.7310549835701506, "No": 0.26894009080634557}, "ground_truth": 0}, {"key": "37675776", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.4378212300513621, "res": {"No": 0.5621735873514397, "Yes": 0.4378212300513621}, "ground_truth": 0}, {"key": "37675776", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621734198106798, "res": {"Yes": 0.5621734198106798, "No": 0.4378210995704871}, "ground_truth": 0}, {"key": "37675776", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310538288528385, "res": {"Yes": 0.7310538288528385, "No": 0.2689396740246255}, "ground_truth": 0}, {"key": "37675776", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772958588818198, "res": {"Yes": 0.7772958588818198, "No": 0.22269897887530887}, "ground_truth": 1}, {"key": "38107017", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.32082012352942585, "res": {"No": 0.6791761663594195, "Yes": 0.32082012352942585}, "ground_truth": 0}, {"key": "38107017", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8354797809307587, "res": {"Yes": 0.8354797809307587, "No": 0.16451572326230876}, "ground_truth": 0}, {"key": "38107017", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8175705323834611, "res": {"Yes": 0.8175705323834611, "No": 0.18242463295000294}, "ground_truth": 0}, {"key": "38107017", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8519491168627682, "res": {"Yes": 0.8519491168627682, "No": 0.14804655545030174}, "ground_truth": 0}, {"key": "38107017", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8807925188048963, "res": {"Yes": 0.8807925188048963, "No": 0.11920231566266719}, "ground_truth": 0}, {"key": "38107017", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9324494449178069, "res": {"Yes": 0.9324494449178069, "No": 0.06754641224308855}, "ground_truth": 1}, {"key": "40046472", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621752627617851, "res": {"Yes": 0.5621752627617851, "No": 0.43782253486225103}, "ground_truth": 0}, {"key": "40046472", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5926644449889013, "res": {"Yes": 0.5926644449889013, "No": 0.40733191896147375}, "ground_truth": 0}, {"key": "40046472", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.679176105636341, "res": {"Yes": 0.679176105636341, "No": 0.3208200852846891}, "ground_truth": 0}, {"key": "40046472", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981839824403755, "res": {"Yes": 0.7981839824403755, "No": 0.20181250948356583}, "ground_truth": 0}, {"key": "40046472", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.37753909277380987, "res": {"No": 0.6224567327770094, "Yes": 0.37753909277380987}, "ground_truth": 0}, {"key": "40046472", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7981843630442481, "res": {"Yes": 0.7981843630442481, "No": 0.20181260571529228}, "ground_truth": 1}, {"key": "32157820", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.32082050597704376, "res": {"No": 0.6791769760009848, "Yes": 0.32082050597704376}, "ground_truth": 0}, {"key": "32157820", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5312077793856743, "res": {"Yes": 0.5312077793856743, "No": 0.4687892199366987}, "ground_truth": 0}, {"key": "32157820", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5926645509655719, "res": {"Yes": 0.5926645509655719, "No": 0.4073319917981033}, "ground_truth": 0}, {"key": "32157820", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224570295875796, "res": {"Yes": 0.6224570295875796, "No": 0.3775392727985209}, "ground_truth": 0}, {"key": "32157820", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.29421416547359674, "res": {"No": 0.7057830716557839, "Yes": 0.29421416547359674}, "ground_truth": 0}, {"key": "32157820", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6513525499497697, "res": {"Yes": 0.6513525499497697, "No": 0.348643885965203}, "ground_truth": 1}, {"key": "41004037", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6513522975961756, "res": {"Yes": 0.6513522975961756, "No": 0.34864376128045543}, "ground_truth": 0}, {"key": "41004037", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9579083019223802, "res": {"Yes": 0.9579083019223802, "No": 0.04208754940237751}, "ground_truth": 0}, {"key": "41004037", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8175711658867216, "res": {"Yes": 0.8175711658867216, "No": 0.1824247851770427}, "ground_truth": 0}, {"key": "41004037", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7772970171437718, "res": {"Yes": 0.7772970171437718, "No": 0.222699323996808}, "ground_truth": 0}, {"key": "41004037", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9241390582466772, "res": {"Yes": 0.9241390582466772, "No": 0.07585795445484123}, "ground_truth": 0}, {"key": "41004037", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9046478772427954, "res": {"Yes": 0.9046478772427954, "No": 0.09534918689414766}, "ground_truth": 1}, {"key": "21387993", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6513523558316118, "res": {"Yes": 0.6513523558316118, "No": 0.348643802842033}, "ground_truth": 0}, {"key": "21387993", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8670330471187292, "res": {"Yes": 0.8670330471187292, "No": 0.13296381428777349}, "ground_truth": 0}, {"key": "21387993", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8670328662415593, "res": {"Yes": 0.8670328662415593, "No": 0.1329637825867336}, "ground_truth": 0}, {"key": "21387993", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981840656974571, "res": {"Yes": 0.7981840656974571, "No": 0.20181253354149314}, "ground_truth": 0}, {"key": "21387993", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8670327758029885, "res": {"Yes": 0.8670327758029885, "No": 0.1329637825867336}, "ground_truth": 0}, {"key": "21387993", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8175717262938613, "res": {"Yes": 0.8175717262938613, "No": 0.18242491565746358}, "ground_truth": 1}, {"key": "34665539", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2942142706928005, "res": {"No": 0.7057833661314902, "Yes": 0.2942142706928005}, "ground_truth": 0}, {"key": "34665539", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5312075577485637, "res": {"Yes": 0.5312075577485637, "No": 0.468789024342635}, "ground_truth": 0}, {"key": "34665539", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6513526470088703, "res": {"Yes": 0.6513526470088703, "No": 0.3486439690883928}, "ground_truth": 0}, {"key": "34665539", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621745590888318, "res": {"Yes": 0.5621745590888318, "No": 0.43782198684120405}, "ground_truth": 0}, {"key": "34665539", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6513526470088703, "res": {"Yes": 0.6513526470088703, "No": 0.3486439690883928}, "ground_truth": 0}, {"key": "34665539", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6224575861077806, "res": {"Yes": 0.6224575861077806, "No": 0.37753961034508543}, "ground_truth": 1}, {"key": "37872111", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4378218824563205, "res": {"No": 0.5621744250559882, "Yes": 0.4378218824563205}, "ground_truth": 0}, {"key": "37872111", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.43782240438098713, "res": {"No": 0.5621750952205259, "Yes": 0.43782240438098713}, "ground_truth": 0}, {"key": "37872111", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.4999975552632138, "res": {"No": 0.4999975552632138, "Yes": 0.4999975552632138}, "ground_truth": 0}, {"key": "37872111", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3775394303202135, "res": {"No": 0.6224572892969449, "Yes": 0.3775394303202135}, "ground_truth": 0}, {"key": "37872111", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.468788772864673, "res": {"No": 0.5312072727867, "Yes": 0.468788772864673}, "ground_truth": 0}, {"key": "37872111", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621737213840836, "res": {"Yes": 0.5621737213840836, "No": 0.4378213344360901}, "ground_truth": 1}, {"key": "36629542", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.43782172587904183, "res": {"No": 0.5621742240067827, "Yes": 0.43782172587904183}, "ground_truth": 0}, {"key": "36629542", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.817571080607408, "res": {"Yes": 0.817571080607408, "No": 0.18242476343031494}, "ground_truth": 0}, {"key": "36629542", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7549109400907128, "res": {"Yes": 0.7549109400907128, "No": 0.24508370664032478}, "ground_truth": 0}, {"key": "36629542", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.79818383971397, "res": {"Yes": 0.79818383971397, "No": 0.2018124854256414}, "ground_truth": 0}, {"key": "36629542", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057824196028714, "res": {"Yes": 0.7057824196028714, "No": 0.29421388488923744}, "ground_truth": 0}, {"key": "36629542", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6791760449132679, "res": {"Yes": 0.6791760449132679, "No": 0.3208200470399569}, "ground_truth": 1}, {"key": "36487527", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7981843630442481, "res": {"Yes": 0.7981843630442481, "No": 0.20181260571529228}, "ground_truth": 0}, {"key": "36487527", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8519493834584634, "res": {"Yes": 0.8519493834584634, "No": 0.1480466083958853}, "ground_truth": 0}, {"key": "36487527", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8807928863002493, "res": {"Yes": 0.8807928863002493, "No": 0.11920234408271731}, "ground_truth": 0}, {"key": "36487527", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8519495611889732, "res": {"Yes": 0.8519495611889732, "No": 0.14804662604441737}, "ground_truth": 0}, {"key": "36487527", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175712389832833, "res": {"Yes": 0.8175712389832833, "No": 0.18242480692377303}, "ground_truth": 0}, {"key": "36487527", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8354790339539593, "res": {"Yes": 0.8354790339539593, "No": 0.1645155859797486}, "ground_truth": 1}, {"key": "37344756", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3486439275267954, "res": {"No": 0.6513526081852282, "Yes": 0.3486439275267954}, "ground_truth": 0}, {"key": "37344756", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.46878891257463523, "res": {"No": 0.5312074310988276, "Yes": 0.46878891257463523}, "ground_truth": 0}, {"key": "37344756", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.24508426174978987, "res": {"No": 0.7549126949444909, "Yes": 0.24508426174978987}, "ground_truth": 0}, {"key": "37344756", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8354801170705364, "res": {"Yes": 0.8354801170705364, "No": 0.16451578209772674}, "ground_truth": 0}, {"key": "37344756", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6513521423017049, "res": {"Yes": 0.6513521423017049, "No": 0.3486436781573152}, "ground_truth": 0}, {"key": "37344756", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8354806150556408, "res": {"Yes": 0.8354806150556408, "No": 0.1645158801568035}, "ground_truth": 1}, {"key": "38707722", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2689401549266675, "res": {"No": 0.7310551578672618, "Yes": 0.2689401549266675}, "ground_truth": 0}, {"key": "38707722", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.43781955989909854, "res": {"No": 0.5621714428334836, "Yes": 0.43781955989909854}, "ground_truth": 0}, {"key": "38707722", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.3208195881035266, "res": {"No": 0.6791751138268275, "Yes": 0.3208195881035266}, "ground_truth": 0}, {"key": "38707722", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4999976744719347, "res": {"No": 0.4999976744719347, "Yes": 0.4999976744719347}, "ground_truth": 0}, {"key": "38707722", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3208197793269595, "res": {"No": 0.6791754984058547, "Yes": 0.3208197793269595}, "ground_truth": 0}, {"key": "38707722", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5926621841577757, "res": {"Yes": 0.5926621841577757, "No": 0.40733036511648}, "ground_truth": 1}, {"key": "37093419", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.02297731810901412, "res": {"No": 0.9770204856898742, "Yes": 0.02297731810901412}, "ground_truth": 0}, {"key": "37093419", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4073313362689065, "res": {"No": 0.5926635971762185, "Yes": 0.4073313362689065}, "ground_truth": 0}, {"key": "37093419", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.4073313605477468, "res": {"No": 0.5926636325017227, "Yes": 0.4073313605477468}, "ground_truth": 0}, {"key": "37093419", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3775395203326387, "res": {"No": 0.622457437702345, "Yes": 0.3775395203326387}, "ground_truth": 0}, {"key": "37093419", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.2689405717091329, "res": {"No": 0.7310562472251484, "Yes": 0.2689405717091329}, "ground_truth": 0}, {"key": "37093419", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.37753916028306644, "res": {"No": 0.6224568440809567, "Yes": 0.37753916028306644}, "ground_truth": 1}, {"key": "35547391", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3486440937732147, "res": {"No": 0.6513528993625997, "Yes": 0.3486440937732147}, "ground_truth": 0}, {"key": "35547391", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.49999803209826793, "res": {"No": 0.49999803209826793, "Yes": 0.49999803209826793}, "ground_truth": 0}, {"key": "35547391", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.49999821091153046, "res": {"No": 0.49999821091153046, "Yes": 0.49999821091153046}, "ground_truth": 0}, {"key": "35547391", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621744920724061, "res": {"Yes": 0.5621744920724061, "No": 0.4378219346487591}, "ground_truth": 0}, {"key": "35547391", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.622457066688911, "res": {"Yes": 0.622457066688911, "No": 0.3775392953016158}, "ground_truth": 0}, {"key": "35547391", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6791758829850997, "res": {"Yes": 0.6791758829850997, "No": 0.3208199705505063}, "ground_truth": 1}, {"key": "37173168", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.037326790139729955, "res": {"No": 0.9626706415836411, "Yes": 0.037326790139729955}, "ground_truth": 0}, {"key": "37173168", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.29421413040053723, "res": {"No": 0.7057830085538628, "Yes": 0.29421413040053723}, "ground_truth": 0}, {"key": "37173168", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.49999892616522, "res": {"No": 0.49999892616522, "Yes": 0.49999892616522}, "ground_truth": 0}, {"key": "37173168", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.32082035299794187, "res": {"No": 0.6791767128673701, "Yes": 0.32082035299794187}, "ground_truth": 0}, {"key": "37173168", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.11920274196413036, "res": {"No": 0.8807958393934747, "Yes": 0.11920274196413036}, "ground_truth": 0}, {"key": "37173168", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.1645161743343844, "res": {"No": 0.8354820218651642, "Yes": 0.1645161743343844}, "ground_truth": 1}, {"key": "30725298", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7981843630442481, "res": {"Yes": 0.7981843630442481, "No": 0.20181260571529228}, "ground_truth": 0}, {"key": "30725298", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.867033486392013, "res": {"Yes": 0.867033486392013, "No": 0.13296387768987597}, "ground_truth": 0}, {"key": "30725298", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8807938969132609, "res": {"Yes": 0.8807938969132609, "No": 0.11920248618306951}, "ground_truth": 0}, {"key": "30725298", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8933067765646107, "res": {"Yes": 0.8933067765646107, "No": 0.10669028705202774}, "ground_truth": 0}, {"key": "30725298", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9324505842740206, "res": {"Yes": 0.9324505842740206, "No": 0.06754649276473469}, "ground_truth": 0}, {"key": "30725298", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8670327758029885, "res": {"Yes": 0.8670327758029885, "No": 0.1329637825867336}, "ground_truth": 1}, {"key": "33830573", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621747936463851, "res": {"Yes": 0.5621747936463851, "No": 0.4378221695148102}, "ground_truth": 0}, {"key": "33830573", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.67917572105697, "res": {"Yes": 0.67917572105697, "No": 0.32081989406107386}, "ground_truth": 0}, {"key": "33830573", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.437822299996004, "res": {"No": 0.5621749611875544, "Yes": 0.437822299996004}, "ground_truth": 0}, {"key": "33830573", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7057824827047398, "res": {"Yes": 0.7057824827047398, "No": 0.2942139199622677}, "ground_truth": 0}, {"key": "33830573", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7772970866395437, "res": {"Yes": 0.7772970866395437, "No": 0.2226993505446378}, "ground_truth": 0}, {"key": "33830573", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621743245313765, "res": {"Yes": 0.5621743245313765, "No": 0.43782180416767413}, "ground_truth": 1}, {"key": "33415474", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.22269924435333766, "res": {"No": 0.7772967159954982, "Yes": 0.22269924435333766}, "ground_truth": 0}, {"key": "33415474", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5312073677739709, "res": {"Yes": 0.5312073677739709, "No": 0.46878885669064535}, "ground_truth": 0}, {"key": "33415474", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.348643885965203, "res": {"No": 0.6513525499497697, "Yes": 0.348643885965203}, "ground_truth": 0}, {"key": "33415474", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.2226993505446378, "res": {"No": 0.7772971561353219, "Yes": 0.2226993505446378}, "ground_truth": 0}, {"key": "33415474", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.32082012352942585, "res": {"No": 0.6791762068414748, "Yes": 0.32082012352942585}, "ground_truth": 0}, {"key": "33415474", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.3208196263482041, "res": {"No": 0.6791751745498174, "Yes": 0.3208196263482041}, "ground_truth": 1}, {"key": "37383994", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5926646922678288, "res": {"Yes": 0.5926646922678288, "No": 0.4073320889136296}, "ground_truth": 0}, {"key": "37383994", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8670318843375813, "res": {"Yes": 0.8670318843375813, "No": 0.1329636557826496}, "ground_truth": 0}, {"key": "37383994", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.932450375855097, "res": {"Yes": 0.932450375855097, "No": 0.06754647666039779}, "ground_truth": 0}, {"key": "37383994", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8933065835506615, "res": {"Yes": 0.8933065835506615, "No": 0.10669026161508413}, "ground_truth": 0}, {"key": "37383994", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8519500689906342, "res": {"Yes": 0.8519500689906342, "No": 0.1480467319356539}, "ground_truth": 0}, {"key": "37383994", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8354801170705364, "res": {"Yes": 0.8354801170705364, "No": 0.16451578209772674}, "ground_truth": 1}, {"key": "38576819", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621746596134856, "res": {"Yes": 0.5621746596134856, "No": 0.43782206512988303}, "ground_truth": 0}, {"key": "38576819", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981842203177746, "res": {"Yes": 0.7981842203177746, "No": 0.20181258165735638}, "ground_truth": 0}, {"key": "38576819", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.754912222483457, "res": {"Yes": 0.754912222483457, "No": 0.2450841156682298}, "ground_truth": 0}, {"key": "38576819", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6513525111261335, "res": {"Yes": 0.6513525111261335, "No": 0.348643885965203}, "ground_truth": 0}, {"key": "38576819", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5621747936463851, "res": {"Yes": 0.5621747936463851, "No": 0.4378221695148102}, "ground_truth": 0}, {"key": "38576819", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772962990211583, "res": {"Yes": 0.7772962990211583, "No": 0.2226991116142837}, "ground_truth": 1}, {"key": "34500226", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.46878910816865227, "res": {"No": 0.5312076527358854, "Yes": 0.46878910816865227}, "ground_truth": 0}, {"key": "34500226", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513503370061992, "res": {"Yes": 0.6513503370061992, "No": 0.3486427222426265}, "ground_truth": 0}, {"key": "34500226", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8670299076132088, "res": {"Yes": 0.8670299076132088, "No": 0.13296333877296868}, "ground_truth": 0}, {"key": "34500226", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310533277496668, "res": {"Yes": 0.7310533277496668, "No": 0.2689394816640494}, "ground_truth": 0}, {"key": "34500226", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8354761207508226, "res": {"Yes": 0.8354761207508226, "No": 0.1645149976272169}, "ground_truth": 0}, {"key": "34500226", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057801689732529, "res": {"Yes": 0.7057801689732529, "No": 0.29421293791900016}, "ground_truth": 1}, {"key": "39856394", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.11920268512384719, "res": {"No": 0.8807952881486544, "Yes": 0.11920268512384719}, "ground_truth": 0}, {"key": "39856394", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5621749276793165, "res": {"Yes": 0.5621749276793165, "No": 0.43782227389976214}, "ground_truth": 0}, {"key": "39856394", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7310572058614313, "res": {"Yes": 0.7310572058614313, "No": 0.26894092437172346}, "ground_truth": 0}, {"key": "39856394", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.56217506171228, "res": {"Yes": 0.56217506171228, "No": 0.437822378284739}, "ground_truth": 0}, {"key": "39856394", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6513531128927547, "res": {"Yes": 0.6513531128927547, "No": 0.34864421845808113}, "ground_truth": 0}, {"key": "39856394", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7981839824403755, "res": {"Yes": 0.7981839824403755, "No": 0.20181250948356583}, "ground_truth": 1}, {"key": "35499522", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.06008637664441563, "res": {"No": 0.9399090080774629, "Yes": 0.06008637664441563}, "ground_truth": 0}, {"key": "35499522", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.1824247416835898, "res": {"No": 0.8175710075108604, "Yes": 0.1824247416835898}, "ground_truth": 0}, {"key": "35499522", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.2226990054230975, "res": {"No": 0.7772959283774883, "Yes": 0.2226990054230975}, "ground_truth": 0}, {"key": "35499522", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.20181241325188526, "res": {"No": 0.7981835304735124, "Yes": 0.20181241325188526}, "ground_truth": 0}, {"key": "35499522", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.1480465730988275, "res": {"No": 0.8519492057279907, "Yes": 0.1480465730988275}, "ground_truth": 0}, {"key": "35499522", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.16451582132135043, "res": {"No": 0.8354802789156627, "Yes": 0.16451582132135043}, "ground_truth": 1}, {"key": "30157766", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.32082054422183065, "res": {"No": 0.6791770974473028, "Yes": 0.32082054422183065}, "ground_truth": 0}, {"key": "30157766", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057831978596429, "res": {"Yes": 0.7057831978596429, "No": 0.2942142005466605}, "ground_truth": 0}, {"key": "30157766", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791770367241411, "res": {"Yes": 0.6791770367241411, "No": 0.32082050597704376}, "ground_truth": 0}, {"key": "30157766", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.49999809170268167, "res": {"No": 0.49999809170268167, "Yes": 0.49999809170268167}, "ground_truth": 0}, {"key": "30157766", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.37753961034508543, "res": {"No": 0.6224575861077806, "Yes": 0.37753961034508543}, "ground_truth": 0}, {"key": "30157766", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4378221956110458, "res": {"No": 0.562174827154615, "Yes": 0.4378221956110458}, "ground_truth": 1}, {"key": "40472346", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.40733189468260017, "res": {"No": 0.5926644096633487, "Yes": 0.40733189468260017}, "ground_truth": 0}, {"key": "40472346", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5621744250559882, "res": {"Yes": 0.5621744250559882, "No": 0.4378218824563205}, "ground_truth": 0}, {"key": "40472346", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.2942136393781425, "res": {"No": 0.7057818306523713, "Yes": 0.2942136393781425}, "ground_truth": 0}, {"key": "40472346", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.37753909277380987, "res": {"No": 0.6224567327770094, "Yes": 0.37753909277380987}, "ground_truth": 0}, {"key": "40472346", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.46878896845863177, "res": {"No": 0.5312074944236919, "Yes": 0.46878896845863177}, "ground_truth": 0}, {"key": "40472346", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.042087599574676046, "res": {"No": 0.9579093974483633, "Yes": 0.042087599574676046}, "ground_truth": 1}, {"key": "35305635", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3208206589562186, "res": {"No": 0.6791773605810664, "Yes": 0.3208206589562186}, "ground_truth": 0}, {"key": "35305635", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5312077160607761, "res": {"Yes": 0.5312077160607761, "No": 0.4687891640526722}, "ground_truth": 0}, {"key": "35305635", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.22269974876246426, "res": {"No": 0.7772985228868894, "Yes": 0.22269974876246426}, "ground_truth": 0}, {"key": "35305635", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.34864421845808113, "res": {"No": 0.6513531517164267, "Yes": 0.34864421845808113}, "ground_truth": 0}, {"key": "35305635", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.437822378284739, "res": {"No": 0.56217506171228, "Yes": 0.437822378284739}, "ground_truth": 0}, {"key": "35305635", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.377539812873169, "res": {"No": 0.6224579385708318, "Yes": 0.377539812873169}, "ground_truth": 1}, {"key": "32495926", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.46878832579307367, "res": {"No": 0.5312067661882088, "Yes": 0.46878832579307367}, "ground_truth": 0}, {"key": "32495926", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5312069878249893, "res": {"Yes": 0.5312069878249893, "No": 0.4687885213868459}, "ground_truth": 0}, {"key": "32495926", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.49999743605452135, "res": {"No": 0.49999743605452135, "Yes": 0.49999743605452135}, "ground_truth": 0}, {"key": "32495926", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310550489315625, "res": {"Yes": 0.7310550489315625, "No": 0.26894012286650465}, "ground_truth": 0}, {"key": "32495926", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224571037902444, "res": {"Yes": 0.6224571037902444, "No": 0.37753931780471206}, "ground_truth": 0}, {"key": "32495926", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057817044487567, "res": {"Yes": 0.7057817044487567, "No": 0.29421360430514565}, "ground_truth": 1}, {"key": "37353801", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7057813468719711, "res": {"Yes": 0.7057813468719711, "No": 0.2942134289402242}, "ground_truth": 0}, {"key": "37353801", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7549101751557272, "res": {"Yes": 0.7549101751557272, "No": 0.2450834436941749}, "ground_truth": 0}, {"key": "37353801", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8175703618249748, "res": {"Yes": 0.8175703618249748, "No": 0.18242461120329334}, "ground_truth": 0}, {"key": "37353801", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310554193130065, "res": {"Yes": 0.7310554193130065, "No": 0.2689402511071791}, "ground_truth": 0}, {"key": "37353801", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8807936212914155, "res": {"Yes": 0.8807936212914155, "No": 0.11920245776298552}, "ground_truth": 0}, {"key": "37353801", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7981817820777942, "res": {"Yes": 0.7981817820777942, "No": 0.2018119561520292}, "ground_truth": 1}, {"key": "30159904", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.32082046773226147, "res": {"No": 0.6791769355188836, "Yes": 0.32082046773226147}, "ground_truth": 0}, {"key": "30159904", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8354802789156627, "res": {"Yes": 0.8354802789156627, "No": 0.16451582132135043}, "ground_truth": 0}, {"key": "30159904", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621751622370236, "res": {"Yes": 0.5621751622370236, "No": 0.437822456573488}, "ground_truth": 0}, {"key": "30159904", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5926650101980302, "res": {"Yes": 0.5926650101980302, "No": 0.4073323074236484}, "ground_truth": 0}, {"key": "30159904", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8670331375573282, "res": {"Yes": 0.8670331375573282, "No": 0.13296384598882094}, "ground_truth": 0}, {"key": "30159904", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8670325044873327, "res": {"Yes": 0.8670325044873327, "No": 0.13296375088570125}, "ground_truth": 1}, {"key": "33698679", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5926648335701196, "res": {"Yes": 0.5926648335701196, "No": 0.40733218602917903}, "ground_truth": 0}, {"key": "33698679", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9465934534312528, "res": {"Yes": 0.9465934534312528, "No": 0.05340314573589099}, "ground_truth": 0}, {"key": "33698679", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772978742587272, "res": {"Yes": 0.7772978742587272, "No": 0.22269956292738996}, "ground_truth": 0}, {"key": "33698679", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791764902159297, "res": {"Yes": 0.6791764902159297, "No": 0.32082027650841827}, "ground_truth": 0}, {"key": "33698679", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926647275933984, "res": {"Yes": 0.5926647275933984, "No": 0.4073321131925148}, "ground_truth": 0}, {"key": "33698679", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9046468055592747, "res": {"Yes": 0.9046468055592747, "No": 0.09534907322912711}, "ground_truth": 1}, {"key": "40530172", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.06008654855316406, "res": {"No": 0.9399117462027683, "Yes": 0.06008654855316406}, "ground_truth": 0}, {"key": "40530172", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.32082035299794187, "res": {"No": 0.6791767128673701, "Yes": 0.32082035299794187}, "ground_truth": 0}, {"key": "40530172", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.13296384598882094, "res": {"No": 0.8670331375573282, "Yes": 0.13296384598882094}, "ground_truth": 0}, {"key": "40530172", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.0953491641611327, "res": {"No": 0.9046476817784108, "Yes": 0.0953491641611327}, "ground_truth": 0}, {"key": "40530172", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.26894044346830553, "res": {"No": 0.731055920417612, "Yes": 0.26894044346830553}, "ground_truth": 0}, {"key": "40530172", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.46878896845863177, "res": {"No": 0.5312074944236919, "Yes": 0.46878896845863177}, "ground_truth": 1}, {"key": "40652941", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.18242515487181094, "res": {"No": 0.8175728349265083, "Yes": 0.18242515487181094}, "ground_truth": 0}, {"key": "40652941", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981833044901768, "res": {"Yes": 0.7981833044901768, "No": 0.20181234107815496}, "ground_truth": 0}, {"key": "40652941", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8807937131653544, "res": {"Yes": 0.8807937131653544, "No": 0.11920245776298552}, "ground_truth": 0}, {"key": "40652941", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9324492364991379, "res": {"Yes": 0.9324492364991379, "No": 0.06754639613877084}, "ground_truth": 0}, {"key": "40652941", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8670322331717619, "res": {"Yes": 0.8670322331717619, "No": 0.13296368748365925}, "ground_truth": 0}, {"key": "40652941", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9148968717943631, "res": {"Yes": 0.9148968717943631, "No": 0.08509866267424875}, "ground_truth": 1}, {"key": "40122246", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.1645160174396091, "res": {"No": 0.8354812748863611, "Yes": 0.1645160174396091}, "ground_truth": 0}, {"key": "40122246", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.11920265670371576, "res": {"No": 0.8807950125263736, "Yes": 0.11920265670371576}, "ground_truth": 0}, {"key": "40122246", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.09534907322912711, "res": {"No": 0.9046469066614394, "Yes": 0.09534907322912711}, "ground_truth": 0}, {"key": "40122246", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.11920257144336215, "res": {"No": 0.8807944612820707, "Yes": 0.11920257144336215}, "ground_truth": 0}, {"key": "40122246", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.07585790019702349, "res": {"No": 0.9241384454487246, "Yes": 0.07585790019702349}, "ground_truth": 0}, {"key": "40122246", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.2942137445971581, "res": {"No": 0.7057820620257235, "Yes": 0.2942137445971581}, "ground_truth": 1}, {"key": "40032656", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.09534932329235117, "res": {"No": 0.9046491511324054, "Yes": 0.09534932329235117}, "ground_truth": 0}, {"key": "40032656", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9324499659646831, "res": {"Yes": 0.9324499659646831, "No": 0.06754644445173548}, "ground_truth": 0}, {"key": "40032656", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7549120200002474, "res": {"Yes": 0.7549120200002474, "No": 0.24508405723563015}, "ground_truth": 0}, {"key": "40032656", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8519497262244798, "res": {"Yes": 0.8519497262244798, "No": 0.14804666134148778}, "ground_truth": 0}, {"key": "40032656", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8807938050393029, "res": {"Yes": 0.8807938050393029, "No": 0.11920248618306951}, "ground_truth": 0}, {"key": "40032656", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8175713242626135, "res": {"Yes": 0.8175713242626135, "No": 0.18242482867050594}, "ground_truth": 1}, {"key": "38913680", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.16451511529755494, "res": {"No": 0.8354767058805519, "Yes": 0.16451511529755494}, "ground_truth": 0}, {"key": "38913680", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5312053413825426, "res": {"Yes": 0.5312053413825426, "No": 0.46878706840648643}, "ground_truth": 0}, {"key": "38913680", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5312068928377863, "res": {"Yes": 0.5312068928377863, "No": 0.4687884375609335}, "ground_truth": 0}, {"key": "38913680", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4378214649170351, "res": {"No": 0.5621738889249334, "Yes": 0.4378214649170351}, "ground_truth": 0}, {"key": "38913680", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.10669005811975357, "res": {"No": 0.8933048730495556, "Yes": 0.10669005811975357}, "ground_truth": 0}, {"key": "38913680", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621731182374378, "res": {"Yes": 0.5621731182374378, "No": 0.43782086470501}, "ground_truth": 1}, {"key": "17608039", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.22269924435333766, "res": {"No": 0.7772967159954982, "Yes": 0.22269924435333766}, "ground_truth": 0}, {"key": "17608039", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.3486427222426265, "res": {"No": 0.6513503758297058, "Yes": 0.3486427222426265}, "ground_truth": 0}, {"key": "17608039", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.3775381476454853, "res": {"No": 0.6224551745238371, "Yes": 0.3775381476454853}, "ground_truth": 0}, {"key": "17608039", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4999958267399548, "res": {"No": 0.4999958267399548, "Yes": 0.4999958267399548}, "ground_truth": 0}, {"key": "17608039", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3208197410822638, "res": {"No": 0.6791753972008264, "Yes": 0.3208197410822638}, "ground_truth": 0}, {"key": "17608039", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4073307535771728, "res": {"No": 0.5926627493647486, "Yes": 0.4073307535771728}, "ground_truth": 1}, {"key": "40434901", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.025957320151382593, "res": {"No": 0.9740412671601099, "Yes": 0.025957320151382593}, "ground_truth": 0}, {"key": "40434901", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.014063592990120936, "res": {"No": 0.9859341793934001, "Yes": 0.014063592990120936}, "ground_truth": 0}, {"key": "40434901", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772972951268969, "res": {"Yes": 0.7772972951268969, "No": 0.22269940364030685}, "ground_truth": 0}, {"key": "40434901", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312074944236919, "res": {"Yes": 0.5312074944236919, "No": 0.46878896845863177}, "ground_truth": 0}, {"key": "40434901", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8519492945932224, "res": {"Yes": 0.8519492945932224, "No": 0.14804659074735535}, "ground_truth": 0}, {"key": "40434901", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6513530546572509, "res": {"Yes": 0.6513530546572509, "No": 0.34864417689645405}, "ground_truth": 1}, {"key": "37680058", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621746261052657, "res": {"Yes": 0.5621746261052657, "No": 0.43782203903365513}, "ground_truth": 0}, {"key": "37680058", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5926642330356169, "res": {"Yes": 0.5926642330356169, "No": 0.4073317732882538}, "ground_truth": 0}, {"key": "37680058", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772951407602765, "res": {"Yes": 0.7772951407602765, "No": 0.22269879304087703}, "ground_truth": 0}, {"key": "37680058", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6513507252413694, "res": {"Yes": 0.6513507252413694, "No": 0.34864293004994457}, "ground_truth": 0}, {"key": "37680058", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310539595754616, "res": {"Yes": 0.7310539595754616, "No": 0.26893973814484806}, "ground_truth": 0}, {"key": "37680058", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8175704471042136, "res": {"Yes": 0.8175704471042136, "No": 0.18242463295000294}, "ground_truth": 1}, {"key": "37291821", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.222699722214587, "res": {"No": 0.7772984533909889, "Yes": 0.222699722214587}, "ground_truth": 0}, {"key": "37291821", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7310564433097404, "res": {"Yes": 0.7310564433097404, "No": 0.2689406358295695}, "ground_truth": 0}, {"key": "37291821", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791764294928223, "res": {"Yes": 0.6791764294928223, "No": 0.32082023826366335}, "ground_truth": 0}, {"key": "37291821", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8670325949258753, "res": {"Yes": 0.8670325949258753, "No": 0.13296375088570125}, "ground_truth": 0}, {"key": "37291821", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.754912829933412, "res": {"Yes": 0.754912829933412, "No": 0.24508432018243828}, "ground_truth": 0}, {"key": "37291821", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.731055920417612, "res": {"Yes": 0.731055920417612, "No": 0.26894044346830553}, "ground_truth": 1}, {"key": "41002743", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2942142005466605, "res": {"No": 0.7057831978596429, "Yes": 0.2942142005466605}, "ground_truth": 0}, {"key": "41002743", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5621735873514397, "res": {"Yes": 0.5621735873514397, "No": 0.4378212300513621}, "ground_truth": 0}, {"key": "41002743", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791762675645624, "res": {"Yes": 0.6791762675645624, "No": 0.3208201617741671}, "ground_truth": 0}, {"key": "41002743", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310546567631792, "res": {"Yes": 0.7310546567631792, "No": 0.2689399946258913}, "ground_truth": 0}, {"key": "41002743", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.40733196751922535, "res": {"No": 0.5926645156400129, "Yes": 0.40733196751922535}, "ground_truth": 0}, {"key": "41002743", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6791759437081583, "res": {"Yes": 0.6791759437081583, "No": 0.3208200087952293}, "ground_truth": 1}, {"key": "36322869", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7772971561353219, "res": {"Yes": 0.7772971561353219, "No": 0.2226993505446378}, "ground_truth": 0}, {"key": "36322869", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9148969740420619, "res": {"Yes": 0.9148969740420619, "No": 0.08509868296335339}, "ground_truth": 0}, {"key": "36322869", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9241386520097868, "res": {"Yes": 0.9241386520097868, "No": 0.07585791828295842}, "ground_truth": 0}, {"key": "36322869", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9399104821822947, "res": {"Yes": 0.9399104821822947, "No": 0.060086462598728366}, "ground_truth": 0}, {"key": "36322869", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8807932537957558, "res": {"Yes": 0.8807932537957558, "No": 0.11920240092283786}, "ground_truth": 0}, {"key": "36322869", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9046464146310109, "res": {"Yes": 0.9046464146310109, "No": 0.09534902776315685}, "ground_truth": 1}, {"key": "39459717", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5926649395468596, "res": {"Yes": 0.5926649395468596, "No": 0.4073322588658563}, "ground_truth": 0}, {"key": "39459717", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057825458066138, "res": {"Yes": 0.7057825458066138, "No": 0.2942139550353022}, "ground_truth": 0}, {"key": "39459717", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.59266476291897, "res": {"Yes": 0.59266476291897, "No": 0.4073321374714014}, "ground_truth": 0}, {"key": "39459717", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5926647275933984, "res": {"Yes": 0.5926647275933984, "No": 0.4073321131925148}, "ground_truth": 0}, {"key": "39459717", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.09534932329235117, "res": {"No": 0.9046491511324054, "Yes": 0.09534932329235117}, "ground_truth": 0}, {"key": "39459717", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5926650101980302, "res": {"Yes": 0.5926650101980302, "No": 0.4073323074236484}, "ground_truth": 1}, {"key": "36503727", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.29421413040053723, "res": {"No": 0.7057830085538628, "Yes": 0.29421413040053723}, "ground_truth": 0}, {"key": "36503727", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8933051592421195, "res": {"Yes": 0.8933051592421195, "No": 0.10669008355664866}, "ground_truth": 0}, {"key": "36503727", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7057826509764165, "res": {"Yes": 0.7057826509764165, "No": 0.2942139901083408}, "ground_truth": 0}, {"key": "36503727", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7772972951268969, "res": {"Yes": 0.7772972951268969, "No": 0.22269940364030685}, "ground_truth": 0}, {"key": "36503727", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8670315225837645, "res": {"Yes": 0.8670315225837645, "No": 0.13296359238065295}, "ground_truth": 0}, {"key": "36503727", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772945616304828, "res": {"Yes": 0.7772945616304828, "No": 0.22269860720660023}, "ground_truth": 1}, {"key": "35682367", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7057822933991513, "res": {"Yes": 0.7057822933991513, "No": 0.2942138147431894}, "ground_truth": 0}, {"key": "35682367", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7772971561353219, "res": {"Yes": 0.7772971561353219, "No": 0.2226993505446378}, "ground_truth": 0}, {"key": "35682367", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8933053522557609, "res": {"Yes": 0.8933053522557609, "No": 0.10669010899354982}, "ground_truth": 0}, {"key": "35682367", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8354802789156627, "res": {"Yes": 0.8354802789156627, "No": 0.16451582132135043}, "ground_truth": 0}, {"key": "35682367", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9465938801179333, "res": {"Yes": 0.9465938801179333, "No": 0.053403171200501316}, "ground_truth": 0}, {"key": "35682367", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8175712389832833, "res": {"Yes": 0.8175712389832833, "No": 0.18242480692377303}, "ground_truth": 1}, {"key": "36472353", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.24508420331715539, "res": {"No": 0.7549124924611544, "Yes": 0.24508420331715539}, "ground_truth": 0}, {"key": "36472353", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4999983301204076, "res": {"No": 0.4999983301204076, "Yes": 0.4999983301204076}, "ground_truth": 0}, {"key": "36472353", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5312075577485637, "res": {"Yes": 0.5312075577485637, "No": 0.468789024342635}, "ground_truth": 0}, {"key": "36472353", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224566585743889, "res": {"Yes": 0.6224566585743889, "No": 0.3775390477676455}, "ground_truth": 0}, {"key": "36472353", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926628906665761, "res": {"Yes": 0.5926628906665761, "No": 0.4073308506924038}, "ground_truth": 0}, {"key": "36472353", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.81757084913503, "res": {"Yes": 0.81757084913503, "No": 0.18242471993686724}, "ground_truth": 1}, {"key": "37651907", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.437821673686628, "res": {"No": 0.562174156990397, "Yes": 0.437821673686628}, "ground_truth": 0}, {"key": "37651907", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7310561165021163, "res": {"Yes": 0.7310561165021163, "No": 0.2689405075887116}, "ground_truth": 0}, {"key": "37651907", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.867033576830658, "res": {"Yes": 0.867033576830658, "No": 0.13296390939093852}, "ground_truth": 0}, {"key": "37651907", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981845176646232, "res": {"Yes": 0.7981845176646232, "No": 0.20181265383117272}, "ground_truth": 0}, {"key": "37651907", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9324502716456526, "res": {"Yes": 0.9324502716456526, "No": 0.06754647666039779}, "ground_truth": 0}, {"key": "37651907", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8670328662415593, "res": {"Yes": 0.8670328662415593, "No": 0.1329637825867336}, "ground_truth": 1}, {"key": "36255476", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5926641977100768, "res": {"Yes": 0.5926641977100768, "No": 0.4073317490093889}, "ground_truth": 0}, {"key": "36255476", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8933056317928327, "res": {"Yes": 0.8933056317928327, "No": 0.10669013443045705}, "ground_truth": 0}, {"key": "36255476", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5312071777994462, "res": {"Yes": 0.5312071777994462, "No": 0.4687886890387157}, "ground_truth": 0}, {"key": "36255476", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9046460237029159, "res": {"Yes": 0.9046460237029159, "No": 0.09534898229720824}, "ground_truth": 0}, {"key": "36255476", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8519494723237138, "res": {"Yes": 0.8519494723237138, "No": 0.14804662604441737}, "ground_truth": 0}, {"key": "36255476", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310561818636294, "res": {"Yes": 0.7310561818636294, "No": 0.2689405396489203}, "ground_truth": 1}, {"key": "37283518", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.22269956292738996, "res": {"No": 0.7772978047628848, "Yes": 0.22269956292738996}, "ground_truth": 0}, {"key": "37283518", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4999976148675707, "res": {"No": 0.4999976148675707, "Yes": 0.4999976148675707}, "ground_truth": 0}, {"key": "37283518", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.437821360532276, "res": {"No": 0.5621737548922496, "Yes": 0.437821360532276}, "ground_truth": 0}, {"key": "37283518", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.46878846550290265, "res": {"No": 0.5312069245001855, "Yes": 0.46878846550290265}, "ground_truth": 0}, {"key": "37283518", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4687886890387157, "res": {"No": 0.5312071777994462, "Yes": 0.4687886890387157}, "ground_truth": 0}, {"key": "37283518", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.46878826990915373, "res": {"No": 0.5312067028634314, "Yes": 0.46878826990915373}, "ground_truth": 1}, {"key": "34906785", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.49999844932931325, "res": {"No": 0.49999844932931325, "Yes": 0.49999844932931325}, "ground_truth": 0}, {"key": "34906785", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057820620257235, "res": {"Yes": 0.7057820620257235, "No": 0.2942137445971581}, "ground_truth": 0}, {"key": "34906785", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5926640917334695, "res": {"Yes": 0.5926640917334695, "No": 0.4073316761728028}, "ground_truth": 0}, {"key": "34906785", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621743245313765, "res": {"Yes": 0.5621743245313765, "No": 0.43782180416767413}, "ground_truth": 0}, {"key": "34906785", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926646216166962, "res": {"Yes": 0.5926646216166962, "No": 0.40733204035586357}, "ground_truth": 0}, {"key": "34906785", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.40733223458696244, "res": {"No": 0.5926649042212775, "Yes": 0.40733223458696244}, "ground_truth": 1}, {"key": "34965328", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2942135341591645, "res": {"No": 0.7057815782451646, "Yes": 0.2942135341591645}, "ground_truth": 0}, {"key": "34965328", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6224562875614192, "res": {"Yes": 0.6224562875614192, "No": 0.37753882273690426}, "ground_truth": 0}, {"key": "34965328", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.2942136393781425, "res": {"No": 0.7057818306523713, "Yes": 0.2942136393781425}, "ground_truth": 0}, {"key": "34965328", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224564730678764, "res": {"Yes": 0.6224564730678764, "No": 0.3775389352522581}, "ground_truth": 0}, {"key": "34965328", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5312071777994462, "res": {"Yes": 0.5312071777994462, "No": 0.4687886890387157}, "ground_truth": 0}, {"key": "34965328", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4073314091054318, "res": {"No": 0.5926637031527375, "Yes": 0.4073314091054318}, "ground_truth": 1}, {"key": "38788440", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7549123574722937, "res": {"Yes": 0.7549123574722937, "No": 0.24508414488453484}, "ground_truth": 0}, {"key": "38788440", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981836850937263, "res": {"Yes": 0.7981836850937263, "No": 0.2018124373098011}, "ground_truth": 0}, {"key": "38788440", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.622456973935587, "res": {"Yes": 0.622456973935587, "No": 0.37753922779233506}, "ground_truth": 0}, {"key": "38788440", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310549182087447, "res": {"Yes": 0.7310549182087447, "No": 0.2689400587461903}, "ground_truth": 0}, {"key": "38788440", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.622457066688911, "res": {"Yes": 0.622457066688911, "No": 0.3775392953016158}, "ground_truth": 0}, {"key": "38788440", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7549121549890477, "res": {"Yes": 0.7549121549890477, "No": 0.24508408645192822}, "ground_truth": 1}, {"key": "35046866", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7057828402821008, "res": {"Yes": 0.7057828402821008, "No": 0.29421406025443064}, "ground_truth": 0}, {"key": "35046866", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9626703116507583, "res": {"Yes": 0.9626703116507583, "No": 0.037326781240330745}, "ground_truth": 0}, {"key": "35046866", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9241381424925835, "res": {"Yes": 0.9241381424925835, "No": 0.07585788211109286}, "ground_truth": 0}, {"key": "35046866", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7549120874946446, "res": {"Yes": 0.7549120874946446, "No": 0.24508408645192822}, "ground_truth": 0}, {"key": "35046866", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9399106922686822, "res": {"Yes": 0.9399106922686822, "No": 0.060086476924459106}, "ground_truth": 0}, {"key": "35046866", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8670329566801396, "res": {"Yes": 0.8670329566801396, "No": 0.13296381428777349}, "ground_truth": 1}, {"key": "37629558", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4999983301204076, "res": {"No": 0.4999983301204076, "Yes": 0.4999983301204076}, "ground_truth": 0}, {"key": "37629558", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7772969476480059, "res": {"Yes": 0.7772969476480059, "No": 0.2226992974489814}, "ground_truth": 0}, {"key": "37629558", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7310563779482039, "res": {"Yes": 0.7310563779482039, "No": 0.26894060376934925}, "ground_truth": 0}, {"key": "37629558", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7772973646226938, "res": {"Yes": 0.7772973646226938, "No": 0.2226994301881461}, "ground_truth": 0}, {"key": "37629558", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175706054799661, "res": {"Yes": 0.8175706054799661, "No": 0.18242465469671512}, "ground_truth": 0}, {"key": "37629558", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621748941710807, "res": {"Yes": 0.5621748941710807, "No": 0.4378222478035218}, "ground_truth": 1}, {"key": "33859914", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2942139550353022, "res": {"No": 0.705782587874533, "Yes": 0.2942139550353022}, "ground_truth": 0}, {"key": "33859914", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4999976148675707, "res": {"No": 0.4999976148675707, "Yes": 0.4999976148675707}, "ground_truth": 0}, {"key": "33859914", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.4073314576631226, "res": {"No": 0.5926637738037608, "Yes": 0.4073314576631226}, "ground_truth": 0}, {"key": "33859914", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.46878832579307367, "res": {"No": 0.5312067661882088, "Yes": 0.46878832579307367}, "ground_truth": 0}, {"key": "33859914", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3486438444036155, "res": {"No": 0.6513524528906834, "Yes": 0.3486438444036155}, "ground_truth": 0}, {"key": "33859914", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6513514434770445, "res": {"Yes": 0.6513514434770445, "No": 0.3486433041034292}, "ground_truth": 1}, {"key": "39790523", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4999983301204076, "res": {"No": 0.4999983301204076, "Yes": 0.4999983301204076}, "ground_truth": 0}, {"key": "39790523", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.914897171720979, "res": {"Yes": 0.914897171720979, "No": 0.0850987032524629}, "ground_truth": 0}, {"key": "39790523", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.939909533292696, "res": {"Yes": 0.939909533292696, "No": 0.06008640529583954}, "ground_truth": 0}, {"key": "39790523", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.562174827154615, "res": {"Yes": 0.562174827154615, "No": 0.4378221956110458}, "ground_truth": 0}, {"key": "39790523", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057826509764165, "res": {"Yes": 0.7057826509764165, "No": 0.2942139901083408}, "ground_truth": 0}, {"key": "39790523", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.79818383971397, "res": {"Yes": 0.79818383971397, "No": 0.2018124854256414}, "ground_truth": 1}, {"key": "33509656", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7057820620257235, "res": {"Yes": 0.7057820620257235, "No": 0.2942137445971581}, "ground_truth": 0}, {"key": "33509656", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.46878888463263946, "res": {"No": 0.5312073994363983, "Yes": 0.46878888463263946}, "ground_truth": 0}, {"key": "33509656", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8354796066361124, "res": {"Yes": 0.8354796066361124, "No": 0.16451568403870845}, "ground_truth": 0}, {"key": "33509656", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.754912222483457, "res": {"Yes": 0.754912222483457, "No": 0.2450841156682298}, "ground_truth": 0}, {"key": "33509656", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791751745498174, "res": {"Yes": 0.6791751745498174, "No": 0.3208196263482041}, "ground_truth": 0}, {"key": "33509656", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8354806150556408, "res": {"Yes": 0.8354806150556408, "No": 0.1645158801568035}, "ground_truth": 1}, {"key": "17380923", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.46878826990915373, "res": {"No": 0.5312067028634314, "Yes": 0.46878826990915373}, "ground_truth": 0}, {"key": "17380923", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8175700450735947, "res": {"Yes": 0.8175700450735947, "No": 0.1824245459631801}, "ground_truth": 0}, {"key": "17380923", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8519477331055, "res": {"Yes": 0.8519477331055, "No": 0.1480463083711622}, "ground_truth": 0}, {"key": "17380923", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.817571080607408, "res": {"Yes": 0.817571080607408, "No": 0.18242476343031494}, "ground_truth": 0}, {"key": "17380923", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175692531956813, "res": {"Yes": 0.8175692531956813, "No": 0.18242435024298043}, "ground_truth": 0}, {"key": "17380923", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6791751138268275, "res": {"Yes": 0.6791751138268275, "No": 0.3208195881035266}, "ground_truth": 1}, {"key": "36202526", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7057819989238926, "res": {"Yes": 0.7057819989238926, "No": 0.2942137095241487}, "ground_truth": 0}, {"key": "36202526", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8807932537957558, "res": {"Yes": 0.8807932537957558, "No": 0.11920240092283786}, "ground_truth": 0}, {"key": "36202526", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791756603339313, "res": {"Yes": 0.6791756603339313, "No": 0.3208198558163645}, "ground_truth": 0}, {"key": "36202526", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791759437081583, "res": {"Yes": 0.6791759437081583, "No": 0.3208200087952293}, "ground_truth": 0}, {"key": "36202526", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8807934375435664, "res": {"Yes": 0.8807934375435664, "No": 0.1192024293429083}, "ground_truth": 0}, {"key": "36202526", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9046471021256566, "res": {"Yes": 0.9046471021256566, "No": 0.09534909596212039}, "ground_truth": 1}, {"key": "26419232", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6224559907512027, "res": {"Yes": 0.6224559907512027, "No": 0.37753864271240783}, "ground_truth": 0}, {"key": "26419232", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6224561020550173, "res": {"Yes": 0.6224561020550173, "No": 0.377538710221584}, "ground_truth": 0}, {"key": "26419232", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791749518988812, "res": {"Yes": 0.6791749518988812, "No": 0.32081951161418537}, "ground_truth": 0}, {"key": "26419232", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224559907512027, "res": {"Yes": 0.6224559907512027, "No": 0.37753864271240783}, "ground_truth": 0}, {"key": "26419232", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7549108051021296, "res": {"Yes": 0.7549108051021296, "No": 0.24508364820782266}, "ground_truth": 0}, {"key": "26419232", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6513517540656899, "res": {"Yes": 0.6513517540656899, "No": 0.3486434703495512}, "ground_truth": 1}, {"key": "34232398", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.59266476291897, "res": {"Yes": 0.59266476291897, "No": 0.4073321374714014}, "ground_truth": 0}, {"key": "34232398", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9046465157331319, "res": {"Yes": 0.9046465157331319, "No": 0.09534905049613927}, "ground_truth": 0}, {"key": "34232398", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.46878796254771316, "res": {"No": 0.5312063545772905, "Yes": 0.46878796254771316}, "ground_truth": 0}, {"key": "34232398", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4687891640526722, "res": {"No": 0.5312077160607761, "Yes": 0.4687891640526722}, "ground_truth": 0}, {"key": "34232398", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.622457066688911, "res": {"Yes": 0.622457066688911, "No": 0.3775392953016158}, "ground_truth": 0}, {"key": "34232398", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057812837702042, "res": {"Yes": 0.7057812837702042, "No": 0.2942133938672524}, "ground_truth": 1}, {"key": "33586045", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5926646922678288, "res": {"Yes": 0.5926646922678288, "No": 0.4073320889136296}, "ground_truth": 0}, {"key": "33586045", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.962668762402212, "res": {"Yes": 0.962668762402212, "No": 0.03732671894459571}, "ground_truth": 0}, {"key": "33586045", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8354801170705364, "res": {"Yes": 0.8354801170705364, "No": 0.16451578209772674}, "ground_truth": 0}, {"key": "33586045", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7057819989238926, "res": {"Yes": 0.7057819989238926, "No": 0.2942137095241487}, "ground_truth": 0}, {"key": "33586045", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8519493834584634, "res": {"Yes": 0.8519493834584634, "No": 0.1480466083958853}, "ground_truth": 0}, {"key": "33586045", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9626674390877197, "res": {"Yes": 0.9626674390877197, "No": 0.037326665548334144}, "ground_truth": 1}, {"key": "32281151", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.13296394109200865, "res": {"No": 0.8670337577079761, "Yes": 0.13296394109200865}, "ground_truth": 0}, {"key": "32281151", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6791768140725944, "res": {"Yes": 0.6791768140725944, "No": 0.32082042948748374}, "ground_truth": 0}, {"key": "32281151", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621750282040362, "res": {"Yes": 0.5621750282040362, "No": 0.43782235218849247}, "ground_truth": 0}, {"key": "32281151", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224577530639378, "res": {"Yes": 0.6224577530639378, "No": 0.37753972286067405}, "ground_truth": 0}, {"key": "32281151", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310561818636294, "res": {"Yes": 0.7310561818636294, "No": 0.2689405396489203}, "ground_truth": 0}, {"key": "32281151", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057826509764165, "res": {"Yes": 0.7057826509764165, "No": 0.2942139901083408}, "ground_truth": 1}, {"key": "37308159", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3486438444036155, "res": {"No": 0.6513524528906834, "Yes": 0.3486438444036155}, "ground_truth": 0}, {"key": "37308159", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4378216214942205, "res": {"No": 0.5621740899740191, "Yes": 0.4378216214942205}, "ground_truth": 0}, {"key": "37308159", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5312054363694682, "res": {"Yes": 0.5312054363694682, "No": 0.468787152232154}, "ground_truth": 0}, {"key": "37308159", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312068295129938, "res": {"Yes": 0.5312068295129938, "No": 0.46878838167700027}, "ground_truth": 0}, {"key": "37308159", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4687886890387157, "res": {"No": 0.5312071777994462, "Yes": 0.4687886890387157}, "ground_truth": 0}, {"key": "37308159", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4073314091054318, "res": {"No": 0.5926637031527375, "Yes": 0.4073314091054318}, "ground_truth": 1}, {"key": "35694408", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7772975036143062, "res": {"Yes": 0.7772975036143062, "No": 0.22269945673598857}, "ground_truth": 0}, {"key": "35694408", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8670322331717619, "res": {"Yes": 0.8670322331717619, "No": 0.13296368748365925}, "ground_truth": 0}, {"key": "35694408", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8175718846698616, "res": {"Yes": 0.8175718846698616, "No": 0.18242493740420945}, "ground_truth": 0}, {"key": "35694408", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.754911885011471, "res": {"Yes": 0.754911885011471, "No": 0.2450839988030444}, "ground_truth": 0}, {"key": "35694408", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8354815238792214, "res": {"Yes": 0.8354815238792214, "No": 0.16451605666328892}, "ground_truth": 0}, {"key": "35694408", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310563779482039, "res": {"Yes": 0.7310563779482039, "No": 0.26894060376934925}, "ground_truth": 1}, {"key": "39781995", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4999986877472098, "res": {"No": 0.4999986877472098, "Yes": 0.4999986877472098}, "ground_truth": 0}, {"key": "39781995", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981836850937263, "res": {"Yes": 0.7981836850937263, "No": 0.2018124373098011}, "ground_truth": 0}, {"key": "39781995", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772965770040267, "res": {"Yes": 0.7772965770040267, "No": 0.2226991912577066}, "ground_truth": 0}, {"key": "39781995", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791762675645624, "res": {"Yes": 0.6791762675645624, "No": 0.3208201617741671}, "ground_truth": 0}, {"key": "39781995", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057826509764165, "res": {"Yes": 0.7057826509764165, "No": 0.2942139901083408}, "ground_truth": 0}, {"key": "39781995", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310558768432849, "res": {"Yes": 0.7310558768432849, "No": 0.26894044346830553}, "ground_truth": 1}, {"key": "22799372", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.29421430576587676, "res": {"No": 0.7057834292334433, "Yes": 0.29421430576587676}, "ground_truth": 0}, {"key": "22799372", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6224578458173778, "res": {"Yes": 0.6224578458173778, "No": 0.37753976786691884}, "ground_truth": 0}, {"key": "22799372", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.798184898268751, "res": {"Yes": 0.798184898268751, "No": 0.201812750062968}, "ground_truth": 0}, {"key": "22799372", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981848269054633, "res": {"Yes": 0.7981848269054633, "No": 0.20181272600501488}, "ground_truth": 0}, {"key": "22799372", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5312074627612587, "res": {"Yes": 0.5312074627612587, "No": 0.46878894051663267}, "ground_truth": 0}, {"key": "22799372", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6791769355188836, "res": {"Yes": 0.6791769355188836, "No": 0.32082046773226147}, "ground_truth": 1}, {"key": "37428240", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6791758829850997, "res": {"Yes": 0.6791758829850997, "No": 0.3208199705505063}, "ground_truth": 0}, {"key": "37428240", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8354801170705364, "res": {"Yes": 0.8354801170705364, "No": 0.16451578209772674}, "ground_truth": 0}, {"key": "37428240", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9465926000584686, "res": {"Yes": 0.9465926000584686, "No": 0.05340309480670677}, "ground_truth": 0}, {"key": "37428240", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8670319747760591, "res": {"Yes": 0.8670319747760591, "No": 0.1329636557826496}, "ground_truth": 0}, {"key": "37428240", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791756198519086, "res": {"Yes": 0.6791756198519086, "No": 0.3208198558163645}, "ground_truth": 0}, {"key": "37428240", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9465924907421758, "res": {"Yes": 0.9465924907421758, "No": 0.05340309480670677}, "ground_truth": 1}, {"key": "40612657", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5312076527358854, "res": {"Yes": 0.5312076527358854, "No": 0.46878910816865227}, "ground_truth": 0}, {"key": "40612657", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7310560075662741, "res": {"Yes": 0.7310560075662741, "No": 0.26894047552850664}, "ground_truth": 0}, {"key": "40612657", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772976657712186, "res": {"Yes": 0.7772976657712186, "No": 0.22269950983168293}, "ground_truth": 0}, {"key": "40612657", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981845176646232, "res": {"Yes": 0.7981845176646232, "No": 0.20181265383117272}, "ground_truth": 0}, {"key": "40612657", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.40733189468260017, "res": {"No": 0.5926644096633487, "Yes": 0.40733189468260017}, "ground_truth": 0}, {"key": "40612657", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8519505133173358, "res": {"Yes": 0.8519505133173358, "No": 0.14804680252985367}, "ground_truth": 1}, {"key": "34404662", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.1480469437183542, "res": {"No": 0.8519513765813043, "Yes": 0.1480469437183542}, "ground_truth": 0}, {"key": "34404662", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7310564433097404, "res": {"Yes": 0.7310564433097404, "No": 0.2689406358295695}, "ground_truth": 0}, {"key": "34404662", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8933060178203613, "res": {"Yes": 0.8933060178203613, "No": 0.10669018530428968}, "ground_truth": 0}, {"key": "34404662", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8933058248065762, "res": {"Yes": 0.8933058248065762, "No": 0.10669015986737033}, "ground_truth": 0}, {"key": "34404662", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791769355188836, "res": {"Yes": 0.6791769355188836, "No": 0.32082046773226147}, "ground_truth": 0}, {"key": "34404662", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8933067765646107, "res": {"Yes": 0.8933067765646107, "No": 0.10669028705202774}, "ground_truth": 1}, {"key": "32619704", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.46878908022664484, "res": {"No": 0.531207621073443, "Yes": 0.46878908022664484}, "ground_truth": 0}, {"key": "32619704", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6791760449132679, "res": {"Yes": 0.6791760449132679, "No": 0.3208200470399569}, "ground_truth": 0}, {"key": "32619704", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.817571080607408, "res": {"Yes": 0.817571080607408, "No": 0.18242476343031494}, "ground_truth": 0}, {"key": "32619704", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310558768432849, "res": {"Yes": 0.7310558768432849, "No": 0.26894044346830553}, "ground_truth": 0}, {"key": "32619704", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310553539515616, "res": {"Yes": 0.7310553539515616, "No": 0.2689402511071791}, "ground_truth": 0}, {"key": "32619704", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.49999821091153046, "res": {"No": 0.49999821091153046, "Yes": 0.49999821091153046}, "ground_truth": 1}, {"key": "39014883", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4999983301204076, "res": {"No": 0.4999983301204076, "Yes": 0.4999983301204076}, "ground_truth": 0}, {"key": "39014883", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.49999821091153046, "res": {"No": 0.49999821091153046, "Yes": 0.49999821091153046}, "ground_truth": 0}, {"key": "39014883", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.43782180416767413, "res": {"No": 0.5621743245313765, "Yes": 0.43782180416767413}, "ground_truth": 0}, {"key": "39014883", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.59266476291897, "res": {"Yes": 0.59266476291897, "No": 0.4073321374714014}, "ground_truth": 0}, {"key": "39014883", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224569182835993, "res": {"Yes": 0.6224569182835993, "No": 0.3775392052892442}, "ground_truth": 0}, {"key": "39014883", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4073321374714014, "res": {"No": 0.59266476291897, "Yes": 0.4073321374714014}, "ground_truth": 1}, {"key": "37982812", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4073309235288423, "res": {"No": 0.5926629966429687, "Yes": 0.4073309235288423}, "ground_truth": 0}, {"key": "37982812", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513514434770445, "res": {"Yes": 0.6513514434770445, "No": 0.3486433041034292}, "ground_truth": 0}, {"key": "37982812", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.679174506597228, "res": {"Yes": 0.679174506597228, "No": 0.3208193203909121}, "ground_truth": 0}, {"key": "37982812", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.437821438820843, "res": {"No": 0.5621738554167595, "Yes": 0.437821438820843}, "ground_truth": 0}, {"key": "37982812", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224554342324282, "res": {"Yes": 0.6224554342324282, "No": 0.37753830516670844}, "ground_truth": 0}, {"key": "37982812", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.622454989017767, "res": {"Yes": 0.622454989017767, "No": 0.37753803513036616}, "ground_truth": 1}, {"key": "28123476", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.49999850893377673, "res": {"No": 0.49999850893377673, "Yes": 0.49999850893377673}, "ground_truth": 0}, {"key": "28123476", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9046468055592747, "res": {"Yes": 0.9046468055592747, "No": 0.09534907322912711}, "ground_truth": 0}, {"key": "28123476", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9324494449178069, "res": {"Yes": 0.9324494449178069, "No": 0.06754641224308855}, "ground_truth": 0}, {"key": "28123476", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8670310703917056, "res": {"Yes": 0.8670310703917056, "No": 0.13296352897868652}, "ground_truth": 0}, {"key": "28123476", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8670326853644271, "res": {"Yes": 0.8670326853644271, "No": 0.1329637825867336}, "ground_truth": 0}, {"key": "28123476", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9046466100951217, "res": {"Yes": 0.9046466100951217, "No": 0.09534905049613927}, "ground_truth": 1}, {"key": "39078849", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.49999844932931325, "res": {"No": 0.49999844932931325, "Yes": 0.49999844932931325}, "ground_truth": 0}, {"key": "39078849", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9465926000584686, "res": {"Yes": 0.9465926000584686, "No": 0.05340309480670677}, "ground_truth": 0}, {"key": "39078849", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8933064903715286, "res": {"Yes": 0.8933064903715286, "No": 0.10669023617814659}, "ground_truth": 0}, {"key": "39078849", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5926644449889013, "res": {"Yes": 0.5926644449889013, "No": 0.40733191896147375}, "ground_truth": 0}, {"key": "39078849", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310563779482039, "res": {"Yes": 0.7310563779482039, "No": 0.26894060376934925}, "ground_truth": 0}, {"key": "39078849", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8807941725351927, "res": {"Yes": 0.8807941725351927, "No": 0.11920254302325782}, "ground_truth": 1}, {"key": "39414137", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.03308586238356273, "res": {"No": 0.9669106098319871, "Yes": 0.03308586238356273}, "ground_truth": 0}, {"key": "39414137", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.05340314573589099, "res": {"No": 0.9465934534312528, "Yes": 0.05340314573589099}, "ground_truth": 0}, {"key": "39414137", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.04742570496113604, "res": {"No": 0.9525706877788608, "Yes": 0.04742570496113604}, "ground_truth": 0}, {"key": "39414137", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.05340313300359038, "res": {"No": 0.9465932383248172, "Yes": 0.05340313300359038}, "ground_truth": 0}, {"key": "39414137", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.07585790019702349, "res": {"No": 0.9241383490535781, "Yes": 0.07585790019702349}, "ground_truth": 0}, {"key": "39414137", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.03732675454214586, "res": {"No": 0.9626697593720553, "Yes": 0.03732675454214586}, "ground_truth": 1}, {"key": "37371354", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.32082023826366335, "res": {"No": 0.6791764294928223, "Yes": 0.32082023826366335}, "ground_truth": 0}, {"key": "37371354", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8519499039550612, "res": {"Yes": 0.8519499039550612, "No": 0.14804669663856665}, "ground_truth": 0}, {"key": "37371354", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224572892969449, "res": {"Yes": 0.6224572892969449, "No": 0.3775394303202135}, "ground_truth": 0}, {"key": "37371354", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8519498150897659, "res": {"Yes": 0.8519498150897659, "No": 0.14804667899002616}, "ground_truth": 0}, {"key": "37371354", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175711658867216, "res": {"Yes": 0.8175711658867216, "No": 0.1824247851770427}, "ground_truth": 0}, {"key": "37371354", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9324502716456526, "res": {"Yes": 0.9324502716456526, "No": 0.06754647666039779}, "ground_truth": 1}, {"key": "29497179", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621736543677577, "res": {"Yes": 0.5621736543677577, "No": 0.43782128224372296}, "ground_truth": 0}, {"key": "29497179", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8807897363450554, "res": {"Yes": 0.8807897363450554, "No": 0.11920191778267707}, "ground_truth": 0}, {"key": "29497179", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.731055550035914, "res": {"Yes": 0.731055550035914, "No": 0.2689403152275393}, "ground_truth": 0}, {"key": "29497179", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8175716410144892, "res": {"Yes": 0.8175716410144892, "No": 0.18242489391072028}, "ground_truth": 0}, {"key": "29497179", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310553539515616, "res": {"Yes": 0.7310553539515616, "No": 0.2689402511071791}, "ground_truth": 0}, {"key": "29497179", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8519461843156269, "res": {"Yes": 0.8519461843156269, "No": 0.14804604364397025}, "ground_truth": 1}, {"key": "35908694", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.34864405221160244, "res": {"No": 0.6513528605389426, "Yes": 0.34864405221160244}, "ground_truth": 0}, {"key": "35908694", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8175721161425328, "res": {"Yes": 0.8175721161425328, "No": 0.18242500264446268}, "ground_truth": 0}, {"key": "35908694", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224576603105115, "res": {"Yes": 0.6224576603105115, "No": 0.37753965535131684}, "ground_truth": 0}, {"key": "35908694", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7772977352670486, "res": {"Yes": 0.7772977352670486, "No": 0.22269953637953485}, "ground_truth": 0}, {"key": "35908694", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926641977100768, "res": {"Yes": 0.5926641977100768, "No": 0.4073317490093889}, "ground_truth": 0}, {"key": "35908694", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6791770974473028, "res": {"Yes": 0.6791770974473028, "No": 0.32082054422183065}, "ground_truth": 1}, {"key": "37619358", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.32082035299794187, "res": {"No": 0.6791766521442428, "Yes": 0.32082035299794187}, "ground_truth": 0}, {"key": "37619358", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.437822221707283, "res": {"No": 0.5621748606628468, "Yes": 0.437822221707283}, "ground_truth": 0}, {"key": "37619358", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.43782227389976214, "res": {"No": 0.5621749276793165, "Yes": 0.43782227389976214}, "ground_truth": 0}, {"key": "37619358", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312078743730358, "res": {"Yes": 0.5312078743730358, "No": 0.46878930376275096}, "ground_truth": 0}, {"key": "37619358", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.46878838167700027, "res": {"No": 0.5312068295129938, "Yes": 0.46878838167700027}, "ground_truth": 0}, {"key": "37619358", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621749611875544, "res": {"Yes": 0.5621749611875544, "No": 0.437822299996004}, "ground_truth": 1}, {"key": "37293103", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3775393853140089, "res": {"No": 0.622457215094258, "Yes": 0.3775393853140089}, "ground_truth": 0}, {"key": "37293103", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057824196028714, "res": {"Yes": 0.7057824196028714, "No": 0.29421388488923744}, "ground_truth": 0}, {"key": "37293103", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.437821517109424, "res": {"No": 0.5621739559412873, "Yes": 0.437821517109424}, "ground_truth": 0}, {"key": "37293103", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312072411242802, "res": {"Yes": 0.5312072411242802, "No": 0.4687887449226856}, "ground_truth": 0}, {"key": "37293103", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926643390122496, "res": {"Yes": 0.5926643390122496, "No": 0.4073318461248573}, "ground_truth": 0}, {"key": "37293103", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.3486436365957525, "res": {"No": 0.6513520452426794, "Yes": 0.3486436365957525}, "ground_truth": 1}, {"key": "36883729", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.0953488913653761, "res": {"No": 0.9046451474853858, "Yes": 0.0953488913653761}, "ground_truth": 0}, {"key": "36883729", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.24508385272164107, "res": {"No": 0.7549114125509441, "Yes": 0.24508385272164107}, "ground_truth": 0}, {"key": "36883729", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.22269897887530887, "res": {"No": 0.7772958588818198, "Yes": 0.22269897887530887}, "ground_truth": 0}, {"key": "36883729", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.1480466083958853, "res": {"No": 0.8519493834584634, "Yes": 0.1480466083958853}, "ground_truth": 0}, {"key": "36883729", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.22269908506648242, "res": {"No": 0.7772961368645309, "Yes": 0.22269908506648242}, "ground_truth": 0}, {"key": "36883729", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.26894009080634557, "res": {"No": 0.7310549835701506, "Yes": 0.26894009080634557}, "ground_truth": 1}, {"key": "39209521", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6224574006009916, "res": {"Yes": 0.6224574006009916, "No": 0.3775394978295304}, "ground_truth": 0}, {"key": "39209521", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8354794447911162, "res": {"Yes": 0.8354794447911162, "No": 0.16451566442691182}, "ground_truth": 0}, {"key": "39209521", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8519494723237138, "res": {"Yes": 0.8519494723237138, "No": 0.14804662604441737}, "ground_truth": 0}, {"key": "39209521", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310552885901226, "res": {"Yes": 0.7310552885901226, "No": 0.26894021904700477}, "ground_truth": 0}, {"key": "39209521", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310556153973765, "res": {"Yes": 0.7310556153973765, "No": 0.2689403152275393}, "ground_truth": 0}, {"key": "39209521", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.651351851124672, "res": {"Yes": 0.651351851124672, "No": 0.3486435119110941}, "ground_truth": 1}, {"key": "27792571", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7057822933991513, "res": {"Yes": 0.7057822933991513, "No": 0.2942138147431894}, "ground_truth": 0}, {"key": "27792571", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.94659227916229, "res": {"Yes": 0.94659227916229, "No": 0.05340308207441831}, "ground_truth": 0}, {"key": "27792571", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7549121549890477, "res": {"Yes": 0.7549121549890477, "No": 0.24508408645192822}, "ground_truth": 0}, {"key": "27792571", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8933062041785383, "res": {"Yes": 0.8933062041785383, "No": 0.1066902107412151}, "ground_truth": 0}, {"key": "27792571", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224572892969449, "res": {"Yes": 0.6224572892969449, "No": 0.3775394303202135}, "ground_truth": 0}, {"key": "27792571", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.957908523168569, "res": {"Yes": 0.957908523168569, "No": 0.04208755943683243}, "ground_truth": 1}, {"key": "39755647", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.34864405221160244, "res": {"No": 0.6513528023034614, "Yes": 0.34864405221160244}, "ground_truth": 0}, {"key": "39755647", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513527634798101, "res": {"Yes": 0.6513527634798101, "No": 0.3486440106499951}, "ground_truth": 0}, {"key": "39755647", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6513522005371271, "res": {"Yes": 0.6513522005371271, "No": 0.3486437197188828}, "ground_truth": 0}, {"key": "39755647", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621742575149787, "res": {"Yes": 0.5621742575149787, "No": 0.43782175197525103}, "ground_truth": 0}, {"key": "39755647", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.754911885011471, "res": {"Yes": 0.754911885011471, "No": 0.2450839988030444}, "ground_truth": 0}, {"key": "39755647", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5312071144746197, "res": {"Yes": 0.5312071144746197, "No": 0.4687886331547524}, "ground_truth": 1}, {"key": "40800537", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7549115475396359, "res": {"Yes": 0.7549115475396359, "No": 0.24508391115419195}, "ground_truth": 0}, {"key": "40800537", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8807908519528982, "res": {"Yes": 0.8807908519528982, "No": 0.11920208830251021}, "ground_truth": 0}, {"key": "40800537", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8354802789156627, "res": {"Yes": 0.8354802789156627, "No": 0.16451582132135043}, "ground_truth": 0}, {"key": "40800537", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9241364142674054, "res": {"Yes": 0.9241364142674054, "No": 0.07585773742380311}, "ground_truth": 0}, {"key": "40800537", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8670298171749465, "res": {"Yes": 0.8670298171749465, "No": 0.13296333877296868}, "ground_truth": 0}, {"key": "40800537", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8670301789280519, "res": {"Yes": 0.8670301789280519, "No": 0.13296337047390275}, "ground_truth": 1}, {"key": "14171461", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2689406999500214, "res": {"No": 0.7310566393943849, "Yes": 0.2689406999500214}, "ground_truth": 0}, {"key": "14171461", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057824196028714, "res": {"Yes": 0.7057824196028714, "No": 0.29421388488923744}, "ground_truth": 0}, {"key": "14171461", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9324496533365224, "res": {"Yes": 0.9324496533365224, "No": 0.06754642834741009}, "ground_truth": 0}, {"key": "14171461", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8933066833854576, "res": {"Yes": 0.8933066833854576, "No": 0.10669026161508413}, "ground_truth": 0}, {"key": "14171461", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.592663985756881, "res": {"Yes": 0.592663985756881, "No": 0.4073316033362297}, "ground_truth": 0}, {"key": "14171461", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9525703613075013, "res": {"Yes": 0.9525703613075013, "No": 0.04742568234680305}, "ground_truth": 1}, {"key": "36892440", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2942138147431894, "res": {"No": 0.7057822933991513, "Yes": 0.2942138147431894}, "ground_truth": 0}, {"key": "36892440", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.18242493740420945, "res": {"No": 0.8175718846698616, "Yes": 0.18242493740420945}, "ground_truth": 0}, {"key": "36892440", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.20181258165735638, "res": {"No": 0.7981842203177746, "Yes": 0.20181258165735638}, "ground_truth": 0}, {"key": "36892440", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.16451586054498346, "res": {"No": 0.8354804407608204, "Yes": 0.16451586054498346}, "ground_truth": 0}, {"key": "36892440", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.24508414488453484, "res": {"No": 0.7549122899778724, "Yes": 0.24508414488453484}, "ground_truth": 0}, {"key": "36892440", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.13296381428777349, "res": {"No": 0.8670330471187292, "Yes": 0.13296381428777349}, "ground_truth": 1}, {"key": "33733410", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.43782214341857606, "res": {"No": 0.5621747601381573, "Yes": 0.43782214341857606}, "ground_truth": 0}, {"key": "33733410", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.731055811481799, "res": {"Yes": 0.731055811481799, "No": 0.2689404114081082}, "ground_truth": 0}, {"key": "33733410", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.4687893875888182, "res": {"No": 0.5312079693604143, "Yes": 0.4687893875888182}, "ground_truth": 0}, {"key": "33733410", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.46878896845863177, "res": {"No": 0.5312074944236919, "Yes": 0.46878896845863177}, "ground_truth": 0}, {"key": "33733410", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5621745590888318, "res": {"Yes": 0.5621745590888318, "No": 0.43782198684120405}, "ground_truth": 0}, {"key": "33733410", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.592664268361159, "res": {"Yes": 0.592664268361159, "No": 0.4073317975671202}, "ground_truth": 1}, {"key": "38587765", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.37753965535131684, "res": {"No": 0.6224576603105115, "Yes": 0.37753965535131684}, "ground_truth": 0}, {"key": "38587765", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513529575980895, "res": {"Yes": 0.6513529575980895, "No": 0.3486441353348319}, "ground_truth": 0}, {"key": "38587765", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7310558768432849, "res": {"Yes": 0.7310558768432849, "No": 0.26894044346830553}, "ground_truth": 0}, {"key": "38587765", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6513532681874569, "res": {"Yes": 0.6513532681874569, "No": 0.34864430158135024}, "ground_truth": 0}, {"key": "38587765", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057831347577106, "res": {"Yes": 0.7057831347577106, "No": 0.29421416547359674}, "ground_truth": 0}, {"key": "38587765", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6791763282876553, "res": {"Yes": 0.6791763282876553, "No": 0.3208202000189129}, "ground_truth": 1}, {"key": "41065582", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.20181272600501488, "res": {"No": 0.7981848269054633, "Yes": 0.20181272600501488}, "ground_truth": 0}, {"key": "41065582", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513508417119657, "res": {"Yes": 0.6513508417119657, "No": 0.34864297161142305}, "ground_truth": 0}, {"key": "41065582", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5926640917334695, "res": {"Yes": 0.5926640917334695, "No": 0.4073316761728028}, "ground_truth": 0}, {"key": "41065582", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621745590888318, "res": {"Yes": 0.5621745590888318, "No": 0.43782198684120405}, "ground_truth": 0}, {"key": "41065582", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5312076843983299, "res": {"Yes": 0.5312076843983299, "No": 0.4687891361106614}, "ground_truth": 0}, {"key": "41065582", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621745925970478, "res": {"Yes": 0.5621745925970478, "No": 0.43782201293742884}, "ground_truth": 1}, {"key": "34713891", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.1645159782159387, "res": {"No": 0.8354811130410419, "Yes": 0.1645159782159387}, "ground_truth": 0}, {"key": "34713891", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.32082027650841827, "res": {"No": 0.6791764902159297, "Yes": 0.32082027650841827}, "ground_truth": 0}, {"key": "34713891", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.49999809170268167, "res": {"No": 0.49999809170268167, "Yes": 0.49999809170268167}, "ground_truth": 0}, {"key": "34713891", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.46878910816865227, "res": {"No": 0.5312076527358854, "Yes": 0.46878910816865227}, "ground_truth": 0}, {"key": "34713891", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3486436365957525, "res": {"No": 0.6513520452426794, "Yes": 0.3486436365957525}, "ground_truth": 0}, {"key": "34713891", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.43782203903365513, "res": {"No": 0.5621746261052657, "Yes": 0.43782203903365513}, "ground_truth": 1}, {"key": "18913023", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.8933063971924055, "res": {"Yes": 0.8933063971924055, "No": 0.10669023617814659}, "ground_truth": 0}, {"key": "18913023", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8519498150897659, "res": {"Yes": 0.8519498150897659, "No": 0.14804667899002616}, "ground_truth": 0}, {"key": "18913023", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8670320522947619, "res": {"Yes": 0.8670320522947619, "No": 0.13296368748365925}, "ground_truth": 0}, {"key": "18913023", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8519492057279907, "res": {"Yes": 0.8519492057279907, "No": 0.1480465730988275}, "ground_truth": 0}, {"key": "18913023", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8670319747760591, "res": {"Yes": 0.8670319747760591, "No": 0.1329636557826496}, "ground_truth": 0}, {"key": "18913023", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8933062973576413, "res": {"Yes": 0.8933062973576413, "No": 0.1066902107412151}, "ground_truth": 1}, {"key": "36884100", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6513517540656899, "res": {"Yes": 0.6513517540656899, "No": 0.3486434703495512}, "ground_truth": 0}, {"key": "36884100", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8354806150556408, "res": {"Yes": 0.8354806150556408, "No": 0.1645158801568035}, "ground_truth": 0}, {"key": "36884100", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7310558768432849, "res": {"Yes": 0.7310558768432849, "No": 0.26894044346830553}, "ground_truth": 0}, {"key": "36884100", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8354797809307587, "res": {"Yes": 0.8354797809307587, "No": 0.16451572326230876}, "ground_truth": 0}, {"key": "36884100", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057827771802003, "res": {"Yes": 0.7057827771802003, "No": 0.2942140251813836}, "ground_truth": 0}, {"key": "36884100", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310561818636294, "res": {"Yes": 0.7310561818636294, "No": 0.2689405396489203}, "ground_truth": 1}, {"key": "39899913", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.8519492945932224, "res": {"Yes": 0.8519492945932224, "No": 0.14804659074735535}, "ground_truth": 0}, {"key": "39899913", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8670334088731821, "res": {"Yes": 0.8670334088731821, "No": 0.13296387768987597}, "ground_truth": 0}, {"key": "39899913", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9399104821822947, "res": {"Yes": 0.9399104821822947, "No": 0.060086462598728366}, "ground_truth": 0}, {"key": "39899913", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981839110771696, "res": {"Yes": 0.7981839110771696, "No": 0.20181250948356583}, "ground_truth": 0}, {"key": "39899913", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9324498617552845, "res": {"Yes": 0.9324498617552845, "No": 0.06754644445173548}, "ground_truth": 0}, {"key": "39899913", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8807934375435664, "res": {"Yes": 0.8807934375435664, "No": 0.1192024293429083}, "ground_truth": 1}, {"key": "30725366", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.22269953637953485, "res": {"No": 0.7772977352670486, "Yes": 0.22269953637953485}, "ground_truth": 0}, {"key": "30725366", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.1645160174396091, "res": {"No": 0.8354812748863611, "Yes": 0.1645160174396091}, "ground_truth": 0}, {"key": "30725366", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.1645156448151175, "res": {"No": 0.8354793576438236, "Yes": 0.1645156448151175}, "ground_truth": 0}, {"key": "30725366", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.2689401549266675, "res": {"No": 0.7310551578672618, "Yes": 0.2689401549266675}, "ground_truth": 0}, {"key": "30725366", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.24508402801933554, "res": {"No": 0.7549119525058562, "Yes": 0.24508402801933554}, "ground_truth": 0}, {"key": "30725366", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.43782156930181915, "res": {"No": 0.5621740229576492, "Yes": 0.43782156930181915}, "ground_truth": 1}, {"key": "26133523", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.26894089231146884, "res": {"No": 0.7310571404998266, "Yes": 0.26894089231146884}, "ground_truth": 0}, {"key": "26133523", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8519494723237138, "res": {"Yes": 0.8519494723237138, "No": 0.14804662604441737}, "ground_truth": 0}, {"key": "26133523", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7549124249667211, "res": {"Yes": 0.7549124249667211, "No": 0.24508417410084338}, "ground_truth": 0}, {"key": "26133523", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224576603105115, "res": {"Yes": 0.6224576603105115, "No": 0.37753965535131684}, "ground_truth": 0}, {"key": "26133523", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175717993904731, "res": {"Yes": 0.8175717993904731, "No": 0.18242493740420945}, "ground_truth": 0}, {"key": "26133523", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.622457215094258, "res": {"Yes": 0.622457215094258, "No": 0.3775393853140089}, "ground_truth": 1}, {"key": "29332665", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.43782203903365513, "res": {"No": 0.5621746261052657, "Yes": 0.43782203903365513}, "ground_truth": 0}, {"key": "29332665", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7549123574722937, "res": {"Yes": 0.7549123574722937, "No": 0.24508414488453484}, "ground_truth": 0}, {"key": "29332665", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5312074310988276, "res": {"Yes": 0.5312074310988276, "No": 0.46878891257463523}, "ground_truth": 0}, {"key": "29332665", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7549116150339908, "res": {"Yes": 0.7549116150339908, "No": 0.24508391115419195}, "ground_truth": 0}, {"key": "29332665", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.43782172587904183, "res": {"No": 0.5621742240067827, "Yes": 0.43782172587904183}, "ground_truth": 0}, {"key": "29332665", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5312068928377863, "res": {"Yes": 0.5312068928377863, "No": 0.4687884375609335}, "ground_truth": 1}, {"key": "37400481", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621749276793165, "res": {"Yes": 0.5621749276793165, "No": 0.43782227389976214}, "ground_truth": 0}, {"key": "37400481", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9579093974483633, "res": {"Yes": 0.9579093974483633, "No": 0.042087599574676046}, "ground_truth": 0}, {"key": "37400481", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9465932383248172, "res": {"Yes": 0.9465932383248172, "No": 0.05340313300359038}, "ground_truth": 0}, {"key": "37400481", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9626706415836411, "res": {"Yes": 0.9626706415836411, "No": 0.037326790139729955}, "ground_truth": 0}, {"key": "37400481", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310551142929802, "res": {"Yes": 0.7310551142929802, "No": 0.2689401549266675}, "ground_truth": 0}, {"key": "37400481", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8933052524211136, "res": {"Yes": 0.8933052524211136, "No": 0.10669010899354982}, "ground_truth": 1}, {"key": "38787241", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.43782180416767413, "res": {"No": 0.5621743245313765, "Yes": 0.43782180416767413}, "ground_truth": 0}, {"key": "38787241", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8670324140487997, "res": {"Yes": 0.8670324140487997, "No": 0.13296371918467648}, "ground_truth": 0}, {"key": "38787241", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621743580395785, "res": {"Yes": 0.5621743580395785, "No": 0.43782183026388805}, "ground_truth": 0}, {"key": "38787241", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.731055920417612, "res": {"Yes": 0.731055920417612, "No": 0.26894044346830553}, "ground_truth": 0}, {"key": "38787241", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4999983301204076, "res": {"No": 0.4999983301204076, "Yes": 0.4999983301204076}, "ground_truth": 0}, {"key": "38787241", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.754912222483457, "res": {"Yes": 0.754912222483457, "No": 0.2450841156682298}, "ground_truth": 1}, {"key": "38225963", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.37753961034508543, "res": {"No": 0.6224575861077806, "Yes": 0.37753961034508543}, "ground_truth": 0}, {"key": "38225963", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7772965075083003, "res": {"Yes": 0.7772965075083003, "No": 0.2226991912577066}, "ground_truth": 0}, {"key": "38225963", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224569182835993, "res": {"Yes": 0.6224569182835993, "No": 0.3775392052892442}, "ground_truth": 0}, {"key": "38225963", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791763282876553, "res": {"Yes": 0.6791763282876553, "No": 0.3208202000189129}, "ground_truth": 0}, {"key": "38225963", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4378218824563205, "res": {"No": 0.5621744250559882, "Yes": 0.4378218824563205}, "ground_truth": 0}, {"key": "38225963", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.46878801843159645, "res": {"No": 0.5312064179020264, "Yes": 0.46878801843159645}, "ground_truth": 1}, {"key": "26072034", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3486436781573152, "res": {"No": 0.6513521423017049, "Yes": 0.3486436781573152}, "ground_truth": 0}, {"key": "26072034", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.20181246136771983, "res": {"No": 0.798183756456912, "Yes": 0.20181246136771983}, "ground_truth": 0}, {"key": "26072034", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.1824247416835898, "res": {"No": 0.8175710075108604, "Yes": 0.1824247416835898}, "ground_truth": 0}, {"key": "26072034", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.22269879304087703, "res": {"No": 0.7772951407602765, "Yes": 0.22269879304087703}, "ground_truth": 0}, {"key": "26072034", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.26893996256574754, "res": {"No": 0.7310545914018024, "Yes": 0.26893996256574754}, "ground_truth": 0}, {"key": "26072034", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.26894037934791476, "res": {"No": 0.731055746120319, "Yes": 0.26894037934791476}, "ground_truth": 1}, {"key": "35690810", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4073318461248573, "res": {"No": 0.5926643390122496, "Yes": 0.4073318461248573}, "ground_truth": 0}, {"key": "35690810", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8354797809307587, "res": {"Yes": 0.8354797809307587, "No": 0.16451572326230876}, "ground_truth": 0}, {"key": "35690810", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.731055746120319, "res": {"Yes": 0.731055746120319, "No": 0.26894037934791476}, "ground_truth": 0}, {"key": "35690810", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7549127624389484, "res": {"Yes": 0.7549127624389484, "No": 0.24508429096611234}, "ground_truth": 0}, {"key": "35690810", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8807936212914155, "res": {"Yes": 0.8807936212914155, "No": 0.11920245776298552}, "ground_truth": 0}, {"key": "35690810", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.49999844932931325, "res": {"No": 0.49999844932931325, "Yes": 0.49999844932931325}, "ground_truth": 1}, {"key": "36855665", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.437822221707283, "res": {"No": 0.5621748606628468, "Yes": 0.437822221707283}, "ground_truth": 0}, {"key": "36855665", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4073318461248573, "res": {"No": 0.5926643390122496, "Yes": 0.4073318461248573}, "ground_truth": 0}, {"key": "36855665", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7981835304735124, "res": {"Yes": 0.7981835304735124, "No": 0.20181241325188526}, "ground_truth": 0}, {"key": "36855665", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7549116150339908, "res": {"Yes": 0.7549116150339908, "No": 0.24508391115419195}, "ground_truth": 0}, {"key": "36855665", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057829454519473, "res": {"Yes": 0.7057829454519473, "No": 0.29421409532748183}, "ground_truth": 0}, {"key": "36855665", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.731056051140609, "res": {"Yes": 0.731056051140609, "No": 0.2689405075887116}, "ground_truth": 1}, {"key": "29757662", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2942142356197284, "res": {"No": 0.7057833030295428, "Yes": 0.2942142356197284}, "ground_truth": 0}, {"key": "29757662", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8175722745186087, "res": {"Yes": 0.8175722745186087, "No": 0.18242502439121894}, "ground_truth": 0}, {"key": "29757662", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7981847436483023, "res": {"Yes": 0.7981847436483023, "No": 0.20181270194706463}, "ground_truth": 0}, {"key": "29757662", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981846009217607, "res": {"Yes": 0.7981846009217607, "No": 0.20181267788911725}, "ground_truth": 0}, {"key": "29757662", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.731056051140609, "res": {"Yes": 0.731056051140609, "No": 0.2689405075887116}, "ground_truth": 0}, {"key": "29757662", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8807936212914155, "res": {"Yes": 0.8807936212914155, "No": 0.11920245776298552}, "ground_truth": 1}, {"key": "19134339", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.22269964257097424, "res": {"No": 0.777298152242159, "Yes": 0.22269964257097424}, "ground_truth": 0}, {"key": "19134339", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9241388585708952, "res": {"Yes": 0.9241388585708952, "No": 0.07585793636889766}, "ground_truth": 0}, {"key": "19134339", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8933063971924055, "res": {"Yes": 0.8933063971924055, "No": 0.10669023617814659}, "ground_truth": 0}, {"key": "19134339", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7772965075083003, "res": {"Yes": 0.7772965075083003, "No": 0.2226991912577066}, "ground_truth": 0}, {"key": "19134339", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.9241388585708952, "res": {"Yes": 0.9241388585708952, "No": 0.07585793636889766}, "ground_truth": 0}, {"key": "19134339", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8933057316275224, "res": {"Yes": 0.8933057316275224, "No": 0.10669015986737033}, "ground_truth": 1}, {"key": "35360732", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6224571037902444, "res": {"Yes": 0.6224571037902444, "No": 0.37753931780471206}, "ground_truth": 0}, {"key": "35360732", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.798183756456912, "res": {"Yes": 0.798183756456912, "No": 0.20181246136771983}, "ground_truth": 0}, {"key": "35360732", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6513516375949305, "res": {"Yes": 0.6513516375949305, "No": 0.3486433872264803}, "ground_truth": 0}, {"key": "35360732", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310549835701506, "res": {"Yes": 0.7310549835701506, "No": 0.26894009080634557}, "ground_truth": 0}, {"key": "35360732", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8354802789156627, "res": {"Yes": 0.8354802789156627, "No": 0.16451582132135043}, "ground_truth": 0}, {"key": "35360732", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772964380125801, "res": {"Yes": 0.7772964380125801, "No": 0.22269916470989579}, "ground_truth": 1}, {"key": "37713629", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4378224304772368, "res": {"No": 0.5621751287287737, "Yes": 0.4378224304772368}, "ground_truth": 0}, {"key": "37713629", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.3486437197188828, "res": {"No": 0.6513522587725544, "Yes": 0.3486437197188828}, "ground_truth": 0}, {"key": "37713629", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224571037902444, "res": {"Yes": 0.6224571037902444, "No": 0.37753931780471206}, "ground_truth": 0}, {"key": "37713629", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791770367241411, "res": {"Yes": 0.6791770367241411, "No": 0.32082050597704376}, "ground_truth": 0}, {"key": "37713629", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.09534923236019381, "res": {"No": 0.9046482681716913, "Yes": 0.09534923236019381}, "ground_truth": 0}, {"key": "37713629", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4687886890387157, "res": {"No": 0.5312071777994462, "Yes": 0.4687886890387157}, "ground_truth": 1}, {"key": "33393394", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6513522975961756, "res": {"Yes": 0.6513522975961756, "No": 0.34864376128045543}, "ground_truth": 0}, {"key": "33393394", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.835476618733545, "res": {"Yes": 0.835476618733545, "No": 0.1645150956858261}, "ground_truth": 0}, {"key": "33393394", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.914897069473258, "res": {"Yes": 0.914897069473258, "No": 0.08509868296335339}, "ground_truth": 0}, {"key": "33393394", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7772954882383598, "res": {"Yes": 0.7772954882383598, "No": 0.22269887268418598}, "ground_truth": 0}, {"key": "33393394", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.893303828114694, "res": {"Yes": 0.893303828114694, "No": 0.10668993093536908}, "ground_truth": 0}, {"key": "33393394", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.91489537897926, "res": {"Yes": 0.91489537897926, "No": 0.08509852065065159}, "ground_truth": 1}, {"key": "32275837", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7772972951268969, "res": {"Yes": 0.7772972951268969, "No": 0.22269940364030685}, "ground_truth": 0}, {"key": "32275837", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.59266476291897, "res": {"Yes": 0.59266476291897, "No": 0.4073321374714014}, "ground_truth": 0}, {"key": "32275837", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8519500689906342, "res": {"Yes": 0.8519500689906342, "No": 0.1480467319356539}, "ground_truth": 0}, {"key": "32275837", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981842916810081, "res": {"Yes": 0.7981842916810081, "No": 0.20181260571529228}, "ground_truth": 0}, {"key": "32275837", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7549121549890477, "res": {"Yes": 0.7549121549890477, "No": 0.24508408645192822}, "ground_truth": 0}, {"key": "32275837", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772969476480059, "res": {"Yes": 0.7772969476480059, "No": 0.2226992974489814}, "ground_truth": 1}, {"key": "21458094", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.26894037934791476, "res": {"No": 0.731055746120319, "Yes": 0.26894037934791476}, "ground_truth": 0}, {"key": "21458094", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4999979724938613, "res": {"No": 0.4999979724938613, "Yes": 0.4999979724938613}, "ground_truth": 0}, {"key": "21458094", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8807931619218647, "res": {"Yes": 0.8807931619218647, "No": 0.11920240092283786}, "ground_truth": 0}, {"key": "21458094", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312076527358854, "res": {"Yes": 0.5312076527358854, "No": 0.46878910816865227}, "ground_truth": 0}, {"key": "21458094", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.49999809170268167, "res": {"No": 0.49999809170268167, "Yes": 0.49999809170268167}, "ground_truth": 0}, {"key": "21458094", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8670318843375813, "res": {"Yes": 0.8670318843375813, "No": 0.1329636557826496}, "ground_truth": 1}, {"key": "40975362", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4999983301204076, "res": {"No": 0.4999983301204076, "Yes": 0.4999983301204076}, "ground_truth": 0}, {"key": "40975362", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513527634798101, "res": {"Yes": 0.6513527634798101, "No": 0.3486440106499951}, "ground_truth": 0}, {"key": "40975362", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621737548922496, "res": {"Yes": 0.5621737548922496, "No": 0.437821360532276}, "ground_truth": 0}, {"key": "40975362", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310561818636294, "res": {"Yes": 0.7310561818636294, "No": 0.2689405396489203}, "ground_truth": 0}, {"key": "40975362", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5312076527358854, "res": {"Yes": 0.5312076527358854, "No": 0.46878910816865227}, "ground_truth": 0}, {"key": "40975362", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621739559412873, "res": {"Yes": 0.5621739559412873, "No": 0.437821517109424}, "ground_truth": 1}, {"key": "35234201", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.43782203903365513, "res": {"No": 0.5621746261052657, "Yes": 0.43782203903365513}, "ground_truth": 0}, {"key": "35234201", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5926644096633487, "res": {"Yes": 0.5926644096633487, "No": 0.40733189468260017}, "ground_truth": 0}, {"key": "35234201", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224563617639954, "res": {"Yes": 0.6224563617639954, "No": 0.3775388677430418}, "ground_truth": 0}, {"key": "35234201", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.49999737645018577, "res": {"No": 0.49999737645018577, "Yes": 0.49999737645018577}, "ground_truth": 0}, {"key": "35234201", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224569182835993, "res": {"Yes": 0.6224569182835993, "No": 0.3775392052892442}, "ground_truth": 0}, {"key": "35234201", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5312071144746197, "res": {"Yes": 0.5312071144746197, "No": 0.4687886331547524}, "ground_truth": 1}, {"key": "36037573", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.40733196751922535, "res": {"No": 0.5926645156400129, "Yes": 0.40733196751922535}, "ground_truth": 0}, {"key": "36037573", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8354797809307587, "res": {"Yes": 0.8354797809307587, "No": 0.16451572326230876}, "ground_truth": 0}, {"key": "36037573", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7310548528473445, "res": {"Yes": 0.7310548528473445, "No": 0.2689400587461903}, "ground_truth": 0}, {"key": "36037573", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.651351851124672, "res": {"Yes": 0.651351851124672, "No": 0.3486435119110941}, "ground_truth": 0}, {"key": "36037573", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926635971762185, "res": {"Yes": 0.5926635971762185, "No": 0.4073313362689065}, "ground_truth": 0}, {"key": "36037573", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8670312512685009, "res": {"Yes": 0.8670312512685009, "No": 0.13296356067966597}, "ground_truth": 1}, {"key": "30861915", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7981845176646232, "res": {"Yes": 0.7981845176646232, "No": 0.20181265383117272}, "ground_truth": 0}, {"key": "30861915", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8175722745186087, "res": {"Yes": 0.8175722745186087, "No": 0.18242502439121894}, "ground_truth": 0}, {"key": "30861915", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8933065835506615, "res": {"Yes": 0.8933065835506615, "No": 0.10669026161508413}, "ground_truth": 0}, {"key": "30861915", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981842203177746, "res": {"Yes": 0.7981842203177746, "No": 0.20181258165735638}, "ground_truth": 0}, {"key": "30861915", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7549131674058205, "res": {"Yes": 0.7549131674058205, "No": 0.2450844370477769}, "ground_truth": 0}, {"key": "30861915", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9046480727072223, "res": {"Yes": 0.9046480727072223, "No": 0.09534920962716803}, "ground_truth": 1}, {"key": "40173012", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.407331821845988, "res": {"No": 0.5926643036867033, "Yes": 0.407331821845988}, "ground_truth": 0}, {"key": "40173012", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5312068295129938, "res": {"Yes": 0.5312068295129938, "No": 0.46878838167700027}, "ground_truth": 0}, {"key": "40173012", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621736208595977, "res": {"Yes": 0.5621736208595977, "No": 0.43782125614754175}, "ground_truth": 0}, {"key": "40173012", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312068295129938, "res": {"Yes": 0.5312068295129938, "No": 0.46878838167700027}, "ground_truth": 0}, {"key": "40173012", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926637738037608, "res": {"Yes": 0.5926637738037608, "No": 0.4073314576631226}, "ground_truth": 0}, {"key": "40173012", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.3486435534726419, "res": {"No": 0.6513519481836685, "Yes": 0.3486435534726419}, "ground_truth": 1}, {"key": "35100330", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2942139901083408, "res": {"No": 0.7057826509764165, "Yes": 0.2942139901083408}, "ground_truth": 0}, {"key": "35100330", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6224574748037005, "res": {"Yes": 0.6224574748037005, "No": 0.3775395428357484}, "ground_truth": 0}, {"key": "35100330", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.851950157855956, "res": {"Yes": 0.851950157855956, "No": 0.1480467319356539}, "ground_truth": 0}, {"key": "35100330", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.731055920417612, "res": {"Yes": 0.731055920417612, "No": 0.26894044346830553}, "ground_truth": 0}, {"key": "35100330", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5312071777994462, "res": {"Yes": 0.5312071777994462, "No": 0.4687886890387157}, "ground_truth": 0}, {"key": "35100330", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9046475874163092, "res": {"Yes": 0.9046475874163092, "No": 0.0953491641611327}, "ground_truth": 1}, {"key": "37220221", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.4999985685382473, "res": {"No": 0.4999985685382473, "Yes": 0.4999985685382473}, "ground_truth": 0}, {"key": "37220221", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7772972256311064, "res": {"Yes": 0.7772972256311064, "No": 0.22269937709247073}, "ground_truth": 0}, {"key": "37220221", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.40733218602917903, "res": {"No": 0.5926648335701196, "Yes": 0.40733218602917903}, "ground_truth": 0}, {"key": "37220221", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6513525499497697, "res": {"Yes": 0.6513525499497697, "No": 0.348643885965203}, "ground_truth": 0}, {"key": "37220221", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.49999844932931325, "res": {"No": 0.49999844932931325, "Yes": 0.49999844932931325}, "ground_truth": 0}, {"key": "37220221", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4999985685382473, "res": {"No": 0.4999985685382473, "Yes": 0.4999985685382473}, "ground_truth": 1}, {"key": "38815218", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5312071777994462, "res": {"Yes": 0.5312071777994462, "No": 0.4687886890387157}, "ground_truth": 0}, {"key": "38815218", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5926646216166962, "res": {"Yes": 0.5926646216166962, "No": 0.40733204035586357}, "ground_truth": 0}, {"key": "38815218", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.24508396958675677, "res": {"No": 0.7549117500227189, "Yes": 0.24508396958675677}, "ground_truth": 0}, {"key": "38815218", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.49999660159446985, "res": {"No": 0.49999660159446985, "Yes": 0.49999660159446985}, "ground_truth": 0}, {"key": "38815218", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4999979724938613, "res": {"No": 0.4999979724938613, "Yes": 0.4999979724938613}, "ground_truth": 0}, {"key": "38815218", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.1824246764434299, "res": {"No": 0.8175706907592302, "Yes": 0.1824246764434299}, "ground_truth": 1}, {"key": "39379109", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.04208767985047811, "res": {"No": 0.957911146010346, "Yes": 0.04208767985047811}, "ground_truth": 0}, {"key": "39379109", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7981843630442481, "res": {"Yes": 0.7981843630442481, "No": 0.20181260571529228}, "ground_truth": 0}, {"key": "39379109", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.880794736904179, "res": {"Yes": 0.880794736904179, "No": 0.11920259986347324}, "ground_truth": 0}, {"key": "39379109", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8175725181741701, "res": {"Yes": 0.8175725181741701, "No": 0.18242508963150328}, "ground_truth": 0}, {"key": "39379109", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310567701175105, "res": {"Yes": 0.7310567701175105, "No": 0.26894076407048856}, "ground_truth": 0}, {"key": "39379109", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621750282040362, "res": {"Yes": 0.5621750282040362, "No": 0.43782235218849247}, "ground_truth": 1}, {"key": "14576125", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6224577159625656, "res": {"Yes": 0.6224577159625656, "No": 0.3775396778544346}, "ground_truth": 0}, {"key": "14576125", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7772964380125801, "res": {"Yes": 0.7772964380125801, "No": 0.22269916470989579}, "ground_truth": 0}, {"key": "14576125", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224566956756981, "res": {"Yes": 0.6224566956756981, "No": 0.37753907027072703}, "ground_truth": 0}, {"key": "14576125", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224567884289806, "res": {"Yes": 0.6224567884289806, "No": 0.37753913777997955}, "ground_truth": 0}, {"key": "14576125", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057816413469579, "res": {"Yes": 0.7057816413469579, "No": 0.294213569232153}, "ground_truth": 0}, {"key": "14576125", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6224566956756981, "res": {"Yes": 0.6224566956756981, "No": 0.37753907027072703}, "ground_truth": 1}, {"key": "40814250", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6224556753905028, "res": {"Yes": 0.6224556753905028, "No": 0.3775384626879973}, "ground_truth": 0}, {"key": "40814250", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9241370201786537, "res": {"Yes": 0.9241370201786537, "No": 0.07585779168150443}, "ground_truth": 0}, {"key": "40814250", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8354789468067094, "res": {"Yes": 0.8354789468067094, "No": 0.16451556636796366}, "ground_truth": 0}, {"key": "40814250", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8933047798706012, "res": {"Yes": 0.8933047798706012, "No": 0.10669003268286455}, "ground_truth": 0}, {"key": "40814250", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8519499039550612, "res": {"Yes": 0.8519499039550612, "No": 0.14804669663856665}, "ground_truth": 0}, {"key": "40814250", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8933052524211136, "res": {"Yes": 0.8933052524211136, "No": 0.10669010899354982}, "ground_truth": 1}, {"key": "36334488", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.651351792889281, "res": {"Yes": 0.651351792889281, "No": 0.3486434703495512}, "ground_truth": 0}, {"key": "36334488", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513519481836685, "res": {"Yes": 0.6513519481836685, "No": 0.3486435534726419}, "ground_truth": 0}, {"key": "36334488", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.34864430158135024, "res": {"No": 0.6513533070111381, "Yes": 0.34864430158135024}, "ground_truth": 0}, {"key": "36334488", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.37753972286067405, "res": {"No": 0.6224577530639378, "Yes": 0.37753972286067405}, "ground_truth": 0}, {"key": "36334488", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.40733218602917903, "res": {"No": 0.5926648335701196, "Yes": 0.40733218602917903}, "ground_truth": 0}, {"key": "36334488", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.37753972286067405, "res": {"No": 0.6224577530639378, "Yes": 0.37753972286067405}, "ground_truth": 1}, {"key": "36888322", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.49999844932931325, "res": {"No": 0.49999844932931325, "Yes": 0.49999844932931325}, "ground_truth": 0}, {"key": "36888322", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5621748941710807, "res": {"Yes": 0.5621748941710807, "No": 0.4378222478035218}, "ground_truth": 0}, {"key": "36888322", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.34864334566495225, "res": {"No": 0.6513515405359803, "Yes": 0.34864334566495225}, "ground_truth": 0}, {"key": "36888322", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5621745590888318, "res": {"Yes": 0.5621745590888318, "No": 0.43782198684120405}, "ground_truth": 0}, {"key": "36888322", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224561391562933, "res": {"Yes": 0.6224561391562933, "No": 0.37753873272464533}, "ground_truth": 0}, {"key": "36888322", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4378214649170351, "res": {"No": 0.5621738889249334, "Yes": 0.4378214649170351}, "ground_truth": 1}, {"key": "37318916", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2689405396489203, "res": {"No": 0.7310561818636294, "Yes": 0.2689405396489203}, "ground_truth": 0}, {"key": "37318916", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4073317975671202, "res": {"No": 0.592664268361159, "Yes": 0.4073317975671202}, "ground_truth": 0}, {"key": "37318916", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.37753918278615467, "res": {"No": 0.6224568811822768, "Yes": 0.37753918278615467}, "ground_truth": 0}, {"key": "37318916", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312071144746197, "res": {"Yes": 0.5312071144746197, "No": 0.4687886331547524}, "ground_truth": 0}, {"key": "37318916", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.437821360532276, "res": {"No": 0.5621737548922496, "Yes": 0.437821360532276}, "ground_truth": 0}, {"key": "37318916", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.43782156930181915, "res": {"No": 0.5621740229576492, "Yes": 0.43782156930181915}, "ground_truth": 1}, {"key": "39308700", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.46878849344487344, "res": {"No": 0.5312069561625864, "Yes": 0.46878849344487344}, "ground_truth": 0}, {"key": "39308700", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.348642888488471, "res": {"No": 0.6513506281825552, "Yes": 0.348642888488471}, "ground_truth": 0}, {"key": "39308700", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621732857781079, "res": {"Yes": 0.5621732857781079, "No": 0.4378209951858151}, "ground_truth": 0}, {"key": "39308700", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312065762138992, "res": {"Yes": 0.5312065762138992, "No": 0.46878815814133384}, "ground_truth": 0}, {"key": "39308700", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5312062912525621, "res": {"Yes": 0.5312062912525621, "No": 0.4687879066638365}, "ground_truth": 0}, {"key": "39308700", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5621724480752569, "res": {"Yes": 0.5621724480752569, "No": 0.4378203427821788}, "ground_truth": 1}, {"key": "31061543", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.49999844932931325, "res": {"No": 0.49999844932931325, "Yes": 0.49999844932931325}, "ground_truth": 0}, {"key": "31061543", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5926629966429687, "res": {"Yes": 0.5926629966429687, "No": 0.4073309235288423}, "ground_truth": 0}, {"key": "31061543", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7981830785069053, "res": {"Yes": 0.7981830785069053, "No": 0.2018122929623491}, "ground_truth": 0}, {"key": "31061543", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.622457215094258, "res": {"Yes": 0.622457215094258, "No": 0.3775393853140089}, "ground_truth": 0}, {"key": "31061543", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057794538214188, "res": {"Yes": 0.7057794538214188, "No": 0.29421265733581153}, "ground_truth": 0}, {"key": "31061543", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5312073361115454, "res": {"Yes": 0.5312073361115454, "No": 0.4687888287486529}, "ground_truth": 1}, {"key": "37380894", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.26894021904700477, "res": {"No": 0.7310552885901226, "Yes": 0.26894021904700477}, "ground_truth": 0}, {"key": "37380894", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6791754984058547, "res": {"Yes": 0.6791754984058547, "No": 0.3208197793269595}, "ground_truth": 0}, {"key": "37380894", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7981834591103469, "res": {"Yes": 0.7981834591103469, "No": 0.2018123891939723}, "ground_truth": 0}, {"key": "37380894", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791753364778167, "res": {"Yes": 0.6791753364778167, "No": 0.32081970283757266}, "ground_truth": 0}, {"key": "37380894", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6513524528906834, "res": {"Yes": 0.6513524528906834, "No": 0.3486438444036155}, "ground_truth": 0}, {"key": "37380894", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.705782188229402, "res": {"Yes": 0.705782188229402, "No": 0.29421377967017165}, "ground_truth": 1}, {"key": "38410139", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2689403472877251, "res": {"No": 0.7310556807588449, "Yes": 0.2689403472877251}, "ground_truth": 0}, {"key": "38410139", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9241363109871187, "res": {"Yes": 0.9241363109871187, "No": 0.0758577193379113}, "ground_truth": 0}, {"key": "38410139", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8175704471042136, "res": {"Yes": 0.8175704471042136, "No": 0.18242463295000294}, "ground_truth": 0}, {"key": "38410139", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7057816413469579, "res": {"Yes": 0.7057816413469579, "No": 0.294213569232153}, "ground_truth": 0}, {"key": "38410139", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791754984058547, "res": {"Yes": 0.6791754984058547, "No": 0.3208197793269595}, "ground_truth": 0}, {"key": "38410139", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8175700450735947, "res": {"Yes": 0.8175700450735947, "No": 0.1824245459631801}, "ground_truth": 1}, {"key": "35953842", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.18242506788473922, "res": {"No": 0.8175724328947154, "Yes": 0.18242506788473922}, "ground_truth": 0}, {"key": "35953842", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9046465157331319, "res": {"Yes": 0.9046465157331319, "No": 0.09534905049613927}, "ground_truth": 0}, {"key": "35953842", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8670320522947619, "res": {"Yes": 0.8670320522947619, "No": 0.13296368748365925}, "ground_truth": 0}, {"key": "35953842", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9241386520097868, "res": {"Yes": 0.9241386520097868, "No": 0.07585791828295842}, "ground_truth": 0}, {"key": "35953842", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7772964380125801, "res": {"Yes": 0.7772964380125801, "No": 0.22269916470989579}, "ground_truth": 0}, {"key": "35953842", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8670307990765835, "res": {"Yes": 0.8670307990765835, "No": 0.13296346557675034}, "ground_truth": 1}, {"key": "39815663", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.18242463295000294, "res": {"No": 0.8175704471042136, "Yes": 0.18242463295000294}, "ground_truth": 0}, {"key": "39815663", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.3208199323057878, "res": {"No": 0.679175781780014, "Yes": 0.3208199323057878}, "ground_truth": 0}, {"key": "39815663", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.20181241325188526, "res": {"No": 0.7981836018366844, "Yes": 0.20181241325188526}, "ground_truth": 0}, {"key": "39815663", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.2942136744511435, "res": {"No": 0.7057818727202478, "Yes": 0.2942136744511435}, "ground_truth": 0}, {"key": "39815663", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.37753909277380987, "res": {"No": 0.6224567327770094, "Yes": 0.37753909277380987}, "ground_truth": 0}, {"key": "39815663", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.2689405717091329, "res": {"No": 0.7310563125866733, "Yes": 0.2689405717091329}, "ground_truth": 1}, {"key": "35121432", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2689406999500214, "res": {"No": 0.7310565740328309, "Yes": 0.2689406999500214}, "ground_truth": 0}, {"key": "35121432", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8354791957988758, "res": {"Yes": 0.8354791957988758, "No": 0.16451560559153589}, "ground_truth": 0}, {"key": "35121432", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9148967763631877, "res": {"Yes": 0.9148967763631877, "No": 0.08509866267424875}, "ground_truth": 0}, {"key": "35121432", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7772967854912433, "res": {"Yes": 0.7772967854912433, "No": 0.22269924435333766}, "ground_truth": 0}, {"key": "35121432", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3486440106499951, "res": {"No": 0.6513527634798101, "Yes": 0.3486440106499951}, "ground_truth": 0}, {"key": "35121432", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772967159954982, "res": {"Yes": 0.7772967159954982, "No": 0.22269924435333766}, "ground_truth": 1}, {"key": "21712310", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.43782227389976214, "res": {"No": 0.5621749276793165, "Yes": 0.43782227389976214}, "ground_truth": 0}, {"key": "21712310", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8519499039550612, "res": {"Yes": 0.8519499039550612, "No": 0.14804669663856665}, "ground_truth": 0}, {"key": "21712310", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8933060178203613, "res": {"Yes": 0.8933060178203613, "No": 0.10669018530428968}, "ground_truth": 0}, {"key": "21712310", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.754912829933412, "res": {"Yes": 0.754912829933412, "No": 0.24508432018243828}, "ground_truth": 0}, {"key": "21712310", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.731056051140609, "res": {"Yes": 0.731056051140609, "No": 0.2689405075887116}, "ground_truth": 0}, {"key": "21712310", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8519488629621836, "res": {"Yes": 0.8519488629621836, "No": 0.14804652015325656}, "ground_truth": 1}, {"key": "37952914", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7310564433097404, "res": {"Yes": 0.7310564433097404, "No": 0.2689406358295695}, "ground_truth": 0}, {"key": "37952914", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8175721161425328, "res": {"Yes": 0.8175721161425328, "No": 0.18242500264446268}, "ground_truth": 0}, {"key": "37952914", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9241392648078763, "res": {"Yes": 0.9241392648078763, "No": 0.07585797254078909}, "ground_truth": 0}, {"key": "37952914", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8807938969132609, "res": {"Yes": 0.8807938969132609, "No": 0.11920248618306951}, "ground_truth": 0}, {"key": "37952914", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224573449489658, "res": {"Yes": 0.6224573449489658, "No": 0.37753945282331774}, "ground_truth": 0}, {"key": "37952914", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8519493834584634, "res": {"Yes": 0.8519493834584634, "No": 0.1480466083958853}, "ground_truth": 1}, {"key": "38956779", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.047425772804199705, "res": {"No": 0.9525722030332658, "Yes": 0.047425772804199705}, "ground_truth": 0}, {"key": "38956779", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6791738588862535, "res": {"Yes": 0.6791738588862535, "No": 0.3208190144339119}, "ground_truth": 0}, {"key": "38956779", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6224559907512027, "res": {"Yes": 0.6224559907512027, "No": 0.37753864271240783}, "ground_truth": 0}, {"key": "38956779", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791738588862535, "res": {"Yes": 0.6791738588862535, "No": 0.3208190144339119}, "ground_truth": 0}, {"key": "38956779", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.5926627493647486, "res": {"Yes": 0.5926627493647486, "No": 0.4073307535771728}, "ground_truth": 0}, {"key": "38956779", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5312057529926759, "res": {"Yes": 0.5312057529926759, "No": 0.4687874316511541}, "ground_truth": 1}, {"key": "36101833", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.32082035299794187, "res": {"No": 0.6791767128673701, "Yes": 0.32082035299794187}, "ground_truth": 0}, {"key": "36101833", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057822513312497, "res": {"Yes": 0.7057822513312497, "No": 0.2942138147431894}, "ground_truth": 0}, {"key": "36101833", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621747936463851, "res": {"Yes": 0.5621747936463851, "No": 0.4378221695148102}, "ground_truth": 0}, {"key": "36101833", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.49999844932931325, "res": {"No": 0.49999844932931325, "Yes": 0.49999844932931325}, "ground_truth": 0}, {"key": "36101833", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7549124924611544, "res": {"Yes": 0.7549124924611544, "No": 0.24508420331715539}, "ground_truth": 0}, {"key": "36101833", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8670324140487997, "res": {"Yes": 0.8670324140487997, "No": 0.13296371918467648}, "ground_truth": 1}, {"key": "35544662", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.18242485041724146, "res": {"No": 0.817571482638536, "Yes": 0.18242485041724146}, "ground_truth": 0}, {"key": "35544662", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8519491168627682, "res": {"Yes": 0.8519491168627682, "No": 0.14804655545030174}, "ground_truth": 0}, {"key": "35544662", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8354801170705364, "res": {"Yes": 0.8354801170705364, "No": 0.16451578209772674}, "ground_truth": 0}, {"key": "35544662", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791753972008264, "res": {"Yes": 0.6791753972008264, "No": 0.3208197410822638}, "ground_truth": 0}, {"key": "35544662", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310552232286893, "res": {"Yes": 0.7310552232286893, "No": 0.26894018698683425}, "ground_truth": 0}, {"key": "35544662", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7549118175170919, "res": {"Yes": 0.7549118175170919, "No": 0.24508396958675677}, "ground_truth": 1}, {"key": "39759044", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.07585799062674127, "res": {"No": 0.9241395677643853, "Yes": 0.07585799062674127}, "ground_truth": 0}, {"key": "39759044", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.07585795445484123, "res": {"No": 0.9241391615272709, "Yes": 0.07585795445484123}, "ground_truth": 0}, {"key": "39759044", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.10669026161508413, "res": {"No": 0.8933065835506615, "Yes": 0.10669026161508413}, "ground_truth": 0}, {"key": "39759044", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.06754644445173548, "res": {"No": 0.9324499659646831, "Yes": 0.06754644445173548}, "ground_truth": 0}, {"key": "39759044", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.10669028705202774, "res": {"No": 0.8933068697437735, "Yes": 0.10669028705202774}, "ground_truth": 0}, {"key": "39759044", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.13296384598882094, "res": {"No": 0.8670332279959367, "Yes": 0.13296384598882094}, "ground_truth": 1}, {"key": "39433018", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.14804683782696618, "res": {"No": 0.8519506783530268, "Yes": 0.14804683782696618}, "ground_truth": 0}, {"key": "39433018", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8519477331055, "res": {"Yes": 0.8519477331055, "No": 0.1480463083711622}, "ground_truth": 0}, {"key": "39433018", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791747899709735, "res": {"Yes": 0.6791747899709735, "No": 0.3208194351248624}, "ground_truth": 0}, {"key": "39433018", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8933057316275224, "res": {"Yes": 0.8933057316275224, "No": 0.10669015986737033}, "ground_truth": 0}, {"key": "39433018", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.81757084913503, "res": {"Yes": 0.81757084913503, "No": 0.18242471993686724}, "ground_truth": 0}, {"key": "39433018", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8175697283223373, "res": {"Yes": 0.8175697283223373, "No": 0.18242445897639878}, "ground_truth": 1}, {"key": "22111959", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.16451607627513232, "res": {"No": 0.8354816110267399, "Yes": 0.16451607627513232}, "ground_truth": 0}, {"key": "22111959", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.348643802842033, "res": {"No": 0.6513523558316118, "Yes": 0.348643802842033}, "ground_truth": 0}, {"key": "22111959", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.40733196751922535, "res": {"No": 0.5926645156400129, "Yes": 0.40733196751922535}, "ground_truth": 0}, {"key": "22111959", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.43782183026388805, "res": {"No": 0.5621743580395785, "Yes": 0.43782183026388805}, "ground_truth": 0}, {"key": "22111959", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4687878228380341, "res": {"No": 0.5312061962654837, "Yes": 0.4687878228380341}, "ground_truth": 0}, {"key": "22111959", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4687887449226856, "res": {"No": 0.5312072411242802, "Yes": 0.4687887449226856}, "ground_truth": 1}, {"key": "38210094", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.37753916028306644, "res": {"No": 0.6224568440809567, "Yes": 0.37753916028306644}, "ground_truth": 0}, {"key": "38210094", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.46878880080666213, "res": {"No": 0.5312073044491218, "Yes": 0.46878880080666213}, "ground_truth": 0}, {"key": "38210094", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791758829850997, "res": {"Yes": 0.6791758829850997, "No": 0.3208199705505063}, "ground_truth": 0}, {"key": "38210094", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224566585743889, "res": {"Yes": 0.6224566585743889, "No": 0.3775390477676455}, "ground_truth": 0}, {"key": "38210094", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175713973591893, "res": {"Yes": 0.8175713973591893, "No": 0.18242482867050594}, "ground_truth": 0}, {"key": "38210094", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6224559907512027, "res": {"Yes": 0.6224559907512027, "No": 0.37753864271240783}, "ground_truth": 1}, {"key": "37675935", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3486441353348319, "res": {"No": 0.6513529575980895, "Yes": 0.3486441353348319}, "ground_truth": 0}, {"key": "37675935", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.2689406358295695, "res": {"No": 0.7310564433097404, "Yes": 0.2689406358295695}, "ground_truth": 0}, {"key": "37675935", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.49999827051596546, "res": {"No": 0.49999827051596546, "Yes": 0.49999827051596546}, "ground_truth": 0}, {"key": "37675935", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.4073319432403488, "res": {"No": 0.5926644803144561, "Yes": 0.4073319432403488}, "ground_truth": 0}, {"key": "37675935", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.49999844932931325, "res": {"No": 0.49999844932931325, "Yes": 0.49999844932931325}, "ground_truth": 0}, {"key": "37675935", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4687890522846391, "res": {"No": 0.5312075894110023, "Yes": 0.4687890522846391}, "ground_truth": 1}, {"key": "35732604", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.060086476924459106, "res": {"No": 0.9399105872254825, "Yes": 0.060086476924459106}, "ground_truth": 0}, {"key": "35732604", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.06754647666039779, "res": {"No": 0.932450375855097, "Yes": 0.06754647666039779}, "ground_truth": 0}, {"key": "35732604", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.04208763971255794, "res": {"No": 0.9579102717289557, "Yes": 0.04208763971255794}, "ground_truth": 0}, {"key": "35732604", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.03732679903913128, "res": {"No": 0.9626707527567032, "Yes": 0.03732679903913128}, "ground_truth": 0}, {"key": "35732604", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.04742576149701568, "res": {"No": 0.9525717701031898, "Yes": 0.04742576149701568}, "ground_truth": 0}, {"key": "35732604", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.03308590971330237, "res": {"No": 0.9669120578462025, "Yes": 0.03308590971330237}, "ground_truth": 1}, {"key": "27453212", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.201812774120924, "res": {"No": 0.7981849696320453, "Yes": 0.201812774120924}, "ground_truth": 0}, {"key": "27453212", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.3486435534726419, "res": {"No": 0.6513519481836685, "Yes": 0.3486435534726419}, "ground_truth": 0}, {"key": "27453212", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.32082042948748374, "res": {"No": 0.6791768140725944, "Yes": 0.32082042948748374}, "ground_truth": 0}, {"key": "27453212", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.29421434083895726, "res": {"No": 0.7057834923354019, "Yes": 0.29421434083895726}, "ground_truth": 0}, {"key": "27453212", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.22269961602310964, "res": {"No": 0.7772980827462918, "Yes": 0.22269961602310964}, "ground_truth": 0}, {"key": "27453212", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.32082027650841827, "res": {"No": 0.6791764902159297, "Yes": 0.32082027650841827}, "ground_truth": 1}, {"key": "39910047", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.1480468731240871, "res": {"No": 0.8519509449492108, "Yes": 0.1480468731240871}, "ground_truth": 0}, {"key": "39910047", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.5926643036867033, "res": {"Yes": 0.5926643036867033, "No": 0.407331821845988}, "ground_truth": 0}, {"key": "39910047", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5621745590888318, "res": {"Yes": 0.5621745590888318, "No": 0.43782198684120405}, "ground_truth": 0}, {"key": "39910047", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7981835304735124, "res": {"Yes": 0.7981835304735124, "No": 0.20181241325188526}, "ground_truth": 0}, {"key": "39910047", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4687890522846391, "res": {"No": 0.5312075894110023, "Yes": 0.4687890522846391}, "ground_truth": 0}, {"key": "39910047", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6791763282876553, "res": {"Yes": 0.6791763282876553, "No": 0.3208202000189129}, "ground_truth": 1}, {"key": "40054265", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7772970866395437, "res": {"Yes": 0.7772970866395437, "No": 0.2226993505446378}, "ground_truth": 0}, {"key": "40054265", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.49999809170268167, "res": {"No": 0.49999809170268167, "Yes": 0.49999809170268167}, "ground_truth": 0}, {"key": "40054265", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772968781522464, "res": {"Yes": 0.7772968781522464, "No": 0.2226992974489814}, "ground_truth": 0}, {"key": "40054265", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6224571037902444, "res": {"Yes": 0.6224571037902444, "No": 0.37753931780471206}, "ground_truth": 0}, {"key": "40054265", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791760449132679, "res": {"Yes": 0.6791760449132679, "No": 0.3208200470399569}, "ground_truth": 0}, {"key": "40054265", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057822933991513, "res": {"Yes": 0.7057822933991513, "No": 0.2942138147431894}, "ground_truth": 1}, {"key": "19984615", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.13296390939093852, "res": {"No": 0.8670336672693123, "Yes": 0.13296390939093852}, "ground_truth": 0}, {"key": "19984615", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.24508408645192822, "res": {"No": 0.7549120874946446, "Yes": 0.24508408645192822}, "ground_truth": 0}, {"key": "19984615", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.24508432018243828, "res": {"No": 0.754912829933412, "Yes": 0.24508432018243828}, "ground_truth": 0}, {"key": "19984615", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.3208200087952293, "res": {"No": 0.6791759437081583, "Yes": 0.3208200087952293}, "ground_truth": 0}, {"key": "19984615", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.20181260571529228, "res": {"No": 0.7981842916810081, "Yes": 0.20181260571529228}, "ground_truth": 0}, {"key": "19984615", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.29421388488923744, "res": {"No": 0.7057824196028714, "Yes": 0.29421388488923744}, "ground_truth": 1}, {"key": "16490806", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5312072411242802, "res": {"Yes": 0.5312072411242802, "No": 0.4687887449226856}, "ground_truth": 0}, {"key": "16490806", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9148964764367014, "res": {"Yes": 0.9148964764367014, "No": 0.08509862209605394}, "ground_truth": 0}, {"key": "16490806", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.9241377362560957, "res": {"Yes": 0.9241377362560957, "No": 0.07585784593924455}, "ground_truth": 0}, {"key": "16490806", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8519495611889732, "res": {"Yes": 0.8519495611889732, "No": 0.14804662604441737}, "ground_truth": 0}, {"key": "16490806", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8670304502429799, "res": {"Yes": 0.8670304502429799, "No": 0.1329634338757936}, "ground_truth": 0}, {"key": "16490806", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.9399104821822947, "res": {"Yes": 0.9399104821822947, "No": 0.060086462598728366}, "ground_truth": 1}, {"key": "36396237", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.7772969476480059, "res": {"Yes": 0.7772969476480059, "No": 0.2226992974489814}, "ground_truth": 0}, {"key": "36396237", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.731056051140609, "res": {"Yes": 0.731056051140609, "No": 0.2689405075887116}, "ground_truth": 0}, {"key": "36396237", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8354807769008635, "res": {"Yes": 0.8354807769008635, "No": 0.16451591938045054}, "ground_truth": 0}, {"key": "36396237", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7772970171437718, "res": {"Yes": 0.7772970171437718, "No": 0.222699323996808}, "ground_truth": 0}, {"key": "36396237", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8519496373592031, "res": {"Yes": 0.8519496373592031, "No": 0.14804664369295154}, "ground_truth": 0}, {"key": "36396237", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7549124249667211, "res": {"Yes": 0.7549124249667211, "No": 0.24508417410084338}, "ground_truth": 1}, {"key": "40726444", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.09534925509322502, "res": {"No": 0.9046484636362027, "Yes": 0.09534925509322502}, "ground_truth": 0}, {"key": "40726444", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.18242495915095794, "res": {"No": 0.8175719577664876, "Yes": 0.18242495915095794}, "ground_truth": 0}, {"key": "40726444", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.0850987641198204, "res": {"No": 0.9148979692535951, "Yes": 0.0850987641198204}, "ground_truth": 0}, {"key": "40726444", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.0953491641611327, "res": {"No": 0.9046475874163092, "Yes": 0.0953491641611327}, "ground_truth": 0}, {"key": "40726444", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.13296387768987597, "res": {"No": 0.867033486392013, "Yes": 0.13296387768987597}, "ground_truth": 0}, {"key": "40726444", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.13296394109200865, "res": {"No": 0.8670338481466493, "Yes": 0.13296394109200865}, "ground_truth": 1}, {"key": "37314826", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6224574748037005, "res": {"Yes": 0.6224574748037005, "No": 0.3775395428357484}, "ground_truth": 0}, {"key": "37314826", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.4687891919946846, "res": {"No": 0.5312077477232243, "Yes": 0.4687891919946846}, "ground_truth": 0}, {"key": "37314826", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7057819989238926, "res": {"Yes": 0.7057819989238926, "No": 0.2942137095241487}, "ground_truth": 0}, {"key": "37314826", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.46878891257463523, "res": {"No": 0.5312074310988276, "Yes": 0.46878891257463523}, "ground_truth": 0}, {"key": "37314826", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7057824196028714, "res": {"Yes": 0.7057824196028714, "No": 0.29421388488923744}, "ground_truth": 0}, {"key": "37314826", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772965770040267, "res": {"Yes": 0.7772965770040267, "No": 0.2226991912577066}, "ground_truth": 1}, {"key": "38506971", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.49999791288946177, "res": {"No": 0.49999791288946177, "Yes": 0.49999791288946177}, "ground_truth": 0}, {"key": "38506971", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.59266243143576, "res": {"Yes": 0.59266243143576, "No": 0.4073305350679875}, "ground_truth": 0}, {"key": "38506971", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.5926635971762185, "res": {"Yes": 0.5926635971762185, "No": 0.4073313362689065}, "ground_truth": 0}, {"key": "38506971", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7310544606790663, "res": {"Yes": 0.7310544606790663, "No": 0.2689398984454714}, "ground_truth": 0}, {"key": "38506971", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791754984058547, "res": {"Yes": 0.6791754984058547, "No": 0.3208197793269595}, "ground_truth": 0}, {"key": "38506971", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7310553539515616, "res": {"Yes": 0.7310553539515616, "No": 0.2689402511071791}, "ground_truth": 1}, {"key": "40699312", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6513529575980895, "res": {"Yes": 0.6513529575980895, "No": 0.3486441353348319}, "ground_truth": 0}, {"key": "40699312", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.46878896845863177, "res": {"No": 0.5312074944236919, "Yes": 0.46878896845863177}, "ground_truth": 0}, {"key": "40699312", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.49999827051596546, "res": {"No": 0.49999827051596546, "Yes": 0.49999827051596546}, "ground_truth": 0}, {"key": "40699312", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6791758222620464, "res": {"Yes": 0.6791758222620464, "No": 0.3208199323057878}, "ground_truth": 0}, {"key": "40699312", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.4378219346487591, "res": {"No": 0.5621744920724061, "Yes": 0.4378219346487591}, "ground_truth": 0}, {"key": "40699312", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.49999850893377673, "res": {"No": 0.49999850893377673, "Yes": 0.49999850893377673}, "ground_truth": 1}, {"key": "34695474", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.348643802842033, "res": {"No": 0.6513523558316118, "Yes": 0.348643802842033}, "ground_truth": 0}, {"key": "34695474", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8670318843375813, "res": {"Yes": 0.8670318843375813, "No": 0.1329636557826496}, "ground_truth": 0}, {"key": "34695474", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8354798556284754, "res": {"Yes": 0.8354798556284754, "No": 0.16451574287411241}, "ground_truth": 0}, {"key": "34695474", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5926638091292755, "res": {"Yes": 0.5926638091292755, "No": 0.40733148194197016}, "ground_truth": 0}, {"key": "34695474", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6224563246627063, "res": {"Yes": 0.6224563246627063, "No": 0.3775388452399724}, "ground_truth": 0}, {"key": "34695474", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.5926639151058324, "res": {"Yes": 0.5926639151058324, "No": 0.40733155477852157}, "ground_truth": 1}, {"key": "36281498", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.10669036336289496, "res": {"No": 0.8933075353095045, "Yes": 0.10669036336289496}, "ground_truth": 0}, {"key": "36281498", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.03732680793853473, "res": {"No": 0.9626710826897372, "Yes": 0.03732680793853473}, "ground_truth": 0}, {"key": "36281498", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.10669033792593316, "res": {"No": 0.8933073489510498, "Yes": 0.10669033792593316}, "ground_truth": 0}, {"key": "36281498", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.0850988452763648, "res": {"No": 0.9148988690348172, "Yes": 0.0850988452763648}, "ground_truth": 0}, {"key": "36281498", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.07585793636889766, "res": {"No": 0.9241388585708952, "Yes": 0.07585793636889766}, "ground_truth": 0}, {"key": "36281498", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.04208760960914293, "res": {"No": 0.9579095045030869, "Yes": 0.04208760960914293}, "ground_truth": 1}, {"key": "39558652", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.6791759437081583, "res": {"Yes": 0.6791759437081583, "No": 0.3208200087952293}, "ground_truth": 0}, {"key": "39558652", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057824827047398, "res": {"Yes": 0.7057824827047398, "No": 0.2942139199622677}, "ground_truth": 0}, {"key": "39558652", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7310556153973765, "res": {"Yes": 0.7310556153973765, "No": 0.2689403152275393}, "ground_truth": 0}, {"key": "39558652", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.731055811481799, "res": {"Yes": 0.731055811481799, "No": 0.2689404114081082}, "ground_truth": 0}, {"key": "39558652", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.731055920417612, "res": {"Yes": 0.731055920417612, "No": 0.26894044346830553}, "ground_truth": 0}, {"key": "39558652", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8519497262244798, "res": {"Yes": 0.8519497262244798, "No": 0.14804666134148778}, "ground_truth": 1}, {"key": "37330579", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.042087539367924975, "res": {"No": 0.9579078665671257, "Yes": 0.042087539367924975}, "ground_truth": 0}, {"key": "37330579", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.3486439690883928, "res": {"No": 0.6513526470088703, "Yes": 0.3486439690883928}, "ground_truth": 0}, {"key": "37330579", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.3208199323057878, "res": {"No": 0.6791758222620464, "Yes": 0.3208199323057878}, "ground_truth": 0}, {"key": "37330579", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.40733191896147375, "res": {"No": 0.5926644449889013, "Yes": 0.40733191896147375}, "ground_truth": 0}, {"key": "37330579", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.24508396958675677, "res": {"No": 0.7549117500227189, "Yes": 0.24508396958675677}, "ground_truth": 0}, {"key": "37330579", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.32081928214627115, "res": {"No": 0.6791744053923475, "Yes": 0.32081928214627115}, "ground_truth": 1}, {"key": "40547658", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3775394303202135, "res": {"No": 0.6224572892969449, "Yes": 0.3775394303202135}, "ground_truth": 0}, {"key": "40547658", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.32082027650841827, "res": {"No": 0.6791764902159297, "Yes": 0.32082027650841827}, "ground_truth": 0}, {"key": "40547658", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.49999821091153046, "res": {"No": 0.49999821091153046, "Yes": 0.49999821091153046}, "ground_truth": 0}, {"key": "40547658", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.5312073044491218, "res": {"Yes": 0.5312073044491218, "No": 0.46878880080666213}, "ground_truth": 0}, {"key": "40547658", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.29421413040053723, "res": {"No": 0.7057830085538628, "Yes": 0.29421413040053723}, "ground_truth": 0}, {"key": "40547658", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.43782201293742884, "res": {"No": 0.5621745925970478, "Yes": 0.43782201293742884}, "ground_truth": 1}, {"key": "37119340", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.2689403472877251, "res": {"No": 0.7310556807588449, "Yes": 0.2689403472877251}, "ground_truth": 0}, {"key": "37119340", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.9324496533365224, "res": {"Yes": 0.9324496533365224, "No": 0.06754642834741009}, "ground_truth": 0}, {"key": "37119340", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7981831498700368, "res": {"Yes": 0.7981831498700368, "No": 0.20181231702025057}, "ground_truth": 0}, {"key": "37119340", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8670313417069127, "res": {"Yes": 0.8670313417069127, "No": 0.13296356067966597}, "ground_truth": 0}, {"key": "37119340", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310556807588449, "res": {"Yes": 0.7310556807588449, "No": 0.2689403472877251}, "ground_truth": 0}, {"key": "37119340", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8519490406925849, "res": {"Yes": 0.8519490406925849, "No": 0.1480465378017781}, "ground_truth": 1}, {"key": "35301627", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.26894082819097104, "res": {"No": 0.7310569444150476, "Yes": 0.26894082819097104}, "ground_truth": 0}, {"key": "35301627", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8175713242626135, "res": {"Yes": 0.8175713242626135, "No": 0.18242482867050594}, "ground_truth": 0}, {"key": "35301627", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772970171437718, "res": {"Yes": 0.7772970171437718, "No": 0.222699323996808}, "ground_truth": 0}, {"key": "35301627", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8933063971924055, "res": {"Yes": 0.8933063971924055, "No": 0.10669023617814659}, "ground_truth": 0}, {"key": "35301627", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.6791760044312222, "res": {"Yes": 0.6791760044312222, "No": 0.3208200470399569}, "ground_truth": 0}, {"key": "35301627", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.914898371428426, "res": {"Yes": 0.914898371428426, "No": 0.08509880469808292}, "ground_truth": 1}, {"key": "34037168", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.22269924435333766, "res": {"No": 0.7772967159954982, "Yes": 0.22269924435333766}, "ground_truth": 0}, {"key": "34037168", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.2226993505446378, "res": {"No": 0.7772971561353219, "Yes": 0.2226993505446378}, "ground_truth": 0}, {"key": "34037168", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.2942132185024564, "res": {"No": 0.7057808210240861, "Yes": 0.2942132185024564}, "ground_truth": 0}, {"key": "34037168", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.2689404114081082, "res": {"No": 0.731055811481799, "Yes": 0.2689404114081082}, "ground_truth": 0}, {"key": "34037168", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.3775392727985209, "res": {"No": 0.6224570295875796, "Yes": 0.3775392727985209}, "ground_truth": 0}, {"key": "34037168", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.40733155477852157, "res": {"No": 0.5926639151058324, "Yes": 0.40733155477852157}, "ground_truth": 1}, {"key": "39703862", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621738219085876, "res": {"Yes": 0.5621738219085876, "No": 0.43782141272465247}, "ground_truth": 0}, {"key": "39703862", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.6513515405359803, "res": {"Yes": 0.6513515405359803, "No": 0.34864334566495225}, "ground_truth": 0}, {"key": "39703862", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.81757084913503, "res": {"Yes": 0.81757084913503, "No": 0.18242471993686724}, "ground_truth": 0}, {"key": "39703862", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6513510358296724, "res": {"Yes": 0.6513510358296724, "No": 0.3486430962958882}, "ground_truth": 0}, {"key": "39703862", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8175694115712027, "res": {"Yes": 0.8175694115712027, "No": 0.18242439373633998}, "ground_truth": 0}, {"key": "39703862", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7772962295254566, "res": {"Yes": 0.7772962295254566, "No": 0.22269908506648242}, "ground_truth": 1}, {"key": "16554814", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.07585795445484123, "res": {"No": 0.9241391615272709, "Yes": 0.07585795445484123}, "ground_truth": 0}, {"key": "16554814", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.05340313300359038, "res": {"No": 0.9465931325347849, "Yes": 0.05340313300359038}, "ground_truth": 0}, {"key": "16554814", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.11920248618306951, "res": {"No": 0.8807938969132609, "Yes": 0.11920248618306951}, "ground_truth": 0}, {"key": "16554814", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.11920254302325782, "res": {"No": 0.8807941725351927, "Yes": 0.11920254302325782}, "ground_truth": 0}, {"key": "16554814", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.18242487216397957, "res": {"No": 0.8175715679178915, "Yes": 0.18242487216397957}, "ground_truth": 0}, {"key": "16554814", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.09534909596212039, "res": {"No": 0.9046471021256566, "Yes": 0.09534909596212039}, "ground_truth": 1}, {"key": "32983099", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3775395428357484, "res": {"No": 0.6224574748037005, "Yes": 0.3775395428357484}, "ground_truth": 0}, {"key": "32983099", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7772967854912433, "res": {"Yes": 0.7772967854912433, "No": 0.22269924435333766}, "ground_truth": 0}, {"key": "32983099", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7772969476480059, "res": {"Yes": 0.7772969476480059, "No": 0.2226992974489814}, "ground_truth": 0}, {"key": "32983099", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.7549116825283518, "res": {"Yes": 0.7549116825283518, "No": 0.24508394037047262}, "ground_truth": 0}, {"key": "32983099", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.705782188229402, "res": {"Yes": 0.705782188229402, "No": 0.29421377967017165}, "ground_truth": 0}, {"key": "32983099", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.835479693783431, "res": {"Yes": 0.835479693783431, "No": 0.16451570365050744}, "ground_truth": 1}, {"key": "41072994", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.46878891257463523, "res": {"No": 0.5312074310988276, "Yes": 0.46878891257463523}, "ground_truth": 0}, {"key": "41072994", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7057829033840068, "res": {"Yes": 0.7057829033840068, "No": 0.29421409532748183}, "ground_truth": 0}, {"key": "41072994", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.6791762675645624, "res": {"Yes": 0.6791762675645624, "No": 0.3208201617741671}, "ground_truth": 0}, {"key": "41072994", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.8354812748863611, "res": {"Yes": 0.8354812748863611, "No": 0.1645160174396091}, "ground_truth": 0}, {"key": "41072994", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7549127624389484, "res": {"Yes": 0.7549127624389484, "No": 0.24508429096611234}, "ground_truth": 0}, {"key": "41072994", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.6791764294928223, "res": {"Yes": 0.6791764294928223, "No": 0.32082023826366335}, "ground_truth": 1}, {"key": "38396247", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.3486440106499951, "res": {"No": 0.6513527634798101, "Yes": 0.3486440106499951}, "ground_truth": 0}, {"key": "38396247", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7772952102558808, "res": {"Yes": 0.7772952102558808, "No": 0.22269881958864352}, "ground_truth": 0}, {"key": "38396247", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.7549117500227189, "res": {"Yes": 0.7549117500227189, "No": 0.24508396958675677}, "ground_truth": 0}, {"key": "38396247", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.6513522005371271, "res": {"Yes": 0.6513522005371271, "No": 0.3486437197188828}, "ground_truth": 0}, {"key": "38396247", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.7310542645950062, "res": {"Yes": 0.7310542645950062, "No": 0.2689398343252106}, "ground_truth": 0}, {"key": "38396247", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.7057820620257235, "res": {"Yes": 0.7057820620257235, "No": 0.2942137445971581}, "ground_truth": 1}, {"key": "37507998", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.26894076407048856, "res": {"No": 0.7310568136918909, "Yes": 0.26894076407048856}, "ground_truth": 0}, {"key": "37507998", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.7310565740328309, "res": {"Yes": 0.7310565740328309, "No": 0.2689406999500214}, "ground_truth": 0}, {"key": "37507998", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.4378220912261125, "res": {"No": 0.5621746931217074, "Yes": 0.4378220912261125}, "ground_truth": 0}, {"key": "37507998", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.37753988038255437, "res": {"No": 0.6224580313242994, "Yes": 0.37753988038255437}, "ground_truth": 0}, {"key": "37507998", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.26894082819097104, "res": {"No": 0.7310569444150476, "Yes": 0.26894082819097104}, "ground_truth": 0}, {"key": "37507998", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.4687893875888182, "res": {"No": 0.5312079693604143, "Yes": 0.4687893875888182}, "ground_truth": 1}, {"key": "32593929", "model": "hermes3-8b", "target_model": "human", "recognition_score": 0.5621743245313765, "res": {"Yes": 0.5621743245313765, "No": 0.43782180416767413}, "ground_truth": 0}, {"key": "32593929", "model": "hermes3-8b", "target_model": "claude", "recognition_score": 0.8807938050393029, "res": {"Yes": 0.8807938050393029, "No": 0.11920248618306951}, "ground_truth": 0}, {"key": "32593929", "model": "hermes3-8b", "target_model": "gpt35", "recognition_score": 0.8354807769008635, "res": {"Yes": 0.8354807769008635, "No": 0.16451591938045054}, "ground_truth": 0}, {"key": "32593929", "model": "hermes3-8b", "target_model": "gpt4", "recognition_score": 0.9148985691076449, "res": {"Yes": 0.9148985691076449, "No": 0.08509882498722143}, "ground_truth": 0}, {"key": "32593929", "model": "hermes3-8b", "target_model": "llama", "recognition_score": 0.8519486090616748, "res": {"Yes": 0.8519486090616748, "No": 0.14804646720770456}, "ground_truth": 0}, {"key": "32593929", "model": "hermes3-8b", "target_model": "hermes3-8b", "recognition_score": 0.8670316130222044, "res": {"Yes": 0.8670316130222044, "No": 0.13296359238065295}, "ground_truth": 1}]